{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_preprocessing.ipynb\n",
    "\n",
    "## Objective\n",
    "\n",
    "Preprocess Cusanus' sermons for topic modeling:\n",
    "\n",
    "- Load and parse TEI XML files.\n",
    "- Clean, normalize, and lemmatize text.\n",
    "- Save cleaned text for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为:  /Users/jessie/Documents/Projects/Cusanus_Topic_Modeling\n"
     ]
    }
   ],
   "source": [
    "# 更改工作目录到项目根目录\n",
    "os.chdir('/Users/jessie/Documents/Projects/Cusanus_Topic_Modeling')\n",
    "print(\"当前工作目录为: \", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置文件加载成功，项目根目录为:  /Users/jessie/Documents/Projects/Cusanus_Topic_Modeling\n",
      "输入目录: /Users/jessie/Documents/Projects/Cusanus_Topic_Modeling/data/raw\n",
      "输出目录: /Users/jessie/Documents/Projects/Cusanus_Topic_Modeling/data/processed\n",
      "输入目录中的文件:  ['v170_048.xml', 'v170_060.xml', 'v170_074.xml', 'h180_134.xml', 'v180_135.xml', 'h170_075.xml', 'h170_061.xml', 'h170_049.xml', 'h190_281.xml', 'v160_024_1.xml', 'h190_256.xml', 'h170_101.xml', 'h170_115.xml', 'h190_242.xml', 'v190_243.xml', 'v170_114.xml', 'v170_100.xml', 'v190_257.xml', 'v190_280.xml', 'v190_281.xml', 'v190_256.xml', 'v170_101.xml', 'v170_115.xml', 'v190_242.xml', 'h190_243.xml', 'h170_114.xml', 'h170_100.xml', 'h190_257.xml', 'h190_280.xml', 'h170_048.xml', 'h170_060.xml', 'h170_074.xml', 'v180_134.xml', 'h180_135.xml', 'v170_075.xml', 'v170_061.xml', 'v170_049.xml', 'v170_077.xml', 'v170_063.xml', 'h180_123.xml', 'v170_088.xml', 'h180_137.xml', 'v180_136.xml', 'v180_122.xml', 'h170_089.xml', 'h170_062.xml', 'h170_076.xml', 'h190_282.xml', 'v160_024_2.xml', 'h170_116.xml', 'h190_241.xml', 'h190_255.xml', 'h170_102.xml', 'h190_269.xml', 'v190_268.xml', 'v170_103.xml', 'v190_254.xml', 'v190_240.xml', 'v170_117.xml', 'v190_283.xml', 'v190_282.xml', 'v170_116.xml', 'v190_241.xml', 'v190_255.xml', 'v170_102.xml', 'v190_269.xml', 'h190_268.xml', 'h170_103.xml', 'h190_254.xml', 'h190_240.xml', 'h170_117.xml', 'h510_epalb.xml', 'h190_283.xml', 'h170_077.xml', 'h170_063.xml', 'v180_123.xml', 'h170_088.xml', 'v180_137.xml', 'h180_136.xml', 'h180_122.xml', 'v170_089.xml', 'v170_062.xml', 'v170_076.xml', 'v170_072.xml', 'v170_066.xml', 'h180_126.xml', 'h180_132.xml', 'v170_099.xml', 'v180_133.xml', 'h170_098.xml', 'v180_127.xml', 'h170_067.xml', 'h170_073.xml', 'h190_287.xml', 'h190_293.xml', 'h190_278.xml', 'h170_113.xml', 'h190_244.xml', 'h190_250.xml', 'h170_107.xml', 'v170_106.xml', 'v190_251.xml', 'v190_245.xml', 'v170_112.xml', 'v190_279.xml', 'v190_292.xml', 'v190_286.xml', 'v190_287.xml', 'v190_293.xml', 'v190_278.xml', 'h160_024_2.xml', 'v170_113.xml', 'v190_244.xml', 'v190_250.xml', 'v170_107.xml', 'h170_106.xml', 'h190_251.xml', 'h190_245.xml', 'h170_112.xml', 'h190_279.xml', 'h190_292.xml', 'h190_286.xml', 'h170_072.xml', 'h170_066.xml', 'v180_126.xml', 'v180_132.xml', 'h170_099.xml', 'h180_133.xml', 'v170_098.xml', 'h180_127.xml', 'v170_067.xml', 'v170_073.xml', 'v170_065.xml', 'v170_071.xml', 'v170_059.xml', 'h180_131.xml', 'h180_125.xml', 'v180_124.xml', 'v180_130.xml', 'h170_058.xml', 'h170_070.xml', 'h170_064.xml', 'h190_290.xml', 'h190_284.xml', 'h190_253.xml', 'h170_104.xml', 'h170_110.xml', 'h190_247.xml', 'v190_246.xml', 'v170_111.xml', 'v170_105.xml', 'v190_252.xml', 'v190_285.xml', 'v190_291.xml', 'v190_290.xml', 'v190_284.xml', 'h160_024_1.xml', 'v190_253.xml', 'v170_104.xml', 'v170_110.xml', 'v190_247.xml', 'h190_246.xml', 'h170_111.xml', 'h170_105.xml', 'h190_252.xml', 'h190_285.xml', 'h190_291.xml', 'h170_065.xml', 'h170_071.xml', 'h170_059.xml', 'v180_131.xml', 'v180_125.xml', 'h180_124.xml', 'h180_130.xml', 'v170_058.xml', 'v170_070.xml', 'v170_064.xml', 'v170_037_b.xml', 'h180_194.xml', 'h180_180.xml', 'v160_017.xml', 'v160_003.xml', 'h180_157.xml', 'h180_195_a.xml', 'h180_143.xml', 'v180_142.xml', 'v180_156.xml', 'h160_002.xml', 'h160_016.xml', 'v180_181.xml', 'v180_195.xml', 'h190_235.xml', 'h190_221.xml', 'h190_209.xml', 'v190_208.xml', 'v190_220.xml', 'v190_234.xml', 'v190_235.xml', 'v190_221.xml', 'v190_209.xml', 'h190_208.xml', 'h190_220.xml', 'h190_234.xml', 'v180_194.xml', 'v180_180.xml', 'h160_017.xml', 'h180_197_b.xml', 'h160_003.xml', 'v180_157.xml', 'v180_143.xml', 'h180_142.xml', 'h180_156.xml', 'v160_002.xml', 'v160_016.xml', 'h180_181.xml', 'v170_037_c.xml', 'h180_195.xml', 'v170_028.xml', 'h180_183.xml', 'h180_197.xml', 'v170_037_a.xml', 'v160_014.xml', 'h180_195_b.xml', 'h180_140.xml', 'h180_154.xml', 'h180_168.xml', 'v180_169.xml', 'v180_155.xml', 'v180_141.xml', 'h160_015.xml', 'h160_001.xml', 'v180_196.xml', 'h170_029.xml', 'v180_182.xml', 'h190_222.xml', 'h190_236.xml', 'v190_237.xml', 'v190_223.xml', 'v190_222.xml', 'v190_236.xml', '.gitkeep', 'h190_237.xml', 'h190_223.xml', 'h170_028.xml', 'v180_183.xml', 'v180_197.xml', 'h160_014.xml', 'h180_197_a.xml', 'v180_140.xml', 'v180_154.xml', 'v180_168.xml', 'h180_169.xml', 'h180_155.xml', 'h180_141.xml', 'v160_015.xml', 'v160_001.xml', 'h180_196.xml', 'v170_029.xml', 'h180_182.xml', 'v160_005.xml', 'v160_011.xml', 'h180_186.xml', 'v170_039.xml', 'h180_192.xml', 'h180_179.xml', 'v180_197_a.xml', 'h180_145.xml', 'h180_151.xml', 'v180_150.xml', 'v180_144.xml', 'v180_178.xml', 'h170_038.xml', 'v180_193.xml', 'v180_187.xml', 'h160_010.xml', 'h160_004.xml', 'h190_227.xml', 'h190_233.xml', 'v190_232.xml', 'v190_226.xml', 'v190_227.xml', 'v190_233.xml', 'h190_232.xml', 'h190_226.xml', 'h160_005.xml', 'h160_011.xml', 'v180_186.xml', 'h170_039.xml', 'v180_195_b.xml', 'v180_192.xml', 'v180_179.xml', 'h170_037_a.xml', 'v180_145.xml', 'v180_151.xml', 'h180_150.xml', 'h180_144.xml', 'h180_178.xml', 'v170_038.xml', 'h180_193.xml', 'h180_187.xml', 'v160_010.xml', 'v160_004.xml', 'v160_012.xml', 'v160_006.xml', 'h180_191.xml', 'h180_185.xml', 'v180_197_b.xml', 'h180_152.xml', 'h180_146.xml', 'v180_147.xml', 'h170_037_c.xml', 'v180_153.xml', 'v180_184.xml', 'v180_190.xml', 'h160_007.xml', 'h160_013.xml', 'h190_218.xml', 'h190_230.xml', 'h190_224.xml', 'v190_225.xml', 'v190_231.xml', 'v190_219.xml', 'v190_218.xml', 'v190_230.xml', 'v190_224.xml', 'h190_225.xml', 'h190_231.xml', 'h190_219.xml', 'h160_012.xml', 'h160_006.xml', 'v180_191.xml', 'v180_195_a.xml', 'v180_185.xml', 'v180_152.xml', 'h170_037_b.xml', 'v180_146.xml', 'h180_147.xml', 'h180_153.xml', 'h180_184.xml', 'h180_190.xml', 'v160_007.xml', 'v160_013.xml', 'h180_189.xml', 'v160_022.xml', 'v170_036.xml', 'h180_176.xml', 'h180_162.xml', 'v180_163.xml', 'v180_177.xml', 'h160_023.xml', 'h170_037.xml', 'v180_188.xml', 'h180_200.xml', 'h190_214.xml', 'h190_228.xml', 'v190_229.xml', 'v180_201.xml', 'v190_215.xml', 'v180_182_b.xml', 'v180_200.xml', 'v190_214.xml', 'v190_228.xml', 'h190_229.xml', 'h180_201.xml', 'h190_215.xml', 'v180_189.xml', 'h160_022.xml', 'h170_036.xml', 'v180_176.xml', 'v180_162.xml', 'h180_163.xml', 'h180_177.xml', 'v160_023.xml', 'v170_037.xml', 'h180_188.xml', 'v160_009.xml', 'v170_035.xml', 'v160_021.xml', 'h180_161.xml', 'h180_175.xml', 'h180_149.xml', 'v180_148.xml', 'v180_174.xml', 'v180_160.xml', 'h170_034.xml', 'h160_020.xml', 'h160_008.xml', 'h190_217.xml', 'h180_203.xml', 'h500_ck.xml', 'v190_216.xml', 'v180_202.xml', 'v180_182_a.xml', 'v190_217.xml', 'v180_203.xml', 'h190_216.xml', 'h180_202.xml', 'h160_009.xml', 'h170_035.xml', 'h160_021.xml', 'v180_161.xml', 'v180_175.xml', 'v180_149.xml', 'h180_148.xml', 'h180_174.xml', 'h180_160.xml', 'v170_034.xml', 'v160_020.xml', 'v160_008.xml', 'v160_024.xml', 'v170_030.xml', 'v160_018.xml', 'h180_158.xml', 'h180_164.xml', 'h180_170.xml', 'v180_171.xml', 'v180_165.xml', 'v180_159.xml', 'h160_019.xml', 'h160_025.xml', 'h170_031.xml', 'h190_206.xml', 'h190_212.xml', 'v190_213.xml', 'v190_207.xml', 'v190_206.xml', 'v190_212.xml', 'h190_213.xml', 'h190_207.xml', 'h180_182_a.xml', 'h160_024.xml', 'h170_030.xml', 'h160_018.xml', 'v180_158.xml', 'v180_164.xml', 'v180_170.xml', 'h180_171.xml', 'h180_165.xml', 'h180_159.xml', 'v160_019.xml', 'v160_025.xml', 'v170_031.xml', 'v170_027.xml', 'v170_033.xml', 'h180_198.xml', 'h180_173.xml', 'h180_167.xml', 'v180_166.xml', 'v180_172.xml', 'h170_032.xml', 'v180_199.xml', 'h160_026.xml', 'h190_239.xml', 'h190_211.xml', 'h190_205.xml', 'v190_204.xml', 'v190_210.xml', 'v190_238.xml', 'v190_239.xml', 'v190_211.xml', 'v190_205.xml', 'h190_204.xml', 'h190_210.xml', 'h190_238.xml', 'h180_182_b.xml', 'h170_027.xml', 'h170_033.xml', 'v180_198.xml', 'v180_173.xml', 'v180_167.xml', 'h180_166.xml', 'h180_172.xml', 'v170_032.xml', 'h180_199.xml', 'v160_026.xml', 'v170_069.xml', 'v170_041.xml', 'v170_055.xml', 'h180_129.xml', 'v170_082.xml', 'v170_096.xml', 'h170_097.xml', 'v180_128.xml', 'h170_083.xml', 'h170_054.xml', 'h170_040.xml', 'h170_068.xml', 'h190_288.xml', 'h170_120.xml', 'h190_277.xml', 'h190_263.xml', 'h170_108.xml', 'v170_109.xml', 'tei.dtd', 'v190_262.xml', 'v190_276.xml', 'v170_121.xml', 'v190_289.xml', 'v190_288.xml', 'v170_120.xml', 'v190_277.xml', 'v190_263.xml', 'v170_108.xml', 'h170_109.xml', 'h190_262.xml', 'h190_276.xml', 'h170_121.xml', 'h190_289.xml', 'h170_069.xml', 'v170_079_b.xml', 'h170_041.xml', 'h170_055.xml', 'v180_129.xml', 'h170_082.xml', 'h170_096.xml', 'v170_097.xml', 'h180_128.xml', 'v170_083.xml', 'v170_054.xml', 'v170_040.xml', 'v170_068.xml', 'v170_056.xml', 'v170_042.xml', 'v170_095.xml', 'v170_081.xml', 'h170_080.xml', 'h170_094.xml', 'h170_043.xml', 'h170_057.xml', 'h190_260.xml', 'h190_274.xml', 'h190_248.xml', 'v190_249.xml', 'v190_275.xml', 'v190_261.xml', 'v190_260.xml', 'v190_274.xml', 'v190_248.xml', 'h190_249.xml', 'h190_275.xml', 'h190_261.xml', 'v170_079_a.xml', 'h170_056.xml', 'h170_042.xml', 'h170_095.xml', 'h170_081.xml', 'v170_080.xml', 'v170_094.xml', 'v170_043.xml', 'v170_057.xml', 'v170_053.xml', 'v170_047.xml', 'v170_090.xml', 'v170_084.xml', 'h170_079_a.xml', 'h170_085.xml', 'h170_091.xml', 'h170_046.xml', 'h170_052.xml', 'h190_259.xml', 'lemma.xml', 'h190_265.xml', 'h190_271.xml', 'v190_270.xml', 'v190_264.xml', 'v190_258.xml', 'v190_259.xml', 'v190_265.xml', 'v190_271.xml', 'h190_270.xml', 'h190_264.xml', 'h190_258.xml', 'h170_053.xml', 'h170_047.xml', 'h170_090.xml', 'h170_084.xml', 'v170_085.xml', 'v170_091.xml', 'v170_046.xml', 'v170_052.xml', 'v170_044.xml', 'v170_050.xml', 'v170_078.xml', 'v170_087.xml', 'h180_138.xml', 'v170_093.xml', 'h170_079_b.xml', 'v180_139.xml', 'h170_092.xml', 'h170_086.xml', 'h170_079.xml', 'h170_051.xml', 'h170_045.xml', 'h170_119.xml', 'h190_272.xml', 'h190_266.xml', 'v190_267.xml', 'v190_273.xml', 'v170_118.xml', 'v170_119.xml', 'v190_272.xml', 'v190_266.xml', 'h190_267.xml', 'h190_273.xml', 'h170_118.xml', 'h170_044.xml', 'h170_050.xml', 'h170_078.xml', 'h170_087.xml', 'v180_138.xml', 'h170_093.xml', 'h180_139.xml', 'v170_092.xml', 'v170_086.xml', 'v170_079.xml', 'v170_051.xml', 'v170_045.xml']\n"
     ]
    }
   ],
   "source": [
    "# 加载配置文件\n",
    "CONFIG_PATH = 'config.yaml'\n",
    "\n",
    "try:\n",
    "    with open(CONFIG_PATH, 'r') as config_file:\n",
    "        config = yaml.safe_load(config_file)\n",
    "    BASE_DIR = config.get('BASE_DIR', os.getcwd())\n",
    "    print(\"配置文件加载成功，项目根目录为: \", BASE_DIR)\n",
    "except FileNotFoundError:\n",
    "    print(f\"配置文件未找到: {CONFIG_PATH}，使用当前工作目录。\")\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "# 示例使用 BASE_DIR\n",
    "input_dir = os.path.join(BASE_DIR, 'data/raw')\n",
    "output_dir = os.path.join(BASE_DIR, 'data/processed')\n",
    "\n",
    "print(f\"输入目录: {input_dir}\")\n",
    "print(f\"输出目录: {output_dir}\")\n",
    "\n",
    "# 列出输入目录中的文件\n",
    "print(\"输入目录中的文件: \", os.listdir(input_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义停用词加载函数\n",
    "def load_stopwords(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            stopwords = {line.strip() for line in f if line.strip() and not line.startswith('#')}\n",
    "        print(\"停用词列表加载成功。\")\n",
    "        return stopwords\n",
    "    except FileNotFoundError:\n",
    "        print(f\"停用词文件未找到: {filepath}\")\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义词形表加载函数\n",
    "def load_lemmas(filepath):\n",
    "    lemmas = defaultdict(str)\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            soup = BeautifulSoup(file, 'xml')\n",
    "            for lemma in soup.find_all('lemma'):\n",
    "                lemmas[lemma['name']] = lemma['name']\n",
    "                for variant in lemma.find_all('variant'):\n",
    "                    lemmas[variant['name']] = lemma['name']\n",
    "        print(\"词形表加载成功。\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"词形文件未找到: {filepath}\")\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  处理目录中的文件，保存结果\n",
    "def process_directory(input_dir, output_dir, lemmas, latin_stopwords):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    xml_files = [f for f in os.listdir(input_dir) if f.endswith('.xml')]\n",
    "\n",
    "    for xml_file in tqdm.tqdm(xml_files, desc=\"Processing files\"):\n",
    "        input_path = os.path.join(input_dir, xml_file)\n",
    "        output_path = os.path.join(output_dir, xml_file.replace('.xml', '.txt'))\n",
    "        \n",
    "        # 如果文件已处理则跳过\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"文件已存在，跳过处理: {output_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # 调用预处理函数处理文本\n",
    "            processed_text = preprocess_text_with_pos(input_path, lemmas, latin_stopwords)\n",
    "            \n",
    "            # 写入处理结果到输出文件\n",
    "            with open(output_path, 'w') as out_file:\n",
    "                out_file.write(processed_text)\n",
    "            \n",
    "            print(f\"成功处理文件: {xml_file}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"处理文件 {xml_file} 时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML 文件预处理函数\n",
    "# 处理 XML 文件，检查是否包含 lemma_l 属性，并根据情况进行词形还原和停用词去除\n",
    "def preprocess_text(xml_file):\n",
    "    try:\n",
    "        with open(xml_file, 'r') as file:\n",
    "            soup = BeautifulSoup(file, 'xml')\n",
    "            words = []\n",
    "            for w in soup.find_all('w'):\n",
    "                # 检查词汇是否有 lemma_l 属性\n",
    "                lemma_attr = w.get('lemma_l')\n",
    "                if lemma_attr:\n",
    "                    # 如果有 lemma_l 属性，直接使用\n",
    "                    word = lemma_attr.lower()\n",
    "                else:\n",
    "                    # 如果没有 lemma_l 属性，则使用词汇文本并进行词形还原\n",
    "                    raw_word = w.get_text().lower()\n",
    "                    word = lemmas.get(raw_word, raw_word)\n",
    "                # 去除停用词\n",
    "                if word not in latin_stopwords:\n",
    "                    words.append(word)\n",
    "            return ' '.join(words)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"XML 文件未找到: {xml_file}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为:  /Users/jessie/Documents/Projects/Cusanus_Topic_Modeling\n"
     ]
    }
   ],
   "source": [
    "# 主程序：加载停用词和词形表，并处理指定目录\n",
    "# 更改工作目录到项目根目录\n",
    "os.chdir('/Users/jessie/Documents/Projects/Cusanus_Topic_Modeling')\n",
    "print(\"当前工作目录为: \", os.getcwd())\n",
    "BASE_DIR = '/Users/jessie/Documents/Projects/Cusanus_Topic_Modeling'  # 请设置为实际项目路径\n",
    "stopwords_path = os.path.join(BASE_DIR, 'data/external/stopwords_latin.txt')\n",
    "lemmas_path = os.path.join(BASE_DIR, 'data/external/lemma.xml')\n",
    "input_dir = os.path.join(BASE_DIR, 'data/raw')\n",
    "output_dir = os.path.join(BASE_DIR, 'data/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "停用词文件未找到: /Users/jessie/Documents/Projects/Cusanus_Topic_Modeling/../data/external/stopwords_latin.txt\n",
      "词形文件未找到: /Users/jessie/Documents/Projects/Cusanus_Topic_Modeling/../data/external/lemma.xml\n"
     ]
    }
   ],
   "source": [
    "# 加载停用词和词形表\n",
    "latin_stopwords = load_stopwords(stopwords_path)\n",
    "lemmas = load_lemmas(lemmas_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行数据预处理\n",
    "process_directory('data/raw', 'data/processed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
