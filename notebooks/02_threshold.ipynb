{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# 设置工作目录和路径\n",
    "base_dir = \"/Users/jessie/Documents/Projects/Cusanus_Topic_Modeling\"\n",
    "os.chdir(base_dir)\n",
    "\n",
    "# 设置实验相关目录\n",
    "dirs = {\n",
    "    'input': 'experiments/lda/cusanus/preprocessed',  # 修改为正确的输入目录\n",
    "    'output': 'experiments/lda/cusanus/threshold',\n",
    "    'logs': 'experiments/lda/cusanus/threshold'\n",
    "}\n",
    "\n",
    "# 创建所需目录\n",
    "for dir_path in dirs.values():\n",
    "    os.makedirs(dir_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paragraphs(input_dir: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    加载所有文档的段落\n",
    "    返回: 段落列表，每个段落是词列表\n",
    "    \"\"\"\n",
    "    paragraphs = []\n",
    "    \n",
    "    # 调试信息\n",
    "    print(f\"当前工作目录: {os.getcwd()}\")\n",
    "    print(f\"尝试加载目录: {input_dir}\")\n",
    "    \n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]\n",
    "    print(f\"找到的txt文件: {files}\")\n",
    "    \n",
    "    for filename in files:\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        print(f\"\\n处理文件: {filename}\")\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "            \n",
    "        # 按\"Paragraph\"分割，但跳过空字符串\n",
    "        parts = [p.strip() for p in content.split('Paragraph') if p.strip()]\n",
    "        \n",
    "        for part in parts:\n",
    "            # 分割段落编号和内容\n",
    "            lines = part.split('\\n', 1)  # 最多分割一次\n",
    "            if len(lines) == 2:  # 确保有内容行\n",
    "                content_line = lines[1].strip()\n",
    "                if content_line:  # 确保内容不为空\n",
    "                    words = content_line.split()\n",
    "                    if words:  # 确保有词\n",
    "                        paragraphs.append(words)\n",
    "    \n",
    "    print(f\"\\n总共加载了 {len(paragraphs)} 个段落\")\n",
    "    \n",
    "    if len(paragraphs) == 0:\n",
    "        raise ValueError(f\"未能从目录 {input_dir} 加载到任何段落，请检查文件路径和文件内容格式是否正确\")\n",
    "        \n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置日志配置\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "log_file = os.path.join(dirs['logs'], f'cusanus_threshold_{timestamp}.log')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_thresholds(\n",
    "    corpus: List[List[str]],\n",
    "    min_freqs: List[int] = [2, 3, 4],\n",
    "    max_freqs: List[int] = [200, 800, 1400, 2000],\n",
    "    n_topics: int = 15,\n",
    "    n_splits: int = 5,\n",
    "    alpha: float = 0.5,\n",
    "    random_state: int = 42\n",
    ") -> Tuple[pd.DataFrame, Dict, List]:\n",
    "    \"\"\"评估不同词频阈值组合的效果\"\"\"\n",
    "    \n",
    "    # 初始化结果存储\n",
    "    results = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    logging.info(\"开始阈值评估实验\")\n",
    "    logging.info(f\"参数设置: n_topics={n_topics}, n_splits={n_splits}, alpha={alpha}\")\n",
    "    \n",
    "    # 对所有参数组合进行网格搜索\n",
    "    total_combinations = len(min_freqs) * len(max_freqs)\n",
    "    \n",
    "    with tqdm(total=total_combinations*n_splits, desc=\"实验进度\") as pbar:\n",
    "        for min_freq, max_freq in product(min_freqs, max_freqs):\n",
    "            if min_freq >= max_freq:\n",
    "                continue\n",
    "                \n",
    "            logging.info(f\"\\n评估阈值组合: min_freq={min_freq}, max_freq={max_freq}\")\n",
    "            fold_results = []\n",
    "            \n",
    "            # K折交叉验证\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(corpus), 1):\n",
    "                try:\n",
    "                    # 构建词典\n",
    "                    train_docs = [corpus[i] for i in train_idx]\n",
    "                    dictionary = Dictionary(train_docs)\n",
    "                    \n",
    "                    # 应用词频过滤\n",
    "                    original_tokens = len(dictionary)\n",
    "                    dictionary.filter_extremes(\n",
    "                        no_below=min_freq,\n",
    "                        no_above=0.5,\n",
    "                        keep_n=max_freq\n",
    "                    )\n",
    "                    filtered_tokens = len(dictionary)\n",
    "                    \n",
    "                    logging.info(f\"词典过滤: {original_tokens} -> {filtered_tokens} 个词\")\n",
    "                    \n",
    "                    # 转换为词袋表示\n",
    "                    corpus_bow = [dictionary.doc2bow(doc) for doc in train_docs]\n",
    "                    \n",
    "                    # 训练LDA模型\n",
    "                    lda = LdaModel(\n",
    "                        corpus=corpus_bow,\n",
    "                        id2word=dictionary,\n",
    "                        num_topics=n_topics,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "                    \n",
    "                    # 计算评估指标\n",
    "                    npmi_score = calculate_npmi(lda, corpus_bow, dictionary, train_docs)\n",
    "                    diversity_score = calculate_diversity(lda)\n",
    "                    \n",
    "                    # 计算optimal score (已标准化的指标)\n",
    "                    optimal_score = alpha * npmi_score + (1 - alpha) * diversity_score\n",
    "                    \n",
    "                    # 获取主题词\n",
    "                    topics = lda.show_topics(formatted=False)\n",
    "                    \n",
    "                    fold_results.append({\n",
    "                        'fold': fold,\n",
    "                        'npmi': npmi_score,\n",
    "                        'diversity': diversity_score,\n",
    "                        'optimal_score': optimal_score,\n",
    "                        'topics': topics\n",
    "                    })\n",
    "                    \n",
    "                    logging.info(f\"第 {fold} 折评估完成: \"\n",
    "                               f\"NPMI={npmi_score:.4f}, \"\n",
    "                               f\"Diversity={diversity_score:.4f}, \"\n",
    "                               f\"Optimal Score={optimal_score:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.error(f\"处理第 {fold} 折时发生错误: {str(e)}\")\n",
    "                    continue\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "            \n",
    "            # 计算平均分数\n",
    "            if fold_results:\n",
    "                avg_scores = {\n",
    "                    'npmi': np.mean([r['npmi'] for r in fold_results]),\n",
    "                    'diversity': np.mean([r['diversity'] for r in fold_results]),\n",
    "                    'optimal_score': np.mean([r['optimal_score'] for r in fold_results])\n",
    "                }\n",
    "                \n",
    "                std_scores = {\n",
    "                    'npmi_std': np.std([r['npmi'] for r in fold_results]),\n",
    "                    'diversity_std': np.std([r['diversity'] for r in fold_results]),\n",
    "                    'optimal_score_std': np.std([r['optimal_score'] for r in fold_results])\n",
    "                }\n",
    "                \n",
    "                results.append({\n",
    "                    'min_freq': min_freq,\n",
    "                    'max_freq': max_freq,\n",
    "                    **avg_scores,\n",
    "                    **std_scores,\n",
    "                    'fold_results': fold_results\n",
    "                })\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    results_df = pd.DataFrame([\n",
    "        {k: v for k, v in r.items() if k != 'fold_results'}\n",
    "        for r in results\n",
    "    ])\n",
    "    \n",
    "    # 找出最佳参数组合\n",
    "    best_idx = results_df['optimal_score'].idxmax()\n",
    "    best_params = {\n",
    "        'min_freq': results_df.loc[best_idx, 'min_freq'],\n",
    "        'max_freq': results_df.loc[best_idx, 'max_freq'],\n",
    "        'optimal_score': results_df.loc[best_idx, 'optimal_score']\n",
    "    }\n",
    "    \n",
    "    return results_df, best_params, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_results(results_df: pd.DataFrame, best_params: Dict, raw_results: List, experiment_dir: str):\n",
    "    \"\"\"保存实验结果\"\"\"\n",
    "    try:\n",
    "        # 1. 保存DataFrame结果\n",
    "        results_df.to_csv(os.path.join(experiment_dir, 'evaluation_results.csv'), index=False)\n",
    "        logging.info(\"已保存评估结果DataFrame\")\n",
    "        \n",
    "        # 2. 保存每折详细结果\n",
    "        fold_results_df = pd.DataFrame([\n",
    "            {\n",
    "                'min_freq': result['min_freq'],\n",
    "                'max_freq': result['max_freq'],\n",
    "                'fold': fold_data['fold'],\n",
    "                'npmi': fold_data['npmi'],\n",
    "                'diversity': fold_data['diversity'],\n",
    "                'optimal_score': fold_data['optimal_score']\n",
    "            }\n",
    "            for result in raw_results\n",
    "            for fold_data in result['fold_results']\n",
    "        ])\n",
    "        fold_results_df.to_csv(os.path.join(experiment_dir, 'fold_results.csv'), index=False)\n",
    "        logging.info(\"已保存每折详细结果\")\n",
    "        \n",
    "        # 3. 保存主题词 - 添加类型转换\n",
    "        topics_dir = os.path.join(experiment_dir, 'topics')\n",
    "        os.makedirs(topics_dir, exist_ok=True)\n",
    "        for result in raw_results:\n",
    "            # 转换fold_results中的数据类型\n",
    "            processed_fold_results = []\n",
    "            for fold_data in result['fold_results']:\n",
    "                processed_fold = {\n",
    "                    'fold': int(fold_data['fold']),\n",
    "                    'npmi': float(fold_data['npmi']),\n",
    "                    'diversity': float(fold_data['diversity']),\n",
    "                    'optimal_score': float(fold_data['optimal_score']),\n",
    "                    'topics': [\n",
    "                        [(str(word), float(score)) for word, score in topic]\n",
    "                        for topic_id, topic in fold_data['topics']\n",
    "                    ]\n",
    "                }\n",
    "                processed_fold_results.append(processed_fold)\n",
    "                \n",
    "            topics_file = os.path.join(\n",
    "                topics_dir,\n",
    "                f'topics_min{int(result[\"min_freq\"])}_max{int(result[\"max_freq\"])}.json'\n",
    "            )\n",
    "            with open(topics_file, 'w') as f:\n",
    "                json.dump(processed_fold_results, f, indent=2)\n",
    "        logging.info(\"已保存主题词结果\")\n",
    "        \n",
    "        # 4. 保存最佳参数 - 添加类型转换\n",
    "        processed_best_params = {\n",
    "            'min_freq': int(best_params['min_freq']),\n",
    "            'max_freq': int(best_params['max_freq']),\n",
    "            'optimal_score': float(best_params['optimal_score'])\n",
    "        }\n",
    "        with open(os.path.join(experiment_dir, 'best_params.json'), 'w') as f:\n",
    "            json.dump(processed_best_params, f, indent=2)\n",
    "        logging.info(\"已保存最佳参数\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"保存结果时发生错误: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(results_df: pd.DataFrame, experiment_dir: str):\n",
    "    \"\"\"生成可视化结果\"\"\"\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        pivot_table = results_df.pivot(\n",
    "            index='min_freq',\n",
    "            columns='max_freq',\n",
    "            values='optimal_score'\n",
    "        )\n",
    "        sns.heatmap(\n",
    "            pivot_table,\n",
    "            annot=True,\n",
    "            fmt='.3f',\n",
    "            cmap='YlOrRd',\n",
    "            cbar_kws={'label': 'Optimal Score'}\n",
    "        )\n",
    "        plt.title('词频阈值组合评估结果')\n",
    "        plt.xlabel('最大词频阈值')\n",
    "        plt.ylabel('最小词频阈值')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
    "        plt.close()\n",
    "        logging.info(\"已保存评估结果热力图\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"生成可视化结果时发生错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: /Users/jessie/Documents/Projects/Cusanus_Topic_Modeling\n",
      "尝试加载目录: experiments/lda/cusanus/preprocessed\n",
      "找到的txt文件: ['h160_013_cleaned.txt', 'h190_264_cleaned.txt', 'h180_167_cleaned.txt', 'h190_214_cleaned.txt', 'h180_149_cleaned.txt', 'h180_139_cleaned.txt', 'h170_065_cleaned.txt', 'h170_107_cleaned.txt', 'h170_098_cleaned.txt', 'h170_084_cleaned.txt', 'h170_079_cleaned.txt', 'h190_226_cleaned.txt', 'h180_125_cleaned.txt', 'h160_021_cleaned.txt', 'h190_256_cleaned.txt', 'h180_155_cleaned.txt', 'h170_057_cleaned.txt', 'h190_208_cleaned.txt', 'h170_027_cleaned.txt', 'h190_278_cleaned.txt', 'h190_285_cleaned.txt', 'h180_186_cleaned.txt', 'h170_042_cleaned.txt', 'h170_120_cleaned.txt', 'h170_032_cleaned.txt', 'h190_290_cleaned.txt', 'h180_193_cleaned.txt', 'h170_091_cleaned.txt', 'h190_233_cleaned.txt', 'h180_130_cleaned.txt', 'h190_243_cleaned.txt', 'h180_140_cleaned.txt', 'h170_070_cleaned.txt', 'h170_112_cleaned.txt', 'h160_006_cleaned.txt', 'h190_271_cleaned.txt', 'h180_172_cleaned.txt', 'h190_246_cleaned.txt', 'h180_145_cleaned.txt', 'h190_236_cleaned.txt', 'h170_069_cleaned.txt', 'h180_135_cleaned.txt', 'h170_094_cleaned.txt', 'h170_037_c_cleaned.txt', 'h180_196_cleaned.txt', 'h190_268_cleaned.txt', 'h170_037_cleaned.txt', 'h190_218_cleaned.txt', 'h170_047_cleaned.txt', 'h190_204_cleaned.txt', 'h180_197_a_cleaned.txt', 'h190_274_cleaned.txt', 'h180_177_cleaned.txt', 'h160_003_cleaned.txt', 'h190_289_cleaned.txt', 'h170_088_cleaned.txt', 'h180_202_cleaned.txt', 'h170_117_cleaned.txt', 'h180_129_cleaned.txt', 'h170_075_cleaned.txt', 'h180_159_cleaned.txt', 'h170_102_cleaned.txt', 'h170_060_cleaned.txt', 'h190_211_cleaned.txt', 'h190_261_cleaned.txt', 'h180_162_cleaned.txt', 'h510_epalb_cleaned.txt', 'h160_016_cleaned.txt', 'h190_280_cleaned.txt', 'h180_183_cleaned.txt', 'h170_052_cleaned.txt', 'h190_253_cleaned.txt', 'h180_150_cleaned.txt', 'h160_024_cleaned.txt', 'h190_223_cleaned.txt', 'h170_081_cleaned.txt', 'h180_153_cleaned.txt', 'h190_250_cleaned.txt', 'h170_082_cleaned.txt', 'h180_123_cleaned.txt', 'h190_220_cleaned.txt', 'h180_180_cleaned.txt', 'h190_283_cleaned.txt', 'h160_009_cleaned.txt', 'h170_051_cleaned.txt', 'h190_212_cleaned.txt', 'h160_015_cleaned.txt', 'h180_161_cleaned.txt', 'h190_262_cleaned.txt', 'h170_063_cleaned.txt', 'h170_101_cleaned.txt', 'h190_229_cleaned.txt', 'h170_076_cleaned.txt', 'h180_201_cleaned.txt', 'h170_114_cleaned.txt', 'h190_259_cleaned.txt', 'h180_197_b_cleaned.txt', 'h190_207_cleaned.txt', 'h170_058_cleaned.txt', 'h180_189_cleaned.txt', 'h180_174_cleaned.txt', 'h190_277_cleaned.txt', 'h170_028_cleaned.txt', 'h170_034_cleaned.txt', 'h180_168_cleaned.txt', 'h180_195_cleaned.txt', 'h170_044_cleaned.txt', 'h180_146_cleaned.txt', 'h190_245_cleaned.txt', 'h170_097_cleaned.txt', 'h170_108_cleaned.txt', 'h180_136_cleaned.txt', 'h190_235_cleaned.txt', 'h180_171_cleaned.txt', 'h190_272_cleaned.txt', 'h160_005_cleaned.txt', 'h170_111_cleaned.txt', 'h170_073_cleaned.txt', 'h180_133_cleaned.txt', 'h190_230_cleaned.txt', 'h170_092_cleaned.txt', 'h180_143_cleaned.txt', 'h190_240_cleaned.txt', 'h170_041_cleaned.txt', 'h180_190_cleaned.txt', 'h160_019_cleaned.txt', 'h190_293_cleaned.txt', 'h170_031_cleaned.txt', 'h170_054_cleaned.txt', 'h180_185_cleaned.txt', 'h190_286_cleaned.txt', 'h180_178_cleaned.txt', 'h180_126_cleaned.txt', 'h190_225_cleaned.txt', 'h170_118_cleaned.txt', 'h170_087_cleaned.txt', 'h180_156_cleaned.txt', 'h190_255_cleaned.txt', 'h160_022_cleaned.txt', 'h190_249_cleaned.txt', 'h170_104_cleaned.txt', 'h170_066_cleaned.txt', 'h190_239_cleaned.txt', 'h180_164_cleaned.txt', 'h170_038_cleaned.txt', 'h190_267_cleaned.txt', 'h160_010_cleaned.txt', 'h180_199_cleaned.txt', 'h170_048_cleaned.txt', 'h190_217_cleaned.txt', 'h170_053_cleaned.txt', 'h180_182_cleaned.txt', 'h190_281_cleaned.txt', 'h170_080_cleaned.txt', 'h190_222_cleaned.txt', 'h160_025_cleaned.txt', 'h180_151_cleaned.txt', 'h190_252_cleaned.txt', 'h180_195_b_cleaned.txt', 'h170_061_cleaned.txt', 'h180_182_b_cleaned.txt', 'h170_103_cleaned.txt', 'h160_017_cleaned.txt', 'h180_163_cleaned.txt', 'h190_260_cleaned.txt', 'h190_210_cleaned.txt', 'h190_288_cleaned.txt', 'h160_002_cleaned.txt', 'h180_176_cleaned.txt', 'h190_275_cleaned.txt', 'h190_205_cleaned.txt', 'h180_158_cleaned.txt', 'h170_074_cleaned.txt', 'h180_128_cleaned.txt', 'h170_116_cleaned.txt', 'h180_203_cleaned.txt', 'h170_089_cleaned.txt', 'h170_037_b_cleaned.txt', 'h170_095_cleaned.txt', 'h180_134_cleaned.txt', 'h170_068_cleaned.txt', 'h190_237_cleaned.txt', 'h180_144_cleaned.txt', 'h190_247_cleaned.txt', 'h170_046_cleaned.txt', 'h190_219_cleaned.txt', 'h170_036_cleaned.txt', 'h190_269_cleaned.txt', 'h180_197_cleaned.txt', 'h170_113_cleaned.txt', 'h170_071_cleaned.txt', 'h160_024_1_cleaned.txt', 'h180_173_cleaned.txt', 'h190_270_cleaned.txt', 'h160_007_cleaned.txt', 'h180_192_cleaned.txt', 'h190_291_cleaned.txt', 'h170_033_cleaned.txt', 'h170_121_cleaned.txt', 'h170_043_cleaned.txt', 'h180_141_cleaned.txt', 'h190_242_cleaned.txt', 'h180_131_cleaned.txt', 'h190_232_cleaned.txt', 'h170_090_cleaned.txt', 'h180_154_cleaned.txt', 'h190_257_cleaned.txt', 'h160_020_cleaned.txt', 'h180_124_cleaned.txt', 'h190_227_cleaned.txt', 'h170_078_cleaned.txt', 'h170_085_cleaned.txt', 'h180_187_cleaned.txt', 'h190_284_cleaned.txt', 'h190_279_cleaned.txt', 'h190_209_cleaned.txt', 'h170_079_b_cleaned.txt', 'h170_056_cleaned.txt', 'h190_215_cleaned.txt', 'h180_166_cleaned.txt', 'h190_265_cleaned.txt', 'h160_012_cleaned.txt', 'h170_099_cleaned.txt', 'h170_106_cleaned.txt', 'h170_064_cleaned.txt', 'h180_138_cleaned.txt', 'h180_148_cleaned.txt', 'h190_238_cleaned.txt', 'h170_067_cleaned.txt', 'h500_ck_cleaned.txt', 'h170_105_cleaned.txt', 'h190_248_cleaned.txt', 'h190_216_cleaned.txt', 'h170_049_cleaned.txt', 'h180_198_cleaned.txt', 'h160_011_cleaned.txt', 'h190_266_cleaned.txt', 'h170_039_cleaned.txt', 'h180_165_cleaned.txt', 'h180_179_cleaned.txt', 'h190_287_cleaned.txt', 'h180_184_cleaned.txt', 'h170_055_cleaned.txt', 'h170_079_a_cleaned.txt', 'h160_023_cleaned.txt', 'h190_254_cleaned.txt', 'h180_157_cleaned.txt', 'h170_086_cleaned.txt', 'h170_119_cleaned.txt', 'h190_224_cleaned.txt', 'h180_127_cleaned.txt', 'h190_241_cleaned.txt', 'h180_142_cleaned.txt', 'h170_093_cleaned.txt', 'h190_231_cleaned.txt', 'h180_132_cleaned.txt', 'h170_030_cleaned.txt', 'h190_292_cleaned.txt', 'h160_018_cleaned.txt', 'h180_191_cleaned.txt', 'h170_040_cleaned.txt', 'h160_024_2_cleaned.txt', 'h160_004_cleaned.txt', 'h190_273_cleaned.txt', 'h180_170_cleaned.txt', 'h170_072_cleaned.txt', 'h170_110_cleaned.txt', 'h170_045_cleaned.txt', 'h180_194_cleaned.txt', 'h180_169_cleaned.txt', 'h170_035_cleaned.txt', 'h190_234_cleaned.txt', 'h180_137_cleaned.txt', 'h170_109_cleaned.txt', 'h170_037_a_cleaned.txt', 'h170_096_cleaned.txt', 'h190_244_cleaned.txt', 'h180_147_cleaned.txt', 'h190_258_cleaned.txt', 'h170_115_cleaned.txt', 'h180_200_cleaned.txt', 'h170_077_cleaned.txt', 'h190_228_cleaned.txt', 'h170_029_cleaned.txt', 'h190_276_cleaned.txt', 'h180_175_cleaned.txt', 'h180_188_cleaned.txt', 'h160_001_cleaned.txt', 'h170_059_cleaned.txt', 'h190_206_cleaned.txt', 'h190_263_cleaned.txt', 'h180_160_cleaned.txt', 'h160_014_cleaned.txt', 'h190_213_cleaned.txt', 'h180_195_a_cleaned.txt', 'h170_100_cleaned.txt', 'h180_182_a_cleaned.txt', 'h170_062_cleaned.txt', 'h190_221_cleaned.txt', 'h180_122_cleaned.txt', 'h170_083_cleaned.txt', 'h190_251_cleaned.txt', 'h180_152_cleaned.txt', 'h160_026_cleaned.txt', 'h170_050_cleaned.txt', 'h160_008_cleaned.txt', 'h190_282_cleaned.txt', 'h180_181_cleaned.txt']\n",
      "\n",
      "处理文件: h160_013_cleaned.txt\n",
      "\n",
      "处理文件: h190_264_cleaned.txt\n",
      "\n",
      "处理文件: h180_167_cleaned.txt\n",
      "\n",
      "处理文件: h190_214_cleaned.txt\n",
      "\n",
      "处理文件: h180_149_cleaned.txt\n",
      "\n",
      "处理文件: h180_139_cleaned.txt\n",
      "\n",
      "处理文件: h170_065_cleaned.txt\n",
      "\n",
      "处理文件: h170_107_cleaned.txt\n",
      "\n",
      "处理文件: h170_098_cleaned.txt\n",
      "\n",
      "处理文件: h170_084_cleaned.txt\n",
      "\n",
      "处理文件: h170_079_cleaned.txt\n",
      "\n",
      "处理文件: h190_226_cleaned.txt\n",
      "\n",
      "处理文件: h180_125_cleaned.txt\n",
      "\n",
      "处理文件: h160_021_cleaned.txt\n",
      "\n",
      "处理文件: h190_256_cleaned.txt\n",
      "\n",
      "处理文件: h180_155_cleaned.txt\n",
      "\n",
      "处理文件: h170_057_cleaned.txt\n",
      "\n",
      "处理文件: h190_208_cleaned.txt\n",
      "\n",
      "处理文件: h170_027_cleaned.txt\n",
      "\n",
      "处理文件: h190_278_cleaned.txt\n",
      "\n",
      "处理文件: h190_285_cleaned.txt\n",
      "\n",
      "处理文件: h180_186_cleaned.txt\n",
      "\n",
      "处理文件: h170_042_cleaned.txt\n",
      "\n",
      "处理文件: h170_120_cleaned.txt\n",
      "\n",
      "处理文件: h170_032_cleaned.txt\n",
      "\n",
      "处理文件: h190_290_cleaned.txt\n",
      "\n",
      "处理文件: h180_193_cleaned.txt\n",
      "\n",
      "处理文件: h170_091_cleaned.txt\n",
      "\n",
      "处理文件: h190_233_cleaned.txt\n",
      "\n",
      "处理文件: h180_130_cleaned.txt\n",
      "\n",
      "处理文件: h190_243_cleaned.txt\n",
      "\n",
      "处理文件: h180_140_cleaned.txt\n",
      "\n",
      "处理文件: h170_070_cleaned.txt\n",
      "\n",
      "处理文件: h170_112_cleaned.txt\n",
      "\n",
      "处理文件: h160_006_cleaned.txt\n",
      "\n",
      "处理文件: h190_271_cleaned.txt\n",
      "\n",
      "处理文件: h180_172_cleaned.txt\n",
      "\n",
      "处理文件: h190_246_cleaned.txt\n",
      "\n",
      "处理文件: h180_145_cleaned.txt\n",
      "\n",
      "处理文件: h190_236_cleaned.txt\n",
      "\n",
      "处理文件: h170_069_cleaned.txt\n",
      "\n",
      "处理文件: h180_135_cleaned.txt\n",
      "\n",
      "处理文件: h170_094_cleaned.txt\n",
      "\n",
      "处理文件: h170_037_c_cleaned.txt\n",
      "\n",
      "处理文件: h180_196_cleaned.txt\n",
      "\n",
      "处理文件: h190_268_cleaned.txt\n",
      "\n",
      "处理文件: h170_037_cleaned.txt\n",
      "\n",
      "处理文件: h190_218_cleaned.txt\n",
      "\n",
      "处理文件: h170_047_cleaned.txt\n",
      "\n",
      "处理文件: h190_204_cleaned.txt\n",
      "\n",
      "处理文件: h180_197_a_cleaned.txt\n",
      "\n",
      "处理文件: h190_274_cleaned.txt\n",
      "\n",
      "处理文件: h180_177_cleaned.txt\n",
      "\n",
      "处理文件: h160_003_cleaned.txt\n",
      "\n",
      "处理文件: h190_289_cleaned.txt\n",
      "\n",
      "处理文件: h170_088_cleaned.txt\n",
      "\n",
      "处理文件: h180_202_cleaned.txt\n",
      "\n",
      "处理文件: h170_117_cleaned.txt\n",
      "\n",
      "处理文件: h180_129_cleaned.txt\n",
      "\n",
      "处理文件: h170_075_cleaned.txt\n",
      "\n",
      "处理文件: h180_159_cleaned.txt\n",
      "\n",
      "处理文件: h170_102_cleaned.txt\n",
      "\n",
      "处理文件: h170_060_cleaned.txt\n",
      "\n",
      "处理文件: h190_211_cleaned.txt\n",
      "\n",
      "处理文件: h190_261_cleaned.txt\n",
      "\n",
      "处理文件: h180_162_cleaned.txt\n",
      "\n",
      "处理文件: h510_epalb_cleaned.txt\n",
      "\n",
      "处理文件: h160_016_cleaned.txt\n",
      "\n",
      "处理文件: h190_280_cleaned.txt\n",
      "\n",
      "处理文件: h180_183_cleaned.txt\n",
      "\n",
      "处理文件: h170_052_cleaned.txt\n",
      "\n",
      "处理文件: h190_253_cleaned.txt\n",
      "\n",
      "处理文件: h180_150_cleaned.txt\n",
      "\n",
      "处理文件: h160_024_cleaned.txt\n",
      "\n",
      "处理文件: h190_223_cleaned.txt\n",
      "\n",
      "处理文件: h170_081_cleaned.txt\n",
      "\n",
      "处理文件: h180_153_cleaned.txt\n",
      "\n",
      "处理文件: h190_250_cleaned.txt\n",
      "\n",
      "处理文件: h170_082_cleaned.txt\n",
      "\n",
      "处理文件: h180_123_cleaned.txt\n",
      "\n",
      "处理文件: h190_220_cleaned.txt\n",
      "\n",
      "处理文件: h180_180_cleaned.txt\n",
      "\n",
      "处理文件: h190_283_cleaned.txt\n",
      "\n",
      "处理文件: h160_009_cleaned.txt\n",
      "\n",
      "处理文件: h170_051_cleaned.txt\n",
      "\n",
      "处理文件: h190_212_cleaned.txt\n",
      "\n",
      "处理文件: h160_015_cleaned.txt\n",
      "\n",
      "处理文件: h180_161_cleaned.txt\n",
      "\n",
      "处理文件: h190_262_cleaned.txt\n",
      "\n",
      "处理文件: h170_063_cleaned.txt\n",
      "\n",
      "处理文件: h170_101_cleaned.txt\n",
      "\n",
      "处理文件: h190_229_cleaned.txt\n",
      "\n",
      "处理文件: h170_076_cleaned.txt\n",
      "\n",
      "处理文件: h180_201_cleaned.txt\n",
      "\n",
      "处理文件: h170_114_cleaned.txt\n",
      "\n",
      "处理文件: h190_259_cleaned.txt\n",
      "\n",
      "处理文件: h180_197_b_cleaned.txt\n",
      "\n",
      "处理文件: h190_207_cleaned.txt\n",
      "\n",
      "处理文件: h170_058_cleaned.txt\n",
      "\n",
      "处理文件: h180_189_cleaned.txt\n",
      "\n",
      "处理文件: h180_174_cleaned.txt\n",
      "\n",
      "处理文件: h190_277_cleaned.txt\n",
      "\n",
      "处理文件: h170_028_cleaned.txt\n",
      "\n",
      "处理文件: h170_034_cleaned.txt\n",
      "\n",
      "处理文件: h180_168_cleaned.txt\n",
      "\n",
      "处理文件: h180_195_cleaned.txt\n",
      "\n",
      "处理文件: h170_044_cleaned.txt\n",
      "\n",
      "处理文件: h180_146_cleaned.txt\n",
      "\n",
      "处理文件: h190_245_cleaned.txt\n",
      "\n",
      "处理文件: h170_097_cleaned.txt\n",
      "\n",
      "处理文件: h170_108_cleaned.txt\n",
      "\n",
      "处理文件: h180_136_cleaned.txt\n",
      "\n",
      "处理文件: h190_235_cleaned.txt\n",
      "\n",
      "处理文件: h180_171_cleaned.txt\n",
      "\n",
      "处理文件: h190_272_cleaned.txt\n",
      "\n",
      "处理文件: h160_005_cleaned.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 21:10:32,267 - INFO - 成功加载语料库，共 4645 个段落\n",
      "2024-11-24 21:10:32,267 - INFO - 开始阈值评估实验\n",
      "2024-11-24 21:10:32,268 - INFO - 参数设置: n_topics=15, n_splits=5, alpha=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理文件: h170_111_cleaned.txt\n",
      "\n",
      "处理文件: h170_073_cleaned.txt\n",
      "\n",
      "处理文件: h180_133_cleaned.txt\n",
      "\n",
      "处理文件: h190_230_cleaned.txt\n",
      "\n",
      "处理文件: h170_092_cleaned.txt\n",
      "\n",
      "处理文件: h180_143_cleaned.txt\n",
      "\n",
      "处理文件: h190_240_cleaned.txt\n",
      "\n",
      "处理文件: h170_041_cleaned.txt\n",
      "\n",
      "处理文件: h180_190_cleaned.txt\n",
      "\n",
      "处理文件: h160_019_cleaned.txt\n",
      "\n",
      "处理文件: h190_293_cleaned.txt\n",
      "\n",
      "处理文件: h170_031_cleaned.txt\n",
      "\n",
      "处理文件: h170_054_cleaned.txt\n",
      "\n",
      "处理文件: h180_185_cleaned.txt\n",
      "\n",
      "处理文件: h190_286_cleaned.txt\n",
      "\n",
      "处理文件: h180_178_cleaned.txt\n",
      "\n",
      "处理文件: h180_126_cleaned.txt\n",
      "\n",
      "处理文件: h190_225_cleaned.txt\n",
      "\n",
      "处理文件: h170_118_cleaned.txt\n",
      "\n",
      "处理文件: h170_087_cleaned.txt\n",
      "\n",
      "处理文件: h180_156_cleaned.txt\n",
      "\n",
      "处理文件: h190_255_cleaned.txt\n",
      "\n",
      "处理文件: h160_022_cleaned.txt\n",
      "\n",
      "处理文件: h190_249_cleaned.txt\n",
      "\n",
      "处理文件: h170_104_cleaned.txt\n",
      "\n",
      "处理文件: h170_066_cleaned.txt\n",
      "\n",
      "处理文件: h190_239_cleaned.txt\n",
      "\n",
      "处理文件: h180_164_cleaned.txt\n",
      "\n",
      "处理文件: h170_038_cleaned.txt\n",
      "\n",
      "处理文件: h190_267_cleaned.txt\n",
      "\n",
      "处理文件: h160_010_cleaned.txt\n",
      "\n",
      "处理文件: h180_199_cleaned.txt\n",
      "\n",
      "处理文件: h170_048_cleaned.txt\n",
      "\n",
      "处理文件: h190_217_cleaned.txt\n",
      "\n",
      "处理文件: h170_053_cleaned.txt\n",
      "\n",
      "处理文件: h180_182_cleaned.txt\n",
      "\n",
      "处理文件: h190_281_cleaned.txt\n",
      "\n",
      "处理文件: h170_080_cleaned.txt\n",
      "\n",
      "处理文件: h190_222_cleaned.txt\n",
      "\n",
      "处理文件: h160_025_cleaned.txt\n",
      "\n",
      "处理文件: h180_151_cleaned.txt\n",
      "\n",
      "处理文件: h190_252_cleaned.txt\n",
      "\n",
      "处理文件: h180_195_b_cleaned.txt\n",
      "\n",
      "处理文件: h170_061_cleaned.txt\n",
      "\n",
      "处理文件: h180_182_b_cleaned.txt\n",
      "\n",
      "处理文件: h170_103_cleaned.txt\n",
      "\n",
      "处理文件: h160_017_cleaned.txt\n",
      "\n",
      "处理文件: h180_163_cleaned.txt\n",
      "\n",
      "处理文件: h190_260_cleaned.txt\n",
      "\n",
      "处理文件: h190_210_cleaned.txt\n",
      "\n",
      "处理文件: h190_288_cleaned.txt\n",
      "\n",
      "处理文件: h160_002_cleaned.txt\n",
      "\n",
      "处理文件: h180_176_cleaned.txt\n",
      "\n",
      "处理文件: h190_275_cleaned.txt\n",
      "\n",
      "处理文件: h190_205_cleaned.txt\n",
      "\n",
      "处理文件: h180_158_cleaned.txt\n",
      "\n",
      "处理文件: h170_074_cleaned.txt\n",
      "\n",
      "处理文件: h180_128_cleaned.txt\n",
      "\n",
      "处理文件: h170_116_cleaned.txt\n",
      "\n",
      "处理文件: h180_203_cleaned.txt\n",
      "\n",
      "处理文件: h170_089_cleaned.txt\n",
      "\n",
      "处理文件: h170_037_b_cleaned.txt\n",
      "\n",
      "处理文件: h170_095_cleaned.txt\n",
      "\n",
      "处理文件: h180_134_cleaned.txt\n",
      "\n",
      "处理文件: h170_068_cleaned.txt\n",
      "\n",
      "处理文件: h190_237_cleaned.txt\n",
      "\n",
      "处理文件: h180_144_cleaned.txt\n",
      "\n",
      "处理文件: h190_247_cleaned.txt\n",
      "\n",
      "处理文件: h170_046_cleaned.txt\n",
      "\n",
      "处理文件: h190_219_cleaned.txt\n",
      "\n",
      "处理文件: h170_036_cleaned.txt\n",
      "\n",
      "处理文件: h190_269_cleaned.txt\n",
      "\n",
      "处理文件: h180_197_cleaned.txt\n",
      "\n",
      "处理文件: h170_113_cleaned.txt\n",
      "\n",
      "处理文件: h170_071_cleaned.txt\n",
      "\n",
      "处理文件: h160_024_1_cleaned.txt\n",
      "\n",
      "处理文件: h180_173_cleaned.txt\n",
      "\n",
      "处理文件: h190_270_cleaned.txt\n",
      "\n",
      "处理文件: h160_007_cleaned.txt\n",
      "\n",
      "处理文件: h180_192_cleaned.txt\n",
      "\n",
      "处理文件: h190_291_cleaned.txt\n",
      "\n",
      "处理文件: h170_033_cleaned.txt\n",
      "\n",
      "处理文件: h170_121_cleaned.txt\n",
      "\n",
      "处理文件: h170_043_cleaned.txt\n",
      "\n",
      "处理文件: h180_141_cleaned.txt\n",
      "\n",
      "处理文件: h190_242_cleaned.txt\n",
      "\n",
      "处理文件: h180_131_cleaned.txt\n",
      "\n",
      "处理文件: h190_232_cleaned.txt\n",
      "\n",
      "处理文件: h170_090_cleaned.txt\n",
      "\n",
      "处理文件: h180_154_cleaned.txt\n",
      "\n",
      "处理文件: h190_257_cleaned.txt\n",
      "\n",
      "处理文件: h160_020_cleaned.txt\n",
      "\n",
      "处理文件: h180_124_cleaned.txt\n",
      "\n",
      "处理文件: h190_227_cleaned.txt\n",
      "\n",
      "处理文件: h170_078_cleaned.txt\n",
      "\n",
      "处理文件: h170_085_cleaned.txt\n",
      "\n",
      "处理文件: h180_187_cleaned.txt\n",
      "\n",
      "处理文件: h190_284_cleaned.txt\n",
      "\n",
      "处理文件: h190_279_cleaned.txt\n",
      "\n",
      "处理文件: h190_209_cleaned.txt\n",
      "\n",
      "处理文件: h170_079_b_cleaned.txt\n",
      "\n",
      "处理文件: h170_056_cleaned.txt\n",
      "\n",
      "处理文件: h190_215_cleaned.txt\n",
      "\n",
      "处理文件: h180_166_cleaned.txt\n",
      "\n",
      "处理文件: h190_265_cleaned.txt\n",
      "\n",
      "处理文件: h160_012_cleaned.txt\n",
      "\n",
      "处理文件: h170_099_cleaned.txt\n",
      "\n",
      "处理文件: h170_106_cleaned.txt\n",
      "\n",
      "处理文件: h170_064_cleaned.txt\n",
      "\n",
      "处理文件: h180_138_cleaned.txt\n",
      "\n",
      "处理文件: h180_148_cleaned.txt\n",
      "\n",
      "处理文件: h190_238_cleaned.txt\n",
      "\n",
      "处理文件: h170_067_cleaned.txt\n",
      "\n",
      "处理文件: h500_ck_cleaned.txt\n",
      "\n",
      "处理文件: h170_105_cleaned.txt\n",
      "\n",
      "处理文件: h190_248_cleaned.txt\n",
      "\n",
      "处理文件: h190_216_cleaned.txt\n",
      "\n",
      "处理文件: h170_049_cleaned.txt\n",
      "\n",
      "处理文件: h180_198_cleaned.txt\n",
      "\n",
      "处理文件: h160_011_cleaned.txt\n",
      "\n",
      "处理文件: h190_266_cleaned.txt\n",
      "\n",
      "处理文件: h170_039_cleaned.txt\n",
      "\n",
      "处理文件: h180_165_cleaned.txt\n",
      "\n",
      "处理文件: h180_179_cleaned.txt\n",
      "\n",
      "处理文件: h190_287_cleaned.txt\n",
      "\n",
      "处理文件: h180_184_cleaned.txt\n",
      "\n",
      "处理文件: h170_055_cleaned.txt\n",
      "\n",
      "处理文件: h170_079_a_cleaned.txt\n",
      "\n",
      "处理文件: h160_023_cleaned.txt\n",
      "\n",
      "处理文件: h190_254_cleaned.txt\n",
      "\n",
      "处理文件: h180_157_cleaned.txt\n",
      "\n",
      "处理文件: h170_086_cleaned.txt\n",
      "\n",
      "处理文件: h170_119_cleaned.txt\n",
      "\n",
      "处理文件: h190_224_cleaned.txt\n",
      "\n",
      "处理文件: h180_127_cleaned.txt\n",
      "\n",
      "处理文件: h190_241_cleaned.txt\n",
      "\n",
      "处理文件: h180_142_cleaned.txt\n",
      "\n",
      "处理文件: h170_093_cleaned.txt\n",
      "\n",
      "处理文件: h190_231_cleaned.txt\n",
      "\n",
      "处理文件: h180_132_cleaned.txt\n",
      "\n",
      "处理文件: h170_030_cleaned.txt\n",
      "\n",
      "处理文件: h190_292_cleaned.txt\n",
      "\n",
      "处理文件: h160_018_cleaned.txt\n",
      "\n",
      "处理文件: h180_191_cleaned.txt\n",
      "\n",
      "处理文件: h170_040_cleaned.txt\n",
      "\n",
      "处理文件: h160_024_2_cleaned.txt\n",
      "\n",
      "处理文件: h160_004_cleaned.txt\n",
      "\n",
      "处理文件: h190_273_cleaned.txt\n",
      "\n",
      "处理文件: h180_170_cleaned.txt\n",
      "\n",
      "处理文件: h170_072_cleaned.txt\n",
      "\n",
      "处理文件: h170_110_cleaned.txt\n",
      "\n",
      "处理文件: h170_045_cleaned.txt\n",
      "\n",
      "处理文件: h180_194_cleaned.txt\n",
      "\n",
      "处理文件: h180_169_cleaned.txt\n",
      "\n",
      "处理文件: h170_035_cleaned.txt\n",
      "\n",
      "处理文件: h190_234_cleaned.txt\n",
      "\n",
      "处理文件: h180_137_cleaned.txt\n",
      "\n",
      "处理文件: h170_109_cleaned.txt\n",
      "\n",
      "处理文件: h170_037_a_cleaned.txt\n",
      "\n",
      "处理文件: h170_096_cleaned.txt\n",
      "\n",
      "处理文件: h190_244_cleaned.txt\n",
      "\n",
      "处理文件: h180_147_cleaned.txt\n",
      "\n",
      "处理文件: h190_258_cleaned.txt\n",
      "\n",
      "处理文件: h170_115_cleaned.txt\n",
      "\n",
      "处理文件: h180_200_cleaned.txt\n",
      "\n",
      "处理文件: h170_077_cleaned.txt\n",
      "\n",
      "处理文件: h190_228_cleaned.txt\n",
      "\n",
      "处理文件: h170_029_cleaned.txt\n",
      "\n",
      "处理文件: h190_276_cleaned.txt\n",
      "\n",
      "处理文件: h180_175_cleaned.txt\n",
      "\n",
      "处理文件: h180_188_cleaned.txt\n",
      "\n",
      "处理文件: h160_001_cleaned.txt\n",
      "\n",
      "处理文件: h170_059_cleaned.txt\n",
      "\n",
      "处理文件: h190_206_cleaned.txt\n",
      "\n",
      "处理文件: h190_263_cleaned.txt\n",
      "\n",
      "处理文件: h180_160_cleaned.txt\n",
      "\n",
      "处理文件: h160_014_cleaned.txt\n",
      "\n",
      "处理文件: h190_213_cleaned.txt\n",
      "\n",
      "处理文件: h180_195_a_cleaned.txt\n",
      "\n",
      "处理文件: h170_100_cleaned.txt\n",
      "\n",
      "处理文件: h180_182_a_cleaned.txt\n",
      "\n",
      "处理文件: h170_062_cleaned.txt\n",
      "\n",
      "处理文件: h190_221_cleaned.txt\n",
      "\n",
      "处理文件: h180_122_cleaned.txt\n",
      "\n",
      "处理文件: h170_083_cleaned.txt\n",
      "\n",
      "处理文件: h190_251_cleaned.txt\n",
      "\n",
      "处理文件: h180_152_cleaned.txt\n",
      "\n",
      "处理文件: h160_026_cleaned.txt\n",
      "\n",
      "处理文件: h170_050_cleaned.txt\n",
      "\n",
      "处理文件: h160_008_cleaned.txt\n",
      "\n",
      "处理文件: h190_282_cleaned.txt\n",
      "\n",
      "处理文件: h180_181_cleaned.txt\n",
      "\n",
      "总共加载了 4645 个段落\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "实验进度:   0%|          | 0/60 [00:00<?, ?it/s]2024-11-24 21:10:32,270 - INFO - \n",
      "评估阈值组合: min_freq=2, max_freq=200\n",
      "2024-11-24 21:10:32,276 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:32,400 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:10:32,401 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:10:32.401050', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:32,406 - INFO - discarding 8639 tokens: [('apocalypsis', 16), ('constantinus', 35), ('corona', 25), ('element', 9), ('expono', 81), ('generalis', 29), ('gloriosus', 75), ('grando', 6), ('ioannes', 83), ('luna', 60)]...\n",
      "2024-11-24 21:10:32,407 - INFO - keeping 200 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:32,416 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'larissa']...>\n",
      "2024-11-24 21:10:32,418 - INFO - 词典过滤: 8839 -> 200 个词\n",
      "2024-11-24 21:10:32,460 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:32,461 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:32,462 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:32,465 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:32,466 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:32,466 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:32,825 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:32,827 - INFO - topic #13 (0.067): 0.067*\"amor\" + 0.037*\"filius\" + 0.031*\"pater\" + 0.025*\"spiritus\" + 0.021*\"clotho\" + 0.021*\"imago\" + 0.020*\"morior\" + 0.020*\"mors\" + 0.018*\"unio\" + 0.017*\"natura\"\n",
      "2024-11-24 21:10:32,828 - INFO - topic #8 (0.067): 0.047*\"virtus\" + 0.033*\"christus\" + 0.028*\"homo\" + 0.025*\"spiritus\" + 0.022*\"delphi\" + 0.022*\"vita\" + 0.020*\"dominus\" + 0.020*\"mens\" + 0.015*\"filius\" + 0.015*\"fides\"\n",
      "2024-11-24 21:10:32,828 - INFO - topic #14 (0.067): 0.098*\"christus\" + 0.055*\"spiritus\" + 0.029*\"vita\" + 0.020*\"homo\" + 0.017*\"fides\" + 0.017*\"filius\" + 0.015*\"mundus\" + 0.014*\"corpus\" + 0.014*\"lex\" + 0.013*\"pater\"\n",
      "2024-11-24 21:10:32,828 - INFO - topic #7 (0.067): 0.058*\"spiritus\" + 0.037*\"delphi\" + 0.025*\"gloria\" + 0.025*\"christus\" + 0.024*\"vita\" + 0.023*\"pater\" + 0.020*\"verbum\" + 0.020*\"motus\" + 0.019*\"filius\" + 0.018*\"divinus\"\n",
      "2024-11-24 21:10:32,829 - INFO - topic #9 (0.067): 0.062*\"dies\" + 0.058*\"christus\" + 0.024*\"mundus\" + 0.022*\"vita\" + 0.017*\"peccatum\" + 0.015*\"regnum\" + 0.015*\"delphi\" + 0.014*\"osdroena\" + 0.014*\"annas\" + 0.014*\"spiritus\"\n",
      "2024-11-24 21:10:32,829 - INFO - topic diff=0.791286, rho=1.000000\n",
      "2024-11-24 21:10:33,186 - INFO - -5.186 per-word bound, 36.4 perplexity estimate based on a held-out corpus of 1716 documents with 45975 words\n",
      "2024-11-24 21:10:33,188 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:33,448 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:33,449 - INFO - topic #12 (0.067): 0.085*\"spiritus\" + 0.044*\"verbum\" + 0.039*\"vita\" + 0.029*\"sanctus\" + 0.024*\"christus\" + 0.022*\"debeo\" + 0.021*\"homo\" + 0.021*\"via\" + 0.020*\"regnum\" + 0.017*\"veritas\"\n",
      "2024-11-24 21:10:33,449 - INFO - topic #6 (0.067): 0.085*\"pater\" + 0.062*\"filius\" + 0.039*\"mundus\" + 0.036*\"venio\" + 0.034*\"lux\" + 0.023*\"sanctus\" + 0.023*\"larissa\" + 0.022*\"christus\" + 0.020*\"rex\" + 0.015*\"cognosco\"\n",
      "2024-11-24 21:10:33,450 - INFO - topic #13 (0.067): 0.082*\"amor\" + 0.039*\"imago\" + 0.039*\"clotho\" + 0.035*\"pater\" + 0.034*\"filius\" + 0.028*\"spiritus\" + 0.024*\"symbatios\" + 0.023*\"unio\" + 0.022*\"morior\" + 0.020*\"sanctus\"\n",
      "2024-11-24 21:10:33,451 - INFO - topic #11 (0.067): 0.056*\"vita\" + 0.038*\"iustitia\" + 0.035*\"homo\" + 0.027*\"natura\" + 0.024*\"vivo\" + 0.022*\"finis\" + 0.017*\"gratia\" + 0.017*\"christus\" + 0.017*\"debeo\" + 0.016*\"filius\"\n",
      "2024-11-24 21:10:33,451 - INFO - topic #0 (0.067): 0.068*\"homo\" + 0.060*\"verbum\" + 0.040*\"nomen\" + 0.033*\"vita\" + 0.026*\"gegen\" + 0.026*\"christus\" + 0.024*\"filius\" + 0.020*\"pater\" + 0.016*\"lux\" + 0.014*\"spiritus\"\n",
      "2024-11-24 21:10:33,452 - INFO - topic diff=0.354127, rho=0.707107\n",
      "2024-11-24 21:10:33,452 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.99s', 'datetime': '2024-11-24T21:10:33.452497', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:33,455 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:33,492 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:10:33,503 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:10:33,512 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:10:33,520 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:10:33,522 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:10:33,524 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:10:33,525 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:10:34,611 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:10:34,635 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:10:34,639 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:10:34,643 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:10:34,645 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:10:34,646 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:10:34,653 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:10:34,657 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:10:34,659 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:10:34,661 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:10:34,663 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:10:34,665 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:10:34,667 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:10:34,669 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:10:34,670 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:10:34,673 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:10:34,677 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:10:34,689 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:10:34,692 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:10:34,701 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:10:34,703 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:10:34,703 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:10:34,714 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:10:34,720 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:10:34,722 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:10:34,726 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:10:34,733 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:10:34,747 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:10:34,750 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:10:34,759 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:10:34,761 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:10:34,768 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:10:34,770 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:10:34,772 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:10:34,784 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:10:34,787 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:10:34,795 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:10:34,802 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:10:34,804 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:10:34,809 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:10:34,812 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:10:34,813 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:10:34,822 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:10:34,828 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:10:34,837 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:10:34,839 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:10:34,845 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:10:34,852 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:10:34,854 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:10:34,859 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:10:34,866 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:10:34,869 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:10:34,967 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:34,997 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:10:35,155 - INFO - 第 1 折评估完成: NPMI=0.4980, Diversity=0.4400, Optimal Score=0.4690\n",
      "实验进度:   2%|▏         | 1/60 [00:02<02:50,  2.89s/it]2024-11-24 21:10:35,157 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:35,238 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:10:35,238 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:10:35.238831', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:35,242 - INFO - discarding 8696 tokens: [('aaron', 7), ('asper', 8), ('conservo', 66), ('constantinus', 39), ('contritio', 22), ('conversatio', 28), ('correctio', 22), ('crux', 115), ('divinitas', 67), ('dormio', 34)]...\n",
      "2024-11-24 21:10:35,243 - INFO - keeping 200 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:35,244 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'divinus']...>\n",
      "2024-11-24 21:10:35,244 - INFO - 词典过滤: 8896 -> 200 个词\n",
      "2024-11-24 21:10:35,294 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:35,295 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:35,295 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:35,296 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:35,296 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:35,297 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:35,602 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:35,603 - INFO - topic #13 (0.067): 0.042*\"homo\" + 0.042*\"vita\" + 0.041*\"spiritus\" + 0.033*\"filius\" + 0.022*\"natura\" + 0.022*\"amor\" + 0.021*\"regnum\" + 0.017*\"delphi\" + 0.017*\"pater\" + 0.017*\"unitas\"\n",
      "2024-11-24 21:10:35,603 - INFO - topic #8 (0.067): 0.062*\"christus\" + 0.045*\"verbum\" + 0.036*\"delphi\" + 0.022*\"intellego\" + 0.021*\"vita\" + 0.020*\"virtus\" + 0.019*\"homo\" + 0.019*\"corpus\" + 0.018*\"ratio\" + 0.017*\"bonus\"\n",
      "2024-11-24 21:10:35,604 - INFO - topic #14 (0.067): 0.056*\"verbum\" + 0.034*\"christus\" + 0.034*\"pax\" + 0.027*\"spiritus\" + 0.020*\"vita\" + 0.018*\"homo\" + 0.017*\"motus\" + 0.017*\"recipio\" + 0.015*\"sanctus\" + 0.013*\"semen\"\n",
      "2024-11-24 21:10:35,604 - INFO - topic #7 (0.067): 0.042*\"christus\" + 0.027*\"venio\" + 0.022*\"homo\" + 0.021*\"debeo\" + 0.021*\"sapientia\" + 0.020*\"filius\" + 0.019*\"pater\" + 0.019*\"tempus\" + 0.019*\"spiritus\" + 0.018*\"mundus\"\n",
      "2024-11-24 21:10:35,605 - INFO - topic #9 (0.067): 0.040*\"vita\" + 0.033*\"christus\" + 0.030*\"homo\" + 0.028*\"spiritus\" + 0.025*\"delphi\" + 0.022*\"lux\" + 0.019*\"virtus\" + 0.018*\"scio\" + 0.016*\"fides\" + 0.015*\"filius\"\n",
      "2024-11-24 21:10:35,605 - INFO - topic diff=0.766767, rho=1.000000\n",
      "2024-11-24 21:10:35,905 - INFO - -5.191 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 1716 documents with 46207 words\n",
      "2024-11-24 21:10:35,906 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:36,159 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:36,160 - INFO - topic #12 (0.067): 0.081*\"homo\" + 0.057*\"mundus\" + 0.047*\"dies\" + 0.042*\"veritas\" + 0.028*\"quaero\" + 0.025*\"vita\" + 0.021*\"credo\" + 0.018*\"christus\" + 0.017*\"scio\" + 0.013*\"bonus\"\n",
      "2024-11-24 21:10:36,160 - INFO - topic #6 (0.067): 0.048*\"gratia\" + 0.044*\"delphi\" + 0.028*\"homo\" + 0.027*\"natura\" + 0.027*\"dies\" + 0.026*\"dominus\" + 0.024*\"fides\" + 0.023*\"christus\" + 0.019*\"virgo\" + 0.018*\"vita\"\n",
      "2024-11-24 21:10:36,161 - INFO - topic #13 (0.067): 0.051*\"vita\" + 0.045*\"spiritus\" + 0.042*\"homo\" + 0.037*\"amor\" + 0.028*\"natura\" + 0.028*\"filius\" + 0.026*\"regnum\" + 0.020*\"unitas\" + 0.019*\"panis\" + 0.017*\"delphi\"\n",
      "2024-11-24 21:10:36,161 - INFO - topic #11 (0.067): 0.137*\"spiritus\" + 0.037*\"sanctus\" + 0.028*\"motus\" + 0.027*\"mundus\" + 0.023*\"veritas\" + 0.022*\"domus\" + 0.019*\"dominus\" + 0.018*\"virtus\" + 0.018*\"christus\" + 0.017*\"osdroena\"\n",
      "2024-11-24 21:10:36,161 - INFO - topic #0 (0.067): 0.046*\"gegen\" + 0.044*\"intellectus\" + 0.035*\"lux\" + 0.031*\"ratio\" + 0.027*\"delphi\" + 0.026*\"mundus\" + 0.020*\"veritas\" + 0.019*\"sol\" + 0.019*\"virtus\" + 0.019*\"spiritus\"\n",
      "2024-11-24 21:10:36,162 - INFO - topic diff=0.350584, rho=0.707107\n",
      "2024-11-24 21:10:36,162 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.87s', 'datetime': '2024-11-24T21:10:36.162369', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:36,164 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:36,204 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:10:36,207 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:10:36,210 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:10:36,211 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:10:36,213 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:10:36,214 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:10:36,221 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:10:37,161 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:10:37,164 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:10:37,185 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:10:37,187 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:10:37,190 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:10:37,192 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:10:37,194 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:10:37,199 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:10:37,216 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:10:37,243 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:10:37,246 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:10:37,248 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:10:37,249 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:10:37,251 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:10:37,253 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:10:37,255 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:10:37,260 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:10:37,262 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:10:37,265 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:10:37,268 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:10:37,271 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:10:37,273 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:10:37,276 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:10:37,277 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:10:37,279 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:10:37,287 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:10:37,290 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:10:37,292 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:10:37,293 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:10:37,295 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:10:37,298 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:10:37,309 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:10:37,317 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:10:37,319 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:10:37,321 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:10:37,323 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:10:37,325 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:10:37,326 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:10:37,328 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:10:37,344 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:10:37,346 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:10:37,348 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:10:37,355 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:10:37,363 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:10:37,370 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:10:37,375 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:10:37,378 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:10:37,380 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:10:37,391 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:10:37,394 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:10:37,397 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:10:37,402 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:10:37,497 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:37,505 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:10:37,688 - INFO - 第 2 折评估完成: NPMI=0.4980, Diversity=0.4467, Optimal Score=0.4724\n",
      "实验进度:   3%|▎         | 2/60 [00:05<02:35,  2.68s/it]2024-11-24 21:10:37,690 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:37,776 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:10:37,776 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:10:37.776876', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:37,782 - INFO - discarding 8634 tokens: [('apocalypsis', 13), ('behalten', 129), ('constantinus', 33), ('corona', 28), ('element', 9), ('expono', 80), ('generalis', 26), ('gloriosus', 72), ('grando', 6), ('ioannes', 89)]...\n",
      "2024-11-24 21:10:37,783 - INFO - keeping 200 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:37,785 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:10:37,785 - INFO - 词典过滤: 8834 -> 200 个词\n",
      "2024-11-24 21:10:37,826 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:37,826 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:37,827 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:37,827 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:37,828 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:37,828 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:38,134 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:38,135 - INFO - topic #13 (0.067): 0.040*\"amor\" + 0.038*\"delphi\" + 0.024*\"clotho\" + 0.023*\"filius\" + 0.022*\"pater\" + 0.021*\"vita\" + 0.018*\"verbum\" + 0.017*\"peccatum\" + 0.016*\"spiritus\" + 0.016*\"corpus\"\n",
      "2024-11-24 21:10:38,135 - INFO - topic #8 (0.067): 0.046*\"christus\" + 0.037*\"virtus\" + 0.031*\"debeo\" + 0.029*\"spiritus\" + 0.026*\"homo\" + 0.018*\"delphi\" + 0.016*\"sapientia\" + 0.016*\"vita\" + 0.015*\"pater\" + 0.015*\"verbum\"\n",
      "2024-11-24 21:10:38,136 - INFO - topic #14 (0.067): 0.072*\"christus\" + 0.064*\"spiritus\" + 0.033*\"vita\" + 0.030*\"fides\" + 0.019*\"mundus\" + 0.018*\"homo\" + 0.018*\"debeo\" + 0.014*\"volo\" + 0.014*\"verbum\" + 0.014*\"intellectus\"\n",
      "2024-11-24 21:10:38,136 - INFO - topic #7 (0.067): 0.054*\"spiritus\" + 0.026*\"regnum\" + 0.025*\"christus\" + 0.023*\"verbum\" + 0.023*\"mundus\" + 0.021*\"gloria\" + 0.020*\"filius\" + 0.020*\"vita\" + 0.020*\"motus\" + 0.017*\"sanctus\"\n",
      "2024-11-24 21:10:38,136 - INFO - topic #9 (0.067): 0.113*\"dies\" + 0.025*\"vita\" + 0.022*\"gratia\" + 0.019*\"iustitia\" + 0.018*\"semen\" + 0.017*\"sapientia\" + 0.017*\"annas\" + 0.017*\"mors\" + 0.016*\"reperio\" + 0.016*\"christus\"\n",
      "2024-11-24 21:10:38,137 - INFO - topic diff=0.781915, rho=1.000000\n",
      "2024-11-24 21:10:38,832 - INFO - -5.190 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 1716 documents with 45705 words\n",
      "2024-11-24 21:10:38,872 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:39,197 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:39,198 - INFO - topic #12 (0.067): 0.073*\"spiritus\" + 0.070*\"vita\" + 0.030*\"homo\" + 0.025*\"natura\" + 0.024*\"christus\" + 0.022*\"unio\" + 0.021*\"verbum\" + 0.020*\"delphi\" + 0.018*\"rationalis\" + 0.017*\"corpus\"\n",
      "2024-11-24 21:10:39,199 - INFO - topic #6 (0.067): 0.085*\"lux\" + 0.046*\"fides\" + 0.036*\"tenebrae\" + 0.030*\"intellectus\" + 0.030*\"veritas\" + 0.025*\"verus\" + 0.023*\"gegen\" + 0.023*\"ratio\" + 0.020*\"sol\" + 0.019*\"credo\"\n",
      "2024-11-24 21:10:39,199 - INFO - topic #13 (0.067): 0.056*\"amor\" + 0.045*\"delphi\" + 0.035*\"clotho\" + 0.029*\"peccatum\" + 0.023*\"symbatios\" + 0.022*\"filius\" + 0.021*\"pater\" + 0.020*\"diligo\" + 0.019*\"spiritus\" + 0.019*\"corpus\"\n",
      "2024-11-24 21:10:39,199 - INFO - topic #11 (0.067): 0.047*\"christus\" + 0.026*\"natura\" + 0.026*\"vita\" + 0.025*\"domus\" + 0.019*\"delphi\" + 0.018*\"homo\" + 0.018*\"sapientia\" + 0.017*\"via\" + 0.017*\"verbum\" + 0.017*\"tempus\"\n",
      "2024-11-24 21:10:39,200 - INFO - topic #0 (0.067): 0.098*\"homo\" + 0.040*\"ars\" + 0.028*\"forma\" + 0.023*\"christus\" + 0.023*\"vita\" + 0.019*\"perfectus\" + 0.018*\"natura\" + 0.018*\"iustitia\" + 0.018*\"mundus\" + 0.016*\"pater\"\n",
      "2024-11-24 21:10:39,200 - INFO - topic diff=0.359364, rho=0.707107\n",
      "2024-11-24 21:10:39,200 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 1.37s', 'datetime': '2024-11-24T21:10:39.200728', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:39,203 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:39,264 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:10:39,267 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:10:39,268 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:10:39,273 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:10:39,277 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:10:39,279 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:10:39,310 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:10:40,024 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:10:40,038 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:10:40,078 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:10:40,109 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:10:40,145 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:10:40,191 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:10:40,193 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:10:40,199 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:10:40,206 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:10:40,215 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:10:40,219 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:10:40,225 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:10:40,239 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:10:40,292 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:10:40,296 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:10:40,300 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:10:40,304 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:10:40,307 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:10:40,309 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:10:40,317 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:10:40,326 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:10:40,335 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:10:40,352 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:10:40,354 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:10:40,395 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:10:40,419 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:10:40,461 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:10:40,465 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:10:40,471 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:10:40,475 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:10:40,477 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:10:40,479 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:10:40,498 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:10:40,518 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:10:40,521 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:10:40,528 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:10:40,538 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:10:40,540 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:10:40,542 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:10:40,543 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:10:40,544 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:10:40,545 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:10:40,546 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:10:40,548 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:10:40,549 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:10:40,550 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:10:40,551 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:10:40,560 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:10:40,561 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:10:40,575 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:10:40,581 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:10:40,586 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:10:40,676 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:40,693 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:10:40,857 - INFO - 第 3 折评估完成: NPMI=0.4985, Diversity=0.4733, Optimal Score=0.4859\n",
      "实验进度:   5%|▌         | 3/60 [00:08<02:45,  2.90s/it]2024-11-24 21:10:40,859 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:40,939 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:10:40,940 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:10:40.940370', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:40,943 - INFO - discarding 8685 tokens: [('apocalypsis', 14), ('behalten', 118), ('constantinus', 30), ('corona', 26), ('element', 6), ('expono', 79), ('generalis', 25), ('gloriosus', 80), ('grando', 3), ('ioannes', 87)]...\n",
      "2024-11-24 21:10:40,944 - INFO - keeping 200 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:40,945 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:10:40,945 - INFO - 词典过滤: 8885 -> 200 个词\n",
      "2024-11-24 21:10:40,984 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:40,985 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:40,985 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:40,986 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:40,986 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:40,986 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:41,297 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:41,298 - INFO - topic #13 (0.067): 0.034*\"pater\" + 0.030*\"verbum\" + 0.026*\"spiritus\" + 0.024*\"regnum\" + 0.022*\"ars\" + 0.019*\"annas\" + 0.018*\"unitas\" + 0.018*\"natura\" + 0.017*\"finis\" + 0.017*\"sanctus\"\n",
      "2024-11-24 21:10:41,298 - INFO - topic #8 (0.067): 0.051*\"christus\" + 0.048*\"corpus\" + 0.038*\"homo\" + 0.032*\"delphi\" + 0.023*\"ecclesia\" + 0.023*\"spiritus\" + 0.017*\"sapientia\" + 0.016*\"peccatum\" + 0.014*\"vita\" + 0.013*\"locus\"\n",
      "2024-11-24 21:10:41,298 - INFO - topic #14 (0.067): 0.076*\"spiritus\" + 0.039*\"christus\" + 0.035*\"vita\" + 0.025*\"delphi\" + 0.021*\"mundus\" + 0.020*\"homo\" + 0.020*\"osdroena\" + 0.019*\"mors\" + 0.018*\"filius\" + 0.017*\"fides\"\n",
      "2024-11-24 21:10:41,299 - INFO - topic #7 (0.067): 0.057*\"vita\" + 0.047*\"christus\" + 0.032*\"spiritus\" + 0.027*\"verbum\" + 0.022*\"filius\" + 0.020*\"iustitia\" + 0.019*\"fides\" + 0.018*\"mors\" + 0.016*\"pax\" + 0.015*\"veritas\"\n",
      "2024-11-24 21:10:41,299 - INFO - topic #9 (0.067): 0.055*\"dies\" + 0.043*\"pater\" + 0.040*\"filius\" + 0.031*\"christus\" + 0.027*\"spiritus\" + 0.023*\"sapientia\" + 0.023*\"homo\" + 0.022*\"vita\" + 0.021*\"unio\" + 0.015*\"opus\"\n",
      "2024-11-24 21:10:41,299 - INFO - topic diff=0.759201, rho=1.000000\n",
      "2024-11-24 21:10:41,605 - INFO - -5.177 per-word bound, 36.2 perplexity estimate based on a held-out corpus of 1716 documents with 46027 words\n",
      "2024-11-24 21:10:41,605 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:41,858 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:41,859 - INFO - topic #12 (0.067): 0.053*\"gegen\" + 0.040*\"lux\" + 0.036*\"veritas\" + 0.035*\"intellectus\" + 0.026*\"ratio\" + 0.025*\"christus\" + 0.022*\"natura\" + 0.019*\"verbum\" + 0.018*\"sensibilis\" + 0.018*\"motus\"\n",
      "2024-11-24 21:10:41,859 - INFO - topic #6 (0.067): 0.061*\"virtus\" + 0.033*\"spiritus\" + 0.027*\"larissa\" + 0.026*\"homo\" + 0.024*\"principium\" + 0.023*\"natura\" + 0.022*\"terra\" + 0.022*\"finis\" + 0.021*\"veritas\" + 0.020*\"creo\"\n",
      "2024-11-24 21:10:41,859 - INFO - topic #13 (0.067): 0.053*\"ars\" + 0.052*\"pater\" + 0.038*\"verbum\" + 0.033*\"nomen\" + 0.030*\"annas\" + 0.028*\"regnum\" + 0.026*\"sanctus\" + 0.022*\"natura\" + 0.021*\"spiritus\" + 0.021*\"unitas\"\n",
      "2024-11-24 21:10:41,860 - INFO - topic #11 (0.067): 0.057*\"vita\" + 0.040*\"delphi\" + 0.031*\"spiritus\" + 0.030*\"amor\" + 0.028*\"sanctus\" + 0.024*\"gratia\" + 0.024*\"symbatios\" + 0.019*\"cognosco\" + 0.019*\"clotho\" + 0.019*\"christus\"\n",
      "2024-11-24 21:10:41,860 - INFO - topic #0 (0.067): 0.077*\"christus\" + 0.071*\"panis\" + 0.032*\"forma\" + 0.029*\"nomen\" + 0.028*\"gaudium\" + 0.024*\"verbum\" + 0.024*\"natura\" + 0.023*\"bonus\" + 0.022*\"pater\" + 0.022*\"reperio\"\n",
      "2024-11-24 21:10:41,860 - INFO - topic diff=0.362373, rho=0.707107\n",
      "2024-11-24 21:10:41,861 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.87s', 'datetime': '2024-11-24T21:10:41.861106', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:41,863 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:41,900 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:10:41,903 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:10:41,905 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:10:41,914 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:10:42,006 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:10:42,009 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:10:42,011 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:10:42,814 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:10:42,828 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:10:42,830 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:10:42,841 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:10:42,843 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:10:42,845 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:10:42,846 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:10:42,850 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:10:42,851 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:10:42,862 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:10:42,866 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:10:42,868 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:10:42,869 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:10:42,871 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:10:42,875 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:10:42,885 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:10:42,886 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:10:42,888 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:10:42,896 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:10:42,897 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:10:42,899 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:10:42,901 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:10:42,908 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:10:42,912 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:10:42,916 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:10:42,918 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:10:42,922 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:10:42,927 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:10:42,933 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:10:42,940 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:10:42,943 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:10:42,944 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:10:42,946 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:10:42,948 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:10:42,954 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:10:42,964 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:10:42,965 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:10:42,969 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:10:42,972 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:10:42,975 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:10:42,977 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:10:42,978 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:10:42,986 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:10:42,988 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:10:42,996 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:10:42,997 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:10:42,999 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:10:43,007 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:10:43,008 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:10:43,010 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:10:43,018 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:10:43,023 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:10:43,089 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:43,095 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:10:43,266 - INFO - 第 4 折评估完成: NPMI=0.4990, Diversity=0.4600, Optimal Score=0.4795\n",
      "实验进度:   7%|▋         | 4/60 [00:10<02:31,  2.71s/it]2024-11-24 21:10:43,267 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:43,342 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:10:43,343 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:10:43.343014', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:43,346 - INFO - discarding 8703 tokens: [('apocalypsis', 15), ('behalten', 127), ('constantinus', 35), ('corona', 26), ('element', 9), ('expono', 80), ('generalis', 24), ('gloriosus', 77), ('grando', 7), ('ioannes', 98)]...\n",
      "2024-11-24 21:10:43,346 - INFO - keeping 200 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:43,347 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:10:43,348 - INFO - 词典过滤: 8903 -> 200 个词\n",
      "2024-11-24 21:10:43,384 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:43,384 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:43,385 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:43,385 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:43,386 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:43,386 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:43,689 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:43,689 - INFO - topic #13 (0.067): 0.036*\"lux\" + 0.034*\"vita\" + 0.030*\"christus\" + 0.020*\"gegen\" + 0.020*\"verbum\" + 0.019*\"homo\" + 0.018*\"veritas\" + 0.017*\"vivo\" + 0.017*\"evangelium\" + 0.017*\"spiritus\"\n",
      "2024-11-24 21:10:43,690 - INFO - topic #8 (0.067): 0.048*\"christus\" + 0.032*\"debeo\" + 0.027*\"veritas\" + 0.023*\"nomen\" + 0.022*\"filius\" + 0.020*\"homo\" + 0.019*\"virtus\" + 0.018*\"lex\" + 0.018*\"delphi\" + 0.017*\"gratia\"\n",
      "2024-11-24 21:10:43,690 - INFO - topic #14 (0.067): 0.089*\"christus\" + 0.055*\"spiritus\" + 0.031*\"fides\" + 0.027*\"homo\" + 0.019*\"filius\" + 0.019*\"verbum\" + 0.018*\"vita\" + 0.015*\"virtus\" + 0.012*\"debeo\" + 0.012*\"volo\"\n",
      "2024-11-24 21:10:43,690 - INFO - topic #7 (0.067): 0.043*\"virtus\" + 0.037*\"verbum\" + 0.035*\"christus\" + 0.030*\"spiritus\" + 0.029*\"regnum\" + 0.021*\"delphi\" + 0.018*\"unio\" + 0.017*\"natura\" + 0.016*\"filius\" + 0.016*\"lex\"\n",
      "2024-11-24 21:10:43,691 - INFO - topic #9 (0.067): 0.037*\"pater\" + 0.026*\"sapientia\" + 0.024*\"intellectus\" + 0.024*\"rex\" + 0.023*\"christus\" + 0.020*\"debeo\" + 0.019*\"virtus\" + 0.019*\"homo\" + 0.018*\"delphi\" + 0.017*\"venio\"\n",
      "2024-11-24 21:10:43,691 - INFO - topic diff=0.738142, rho=1.000000\n",
      "2024-11-24 21:10:43,990 - INFO - -5.203 per-word bound, 36.8 perplexity estimate based on a held-out corpus of 1716 documents with 45842 words\n",
      "2024-11-24 21:10:43,990 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:44,241 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:44,241 - INFO - topic #12 (0.067): 0.080*\"filius\" + 0.077*\"pater\" + 0.036*\"homo\" + 0.032*\"christus\" + 0.031*\"natura\" + 0.026*\"mundus\" + 0.023*\"spiritus\" + 0.020*\"verbum\" + 0.019*\"venio\" + 0.017*\"veritas\"\n",
      "2024-11-24 21:10:44,241 - INFO - topic #6 (0.067): 0.064*\"dies\" + 0.047*\"spiritus\" + 0.032*\"ratio\" + 0.031*\"delphi\" + 0.028*\"dominus\" + 0.023*\"fides\" + 0.019*\"debeo\" + 0.018*\"osdroena\" + 0.018*\"sanctus\" + 0.016*\"homo\"\n",
      "2024-11-24 21:10:44,242 - INFO - topic #13 (0.067): 0.040*\"lux\" + 0.030*\"christus\" + 0.028*\"quaero\" + 0.028*\"vita\" + 0.025*\"evangelium\" + 0.025*\"gegen\" + 0.022*\"doctrina\" + 0.021*\"pars\" + 0.020*\"veritas\" + 0.017*\"primo\"\n",
      "2024-11-24 21:10:44,242 - INFO - topic #11 (0.067): 0.058*\"amor\" + 0.045*\"symbatios\" + 0.040*\"clotho\" + 0.037*\"filius\" + 0.033*\"spiritus\" + 0.031*\"christus\" + 0.030*\"pater\" + 0.023*\"diligo\" + 0.020*\"delphi\" + 0.019*\"mater\"\n",
      "2024-11-24 21:10:44,243 - INFO - topic #0 (0.067): 0.036*\"christus\" + 0.028*\"homo\" + 0.026*\"finis\" + 0.026*\"tenebrae\" + 0.023*\"volo\" + 0.022*\"mundus\" + 0.022*\"recipio\" + 0.021*\"spiritus\" + 0.017*\"vita\" + 0.017*\"debeo\"\n",
      "2024-11-24 21:10:44,243 - INFO - topic diff=0.333727, rho=0.707107\n",
      "2024-11-24 21:10:44,243 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.86s', 'datetime': '2024-11-24T21:10:44.243605', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:44,245 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:44,294 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:10:44,297 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:10:44,299 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:10:44,303 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:10:44,429 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:10:44,430 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:10:44,431 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:10:45,374 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:10:45,384 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:10:45,405 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:10:45,429 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:10:45,431 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:10:45,432 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:10:45,434 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:10:45,444 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:10:45,453 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:10:45,460 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:10:45,471 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:10:45,481 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:10:45,493 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:10:45,494 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:10:45,499 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:10:45,502 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:10:45,505 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:10:45,511 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:10:45,518 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:10:45,522 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:10:45,523 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:10:45,524 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:10:45,529 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:10:45,548 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:10:45,555 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:10:45,563 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:10:45,566 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:10:45,578 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:10:45,579 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:10:45,582 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:10:45,583 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:10:45,598 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:10:45,601 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:10:45,609 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:10:45,620 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:10:45,621 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:10:45,627 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:10:45,633 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:10:45,634 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:10:45,639 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:10:45,647 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:10:45,654 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:10:45,659 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:10:45,661 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:10:45,663 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:10:45,675 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:10:45,680 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:10:45,683 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:10:45,686 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:10:45,688 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:10:45,699 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:10:45,700 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:10:45,830 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:45,873 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:10:46,031 - INFO - 第 5 折评估完成: NPMI=0.4970, Diversity=0.4533, Optimal Score=0.4752\n",
      "实验进度:   8%|▊         | 5/60 [00:13<02:30,  2.73s/it]2024-11-24 21:10:46,032 - INFO - \n",
      "评估阈值组合: min_freq=2, max_freq=800\n",
      "2024-11-24 21:10:46,034 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:46,110 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:10:46,110 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:10:46.110638', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:46,114 - INFO - discarding 8039 tokens: [('apocalypsis', 16), ('constantinus', 35), ('corona', 25), ('element', 9), ('generalis', 29), ('grando', 6), ('principalis', 18), ('specialis', 14), ('terraemotus', 5), ('aaron', 7)]...\n",
      "2024-11-24 21:10:46,114 - INFO - keeping 800 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:46,115 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:10:46,115 - INFO - 词典过滤: 8839 -> 800 个词\n",
      "2024-11-24 21:10:46,160 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:46,160 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:46,160 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:46,161 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:46,162 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:46,162 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:46,537 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:46,538 - INFO - topic #6 (0.067): 0.022*\"spiritus\" + 0.021*\"virtus\" + 0.017*\"christus\" + 0.017*\"delphi\" + 0.016*\"vita\" + 0.016*\"homo\" + 0.015*\"corpus\" + 0.014*\"verbum\" + 0.012*\"natura\" + 0.011*\"ratio\"\n",
      "2024-11-24 21:10:46,539 - INFO - topic #13 (0.067): 0.047*\"christus\" + 0.022*\"homo\" + 0.021*\"pater\" + 0.020*\"filius\" + 0.019*\"vita\" + 0.015*\"verbum\" + 0.013*\"virtus\" + 0.012*\"panis\" + 0.011*\"spiritus\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:10:46,539 - INFO - topic #12 (0.067): 0.030*\"spiritus\" + 0.024*\"fides\" + 0.023*\"vita\" + 0.018*\"sanctus\" + 0.017*\"verbum\" + 0.015*\"filius\" + 0.012*\"christus\" + 0.011*\"pater\" + 0.010*\"homo\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:10:46,539 - INFO - topic #10 (0.067): 0.025*\"christus\" + 0.022*\"delphi\" + 0.021*\"fides\" + 0.019*\"spiritus\" + 0.017*\"mundus\" + 0.013*\"verbum\" + 0.011*\"lux\" + 0.010*\"natura\" + 0.009*\"vita\" + 0.009*\"filius\"\n",
      "2024-11-24 21:10:46,540 - INFO - topic #2 (0.067): 0.024*\"spiritus\" + 0.023*\"homo\" + 0.021*\"vita\" + 0.017*\"christus\" + 0.011*\"ratio\" + 0.011*\"sapientia\" + 0.010*\"dominus\" + 0.009*\"gratia\" + 0.009*\"mundus\" + 0.009*\"verbum\"\n",
      "2024-11-24 21:10:46,540 - INFO - topic diff=1.635696, rho=1.000000\n",
      "2024-11-24 21:10:46,915 - INFO - -6.440 per-word bound, 86.8 perplexity estimate based on a held-out corpus of 1716 documents with 72713 words\n",
      "2024-11-24 21:10:46,915 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:47,237 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:47,238 - INFO - topic #10 (0.067): 0.030*\"fides\" + 0.024*\"christus\" + 0.023*\"delphi\" + 0.017*\"spiritus\" + 0.016*\"lux\" + 0.015*\"mundus\" + 0.013*\"natura\" + 0.013*\"gegen\" + 0.013*\"gratia\" + 0.011*\"verbum\"\n",
      "2024-11-24 21:10:47,238 - INFO - topic #1 (0.067): 0.035*\"christus\" + 0.022*\"sanctus\" + 0.019*\"dies\" + 0.014*\"spiritus\" + 0.012*\"lex\" + 0.012*\"mater\" + 0.011*\"evangelium\" + 0.011*\"ecclesia\" + 0.009*\"debeo\" + 0.008*\"osdroena\"\n",
      "2024-11-24 21:10:47,238 - INFO - topic #2 (0.067): 0.031*\"homo\" + 0.021*\"vita\" + 0.017*\"spiritus\" + 0.014*\"christus\" + 0.014*\"peccatum\" + 0.013*\"mors\" + 0.013*\"ratio\" + 0.012*\"dominus\" + 0.012*\"gratia\" + 0.011*\"sapientia\"\n",
      "2024-11-24 21:10:47,238 - INFO - topic #11 (0.067): 0.028*\"vita\" + 0.022*\"clotho\" + 0.020*\"lux\" + 0.019*\"delphi\" + 0.019*\"amor\" + 0.016*\"iustitia\" + 0.014*\"vivo\" + 0.013*\"homo\" + 0.012*\"venio\" + 0.011*\"gegen\"\n",
      "2024-11-24 21:10:47,239 - INFO - topic #0 (0.067): 0.040*\"natura\" + 0.022*\"homo\" + 0.020*\"sapientia\" + 0.016*\"creo\" + 0.013*\"vita\" + 0.013*\"gloria\" + 0.012*\"ada\" + 0.011*\"rex\" + 0.011*\"humanus\" + 0.011*\"locus\"\n",
      "2024-11-24 21:10:47,239 - INFO - topic diff=0.615809, rho=0.707107\n",
      "2024-11-24 21:10:47,239 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.08s', 'datetime': '2024-11-24T21:10:47.239761', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:47,242 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:47,295 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:10:47,525 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:10:47,550 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:10:47,552 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:10:47,554 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:10:47,555 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:10:47,557 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:10:48,173 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:10:48,214 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:10:48,236 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:10:48,240 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:10:48,250 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:10:48,265 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:10:48,275 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:10:48,280 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:10:48,282 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:10:48,292 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:10:48,297 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:10:48,305 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:10:48,308 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:10:48,311 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:10:48,313 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:10:48,321 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:10:48,323 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:10:48,325 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:10:48,327 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:10:48,328 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:10:48,340 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:10:48,342 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:10:48,346 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:10:48,348 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:10:48,349 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:10:48,358 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:10:48,362 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:10:48,363 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:10:48,366 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:10:48,371 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:10:48,374 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:10:48,380 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:10:48,381 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:10:48,388 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:10:48,394 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:10:48,395 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:10:48,400 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:10:48,402 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:10:48,411 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:10:48,418 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:10:48,420 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:10:48,424 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:10:48,426 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:10:48,446 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:10:48,559 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:10:48,561 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:10:48,563 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:10:48,566 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:10:48,569 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:10:48,573 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:10:48,613 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:10:48,619 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:10:48,690 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:48,701 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:10:48,859 - INFO - 第 1 折评估完成: NPMI=0.4902, Diversity=0.4533, Optimal Score=0.4717\n",
      "实验进度:  10%|█         | 6/60 [00:16<02:29,  2.76s/it]2024-11-24 21:10:48,860 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:48,935 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:10:48,935 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:10:48.935950', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:48,939 - INFO - discarding 8096 tokens: [('aaron', 7), ('asper', 8), ('contritio', 22), ('conversatio', 28), ('correctio', 22), ('dormio', 34), ('element', 7), ('eua', 23), ('expositio', 13), ('generalis', 28)]...\n",
      "2024-11-24 21:10:48,939 - INFO - keeping 800 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:48,940 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:10:48,941 - INFO - 词典过滤: 8896 -> 800 个词\n",
      "2024-11-24 21:10:48,984 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:48,985 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:48,985 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:48,986 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:48,987 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:48,987 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:49,344 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:49,345 - INFO - topic #6 (0.067): 0.024*\"spiritus\" + 0.022*\"delphi\" + 0.015*\"vita\" + 0.013*\"corpus\" + 0.012*\"christus\" + 0.011*\"verbum\" + 0.010*\"desiderium\" + 0.010*\"virtus\" + 0.010*\"mundus\" + 0.009*\"essentia\"\n",
      "2024-11-24 21:10:49,345 - INFO - topic #13 (0.067): 0.022*\"verbum\" + 0.018*\"pater\" + 0.017*\"filius\" + 0.017*\"natura\" + 0.017*\"christus\" + 0.014*\"spiritus\" + 0.014*\"vita\" + 0.014*\"dominus\" + 0.012*\"iesus\" + 0.012*\"corpus\"\n",
      "2024-11-24 21:10:49,345 - INFO - topic #12 (0.067): 0.021*\"delphi\" + 0.020*\"spiritus\" + 0.017*\"ratio\" + 0.016*\"fides\" + 0.013*\"verbum\" + 0.012*\"christus\" + 0.011*\"homo\" + 0.010*\"pax\" + 0.010*\"amor\" + 0.009*\"bonus\"\n",
      "2024-11-24 21:10:49,346 - INFO - topic #10 (0.067): 0.023*\"spiritus\" + 0.021*\"vita\" + 0.018*\"verbum\" + 0.016*\"homo\" + 0.014*\"christus\" + 0.013*\"lex\" + 0.012*\"virtus\" + 0.012*\"iustitia\" + 0.011*\"ostendo\" + 0.011*\"pater\"\n",
      "2024-11-24 21:10:49,346 - INFO - topic #2 (0.067): 0.035*\"christus\" + 0.026*\"spiritus\" + 0.016*\"verbum\" + 0.014*\"mundus\" + 0.012*\"rex\" + 0.011*\"fides\" + 0.011*\"filius\" + 0.011*\"sapientia\" + 0.010*\"homo\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:10:49,346 - INFO - topic diff=1.446414, rho=1.000000\n",
      "2024-11-24 21:10:49,714 - INFO - -6.456 per-word bound, 87.8 perplexity estimate based on a held-out corpus of 1716 documents with 73053 words\n",
      "2024-11-24 21:10:49,714 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:50,032 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:50,032 - INFO - topic #10 (0.067): 0.022*\"spiritus\" + 0.020*\"verbum\" + 0.020*\"lex\" + 0.017*\"homo\" + 0.017*\"vita\" + 0.015*\"virtus\" + 0.014*\"ostendo\" + 0.013*\"credo\" + 0.013*\"christus\" + 0.011*\"sanctus\"\n",
      "2024-11-24 21:10:50,033 - INFO - topic #1 (0.067): 0.023*\"debeo\" + 0.018*\"christus\" + 0.018*\"domus\" + 0.016*\"spiritus\" + 0.014*\"peto\" + 0.013*\"gratia\" + 0.012*\"ecclesia\" + 0.012*\"dies\" + 0.011*\"donum\" + 0.011*\"oratio\"\n",
      "2024-11-24 21:10:50,033 - INFO - topic #2 (0.067): 0.034*\"christus\" + 0.027*\"spiritus\" + 0.024*\"nomen\" + 0.018*\"verbum\" + 0.017*\"sapientia\" + 0.013*\"filius\" + 0.013*\"mundus\" + 0.012*\"fides\" + 0.010*\"virtus\" + 0.010*\"mitto\"\n",
      "2024-11-24 21:10:50,033 - INFO - topic #11 (0.067): 0.028*\"pater\" + 0.023*\"mundus\" + 0.017*\"spiritus\" + 0.016*\"christus\" + 0.013*\"homo\" + 0.013*\"filius\" + 0.012*\"peccatum\" + 0.011*\"veritas\" + 0.011*\"sanctus\" + 0.010*\"bonus\"\n",
      "2024-11-24 21:10:50,034 - INFO - topic #0 (0.067): 0.038*\"vita\" + 0.024*\"mors\" + 0.020*\"motus\" + 0.018*\"verbum\" + 0.016*\"delphi\" + 0.014*\"spiritus\" + 0.012*\"virtus\" + 0.011*\"christus\" + 0.011*\"eligo\" + 0.010*\"debeo\"\n",
      "2024-11-24 21:10:50,034 - INFO - topic diff=0.591180, rho=0.707107\n",
      "2024-11-24 21:10:50,034 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.05s', 'datetime': '2024-11-24T21:10:50.034769', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:50,037 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:50,095 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:10:50,119 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:10:50,242 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:10:50,274 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:10:50,276 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:10:50,277 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:10:50,278 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:10:51,127 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:10:51,165 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:10:51,189 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:10:51,191 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:10:51,192 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:10:51,195 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:10:51,196 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:10:51,198 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:10:51,200 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:10:51,202 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:10:51,211 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:10:51,215 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:10:51,220 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:10:51,230 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:10:51,234 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:10:51,238 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:10:51,246 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:10:51,249 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:10:51,279 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:10:51,281 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:10:51,286 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:10:51,287 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:10:51,306 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:10:51,313 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:10:51,347 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:10:51,348 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:10:51,353 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:10:51,366 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:10:51,368 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:10:51,370 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:10:51,375 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:10:51,382 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:10:51,384 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:10:51,396 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:10:51,402 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:10:51,404 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:10:51,405 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:10:51,410 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:10:51,412 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:10:51,428 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:10:51,429 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:10:51,431 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:10:51,433 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:10:51,453 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:10:51,460 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:10:51,463 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:10:51,464 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:10:51,465 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:10:51,470 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:10:51,472 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:10:51,476 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:10:51,483 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:10:51,605 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:51,647 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:10:51,818 - INFO - 第 2 折评估完成: NPMI=0.4939, Diversity=0.4000, Optimal Score=0.4469\n",
      "实验进度:  12%|█▏        | 7/60 [00:19<02:29,  2.83s/it]2024-11-24 21:10:51,820 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:51,895 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:10:51,896 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:10:51.896048', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:51,899 - INFO - discarding 8034 tokens: [('apocalypsis', 13), ('constantinus', 33), ('corona', 28), ('element', 9), ('generalis', 26), ('grando', 6), ('principalis', 17), ('specialis', 13), ('terraemotus', 6), ('aaron', 8)]...\n",
      "2024-11-24 21:10:51,899 - INFO - keeping 800 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:51,900 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:10:51,901 - INFO - 词典过滤: 8834 -> 800 个词\n",
      "2024-11-24 21:10:52,008 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:52,009 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:52,009 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:52,010 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:52,010 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:52,011 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:52,373 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:52,374 - INFO - topic #6 (0.067): 0.060*\"und\" + 0.033*\"dies\" + 0.021*\"delphi\" + 0.019*\"christus\" + 0.019*\"is\" + 0.014*\"vita\" + 0.014*\"verbum\" + 0.011*\"debeo\" + 0.011*\"spiritus\" + 0.010*\"dar\"\n",
      "2024-11-24 21:10:52,375 - INFO - topic #13 (0.067): 0.051*\"christus\" + 0.018*\"homo\" + 0.017*\"venio\" + 0.014*\"corpus\" + 0.013*\"virtus\" + 0.012*\"rex\" + 0.011*\"panis\" + 0.011*\"verbum\" + 0.011*\"spiritus\" + 0.009*\"gloria\"\n",
      "2024-11-24 21:10:52,375 - INFO - topic #12 (0.067): 0.022*\"spiritus\" + 0.021*\"vita\" + 0.019*\"verbum\" + 0.016*\"filius\" + 0.014*\"sanctus\" + 0.012*\"pater\" + 0.012*\"fides\" + 0.011*\"veritas\" + 0.011*\"homo\" + 0.010*\"natura\"\n",
      "2024-11-24 21:10:52,376 - INFO - topic #10 (0.067): 0.033*\"spiritus\" + 0.024*\"christus\" + 0.017*\"mundus\" + 0.015*\"homo\" + 0.014*\"natura\" + 0.012*\"verbum\" + 0.011*\"vita\" + 0.011*\"pater\" + 0.009*\"sapientia\" + 0.009*\"divinus\"\n",
      "2024-11-24 21:10:52,376 - INFO - topic #2 (0.067): 0.020*\"spiritus\" + 0.017*\"homo\" + 0.017*\"virtus\" + 0.017*\"christus\" + 0.015*\"filius\" + 0.013*\"fides\" + 0.012*\"natura\" + 0.011*\"dominus\" + 0.010*\"verbum\" + 0.010*\"gratia\"\n",
      "2024-11-24 21:10:52,376 - INFO - topic diff=1.418527, rho=1.000000\n",
      "2024-11-24 21:10:52,758 - INFO - -6.454 per-word bound, 87.7 perplexity estimate based on a held-out corpus of 1716 documents with 71901 words\n",
      "2024-11-24 21:10:52,759 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:53,055 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:53,056 - INFO - topic #10 (0.067): 0.031*\"spiritus\" + 0.024*\"natura\" + 0.019*\"homo\" + 0.018*\"christus\" + 0.017*\"ars\" + 0.017*\"mundus\" + 0.016*\"sapientia\" + 0.013*\"infinitus\" + 0.012*\"humanus\" + 0.011*\"verbum\"\n",
      "2024-11-24 21:10:53,056 - INFO - topic #1 (0.067): 0.033*\"christus\" + 0.015*\"mundus\" + 0.014*\"dies\" + 0.014*\"mater\" + 0.011*\"sanctus\" + 0.010*\"volo\" + 0.009*\"debeo\" + 0.009*\"ratio\" + 0.008*\"sequor\" + 0.008*\"cognosco\"\n",
      "2024-11-24 21:10:53,056 - INFO - topic #2 (0.067): 0.018*\"virtus\" + 0.016*\"filius\" + 0.016*\"dominus\" + 0.015*\"christus\" + 0.015*\"homo\" + 0.015*\"fides\" + 0.015*\"spiritus\" + 0.014*\"gratia\" + 0.011*\"natura\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:10:53,057 - INFO - topic #11 (0.067): 0.033*\"lux\" + 0.024*\"spiritus\" + 0.019*\"gratia\" + 0.017*\"gegen\" + 0.014*\"tenebrae\" + 0.012*\"fides\" + 0.011*\"veritas\" + 0.011*\"sanctus\" + 0.010*\"donum\" + 0.010*\"homo\"\n",
      "2024-11-24 21:10:53,057 - INFO - topic #0 (0.067): 0.056*\"filius\" + 0.049*\"pater\" + 0.026*\"christus\" + 0.025*\"homo\" + 0.024*\"nomen\" + 0.023*\"spiritus\" + 0.022*\"fides\" + 0.015*\"credo\" + 0.012*\"verbum\" + 0.011*\"vita\"\n",
      "2024-11-24 21:10:53,057 - INFO - topic diff=0.588845, rho=0.707107\n",
      "2024-11-24 21:10:53,058 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.05s', 'datetime': '2024-11-24T21:10:53.058084', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:53,060 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:53,111 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:10:53,203 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:10:53,263 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:10:53,264 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:10:53,267 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:10:53,268 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:10:53,270 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:10:53,968 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:10:54,001 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:10:54,021 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:10:54,039 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:10:54,066 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:10:54,068 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:10:54,070 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:10:54,072 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:10:54,079 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:10:54,087 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:10:54,089 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:10:54,096 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:10:54,099 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:10:54,103 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:10:54,105 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:10:54,107 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:10:54,117 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:10:54,119 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:10:54,121 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:10:54,125 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:10:54,126 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:10:54,128 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:10:54,135 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:10:54,146 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:10:54,151 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:10:54,153 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:10:54,155 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:10:54,156 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:10:54,169 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:10:54,171 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:10:54,174 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:10:54,176 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:10:54,178 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:10:54,179 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:10:54,183 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:10:54,195 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:10:54,220 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:10:54,234 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:10:54,238 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:10:54,240 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:10:54,242 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:10:54,249 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:10:54,256 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:10:54,259 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:10:54,268 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:10:54,270 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:10:54,272 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:10:54,276 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:10:54,278 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:10:54,281 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:10:54,292 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:10:54,294 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:10:54,360 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:54,387 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:10:54,564 - INFO - 第 3 折评估完成: NPMI=0.4922, Diversity=0.4400, Optimal Score=0.4661\n",
      "实验进度:  13%|█▎        | 8/60 [00:22<02:25,  2.80s/it]2024-11-24 21:10:54,565 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:54,655 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:10:54,655 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:10:54.655671', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:54,658 - INFO - discarding 8085 tokens: [('apocalypsis', 14), ('constantinus', 30), ('corona', 26), ('element', 6), ('generalis', 25), ('grando', 3), ('principalis', 16), ('specialis', 12), ('terraemotus', 3), ('amicitia', 23)]...\n",
      "2024-11-24 21:10:54,659 - INFO - keeping 800 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:54,660 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:10:54,660 - INFO - 词典过滤: 8885 -> 800 个词\n",
      "2024-11-24 21:10:54,705 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:54,706 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:54,706 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:54,707 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:54,707 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:54,708 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:55,069 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:55,070 - INFO - topic #6 (0.067): 0.030*\"homo\" + 0.025*\"christus\" + 0.025*\"spiritus\" + 0.020*\"vita\" + 0.016*\"delphi\" + 0.015*\"virtus\" + 0.015*\"verbum\" + 0.015*\"natura\" + 0.013*\"filius\" + 0.009*\"und\"\n",
      "2024-11-24 21:10:55,070 - INFO - topic #13 (0.067): 0.020*\"amor\" + 0.020*\"christus\" + 0.020*\"vita\" + 0.019*\"filius\" + 0.018*\"locus\" + 0.018*\"virtus\" + 0.012*\"verbum\" + 0.011*\"spiritus\" + 0.011*\"debeo\" + 0.011*\"pater\"\n",
      "2024-11-24 21:10:55,071 - INFO - topic #12 (0.067): 0.018*\"spiritus\" + 0.016*\"homo\" + 0.015*\"christus\" + 0.012*\"debeo\" + 0.012*\"pulchritudo\" + 0.011*\"pater\" + 0.011*\"dies\" + 0.010*\"verbum\" + 0.009*\"fides\" + 0.009*\"dominus\"\n",
      "2024-11-24 21:10:55,071 - INFO - topic #10 (0.067): 0.025*\"christus\" + 0.015*\"verbum\" + 0.015*\"pater\" + 0.015*\"homo\" + 0.014*\"nomen\" + 0.013*\"vita\" + 0.013*\"gloria\" + 0.012*\"spiritus\" + 0.012*\"sapientia\" + 0.012*\"principium\"\n",
      "2024-11-24 21:10:55,072 - INFO - topic #2 (0.067): 0.033*\"christus\" + 0.026*\"vita\" + 0.020*\"und\" + 0.016*\"dies\" + 0.015*\"mundus\" + 0.014*\"spiritus\" + 0.012*\"filius\" + 0.012*\"homo\" + 0.011*\"intellego\" + 0.010*\"regnum\"\n",
      "2024-11-24 21:10:55,072 - INFO - topic diff=1.573036, rho=1.000000\n",
      "2024-11-24 21:10:55,437 - INFO - -6.442 per-word bound, 86.9 perplexity estimate based on a held-out corpus of 1716 documents with 72301 words\n",
      "2024-11-24 21:10:55,437 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:55,731 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:55,732 - INFO - topic #10 (0.067): 0.032*\"nomen\" + 0.024*\"pater\" + 0.022*\"christus\" + 0.020*\"principium\" + 0.016*\"creatura\" + 0.015*\"homo\" + 0.015*\"verbum\" + 0.015*\"larissa\" + 0.015*\"tempus\" + 0.014*\"sapientia\"\n",
      "2024-11-24 21:10:55,732 - INFO - topic #1 (0.067): 0.035*\"spiritus\" + 0.024*\"gratia\" + 0.022*\"vita\" + 0.016*\"dies\" + 0.015*\"panis\" + 0.013*\"delphi\" + 0.013*\"sanctus\" + 0.011*\"iustitia\" + 0.010*\"christus\" + 0.010*\"misericordia\"\n",
      "2024-11-24 21:10:55,732 - INFO - topic #2 (0.067): 0.046*\"christus\" + 0.034*\"dies\" + 0.028*\"vita\" + 0.013*\"sanctus\" + 0.012*\"mundus\" + 0.011*\"intellego\" + 0.010*\"mors\" + 0.010*\"homo\" + 0.010*\"venio\" + 0.010*\"filius\"\n",
      "2024-11-24 21:10:55,733 - INFO - topic #11 (0.067): 0.033*\"natura\" + 0.028*\"christus\" + 0.026*\"pater\" + 0.025*\"filius\" + 0.017*\"debeo\" + 0.014*\"corpus\" + 0.014*\"homo\" + 0.011*\"mundus\" + 0.009*\"delphi\" + 0.009*\"dominus\"\n",
      "2024-11-24 21:10:55,733 - INFO - topic #0 (0.067): 0.024*\"pax\" + 0.021*\"terra\" + 0.016*\"christus\" + 0.015*\"voluntas\" + 0.013*\"vita\" + 0.011*\"homo\" + 0.011*\"pater\" + 0.011*\"evangelium\" + 0.010*\"larissa\" + 0.010*\"quaero\"\n",
      "2024-11-24 21:10:55,733 - INFO - topic diff=0.613584, rho=0.707107\n",
      "2024-11-24 21:10:55,734 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.03s', 'datetime': '2024-11-24T21:10:55.734215', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:55,736 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:55,777 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:10:55,783 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:10:55,918 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:10:55,919 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:10:55,920 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:10:55,921 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:10:55,922 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:10:56,601 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:10:56,623 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:10:56,643 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:10:56,672 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:10:56,691 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:10:56,721 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:10:56,723 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:10:56,725 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:10:56,728 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:10:56,747 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:10:56,752 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:10:56,754 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:10:56,757 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:10:56,760 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:10:56,762 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:10:56,774 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:10:56,784 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:10:56,785 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:10:56,793 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:10:56,795 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:10:56,799 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:10:56,802 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:10:56,839 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:10:56,854 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:10:56,916 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:10:56,928 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:10:56,931 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:10:56,960 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:10:56,966 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:10:56,967 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:10:56,968 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:10:56,970 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:10:56,971 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:10:56,972 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:10:56,973 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:10:56,979 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:10:56,981 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:10:56,986 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:10:56,993 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:10:56,995 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:10:56,996 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:10:57,169 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:10:57,224 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:10:57,229 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:10:57,236 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:10:57,239 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:10:57,243 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:10:57,245 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:10:57,251 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:10:57,258 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:10:57,261 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:10:57,262 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:10:57,344 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:10:57,363 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:10:57,541 - INFO - 第 4 折评估完成: NPMI=0.4890, Diversity=0.4200, Optimal Score=0.4545\n",
      "实验进度:  15%|█▌        | 9/60 [00:25<02:25,  2.86s/it]2024-11-24 21:10:57,544 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:10:57,625 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:10:57,626 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:10:57.626271', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:57,629 - INFO - discarding 8103 tokens: [('apocalypsis', 15), ('constantinus', 35), ('corona', 26), ('element', 9), ('generalis', 24), ('grando', 7), ('principalis', 16), ('specialis', 11), ('terraemotus', 5), ('aaron', 5)]...\n",
      "2024-11-24 21:10:57,630 - INFO - keeping 800 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:10:57,631 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:10:57,631 - INFO - 词典过滤: 8903 -> 800 个词\n",
      "2024-11-24 21:10:57,679 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:10:57,679 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:10:57,680 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:10:57,681 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:10:57,681 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:10:57,681 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:10:58,055 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:58,056 - INFO - topic #6 (0.067): 0.027*\"homo\" + 0.024*\"filius\" + 0.021*\"christus\" + 0.020*\"pater\" + 0.016*\"verbum\" + 0.016*\"virtus\" + 0.011*\"vita\" + 0.010*\"imago\" + 0.010*\"intellego\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:10:58,056 - INFO - topic #13 (0.067): 0.047*\"christus\" + 0.025*\"virtus\" + 0.018*\"homo\" + 0.017*\"spiritus\" + 0.014*\"verbum\" + 0.012*\"vita\" + 0.011*\"corpus\" + 0.011*\"delphi\" + 0.009*\"natura\" + 0.009*\"ratio\"\n",
      "2024-11-24 21:10:58,057 - INFO - topic #12 (0.067): 0.029*\"vita\" + 0.023*\"fides\" + 0.022*\"spiritus\" + 0.020*\"verbum\" + 0.016*\"homo\" + 0.015*\"lux\" + 0.013*\"christus\" + 0.013*\"pater\" + 0.013*\"filius\" + 0.012*\"veritas\"\n",
      "2024-11-24 21:10:58,057 - INFO - topic #10 (0.067): 0.030*\"spiritus\" + 0.025*\"christus\" + 0.025*\"filius\" + 0.023*\"vita\" + 0.016*\"fides\" + 0.015*\"verbum\" + 0.015*\"pater\" + 0.014*\"delphi\" + 0.013*\"mundus\" + 0.011*\"natura\"\n",
      "2024-11-24 21:10:58,058 - INFO - topic #2 (0.067): 0.017*\"intellectus\" + 0.016*\"cognosco\" + 0.016*\"christus\" + 0.015*\"dominus\" + 0.013*\"lux\" + 0.013*\"pater\" + 0.012*\"virtus\" + 0.012*\"fides\" + 0.011*\"clotho\" + 0.011*\"iudico\"\n",
      "2024-11-24 21:10:58,058 - INFO - topic diff=1.539441, rho=1.000000\n",
      "2024-11-24 21:10:58,429 - INFO - -6.459 per-word bound, 88.0 perplexity estimate based on a held-out corpus of 1716 documents with 72659 words\n",
      "2024-11-24 21:10:58,429 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:10:58,739 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:10:58,740 - INFO - topic #10 (0.067): 0.029*\"christus\" + 0.028*\"filius\" + 0.026*\"spiritus\" + 0.026*\"vita\" + 0.020*\"pater\" + 0.018*\"delphi\" + 0.017*\"fides\" + 0.016*\"verbum\" + 0.014*\"corpus\" + 0.014*\"veritas\"\n",
      "2024-11-24 21:10:58,740 - INFO - topic #1 (0.067): 0.039*\"christus\" + 0.021*\"debeo\" + 0.020*\"mater\" + 0.016*\"nomen\" + 0.016*\"sanctus\" + 0.016*\"vita\" + 0.014*\"pater\" + 0.014*\"domus\" + 0.014*\"und\" + 0.013*\"symbatios\"\n",
      "2024-11-24 21:10:58,740 - INFO - topic #2 (0.067): 0.029*\"intellectus\" + 0.021*\"cognosco\" + 0.019*\"dominus\" + 0.014*\"pater\" + 0.013*\"nomen\" + 0.013*\"iudico\" + 0.013*\"lux\" + 0.013*\"christus\" + 0.012*\"fides\" + 0.010*\"delphi\"\n",
      "2024-11-24 21:10:58,741 - INFO - topic #11 (0.067): 0.020*\"christus\" + 0.018*\"dies\" + 0.017*\"nomen\" + 0.017*\"delphi\" + 0.014*\"dominus\" + 0.012*\"debeo\" + 0.011*\"vita\" + 0.010*\"peccatum\" + 0.008*\"voluntas\" + 0.008*\"vivo\"\n",
      "2024-11-24 21:10:58,741 - INFO - topic #0 (0.067): 0.041*\"pater\" + 0.037*\"filius\" + 0.019*\"sanctus\" + 0.018*\"nomen\" + 0.015*\"spiritus\" + 0.011*\"christus\" + 0.010*\"gratia\" + 0.009*\"tertius\" + 0.008*\"dies\" + 0.008*\"vita\"\n",
      "2024-11-24 21:10:58,741 - INFO - topic diff=0.615090, rho=0.707107\n",
      "2024-11-24 21:10:58,742 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.06s', 'datetime': '2024-11-24T21:10:58.742161', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:10:58,745 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:10:58,799 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:10:58,896 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:10:58,899 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:10:58,952 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:10:58,955 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:10:58,956 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:10:58,958 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:10:59,759 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:10:59,775 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:10:59,795 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:10:59,812 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:10:59,823 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:10:59,825 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:10:59,827 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:10:59,829 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:10:59,831 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:10:59,833 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:10:59,835 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:10:59,836 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:10:59,838 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:10:59,840 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:10:59,842 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:10:59,844 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:10:59,846 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:10:59,849 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:10:59,852 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:10:59,855 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:10:59,856 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:10:59,865 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:10:59,871 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:10:59,873 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:10:59,876 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:10:59,878 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:10:59,883 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:10:59,894 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:10:59,902 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:10:59,904 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:10:59,907 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:10:59,908 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:10:59,910 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:10:59,914 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:10:59,920 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:10:59,936 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:10:59,943 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:10:59,945 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:10:59,967 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:10:59,976 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:10:59,981 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:10:59,983 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:10:59,985 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:10:59,994 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:10:59,998 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:11:00,002 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:11:00,007 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:11:00,010 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:11:00,019 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:11:00,024 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:11:00,028 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:11:00,036 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:11:00,083 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:00,096 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:11:00,288 - INFO - 第 5 折评估完成: NPMI=0.4891, Diversity=0.3933, Optimal Score=0.4412\n",
      "实验进度:  17%|█▋        | 10/60 [00:28<02:21,  2.82s/it]2024-11-24 21:11:00,288 - INFO - \n",
      "评估阈值组合: min_freq=2, max_freq=1400\n",
      "2024-11-24 21:11:00,291 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:00,365 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:11:00,366 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:11:00.366295', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:00,369 - INFO - discarding 7439 tokens: [('apocalypsis', 16), ('element', 9), ('grando', 6), ('principalis', 18), ('specialis', 14), ('terraemotus', 5), ('aaron', 7), ('asper', 9), ('correctio', 16), ('expositio', 14)]...\n",
      "2024-11-24 21:11:00,369 - INFO - keeping 1400 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:00,371 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:11:00,371 - INFO - 词典过滤: 8839 -> 1400 个词\n",
      "2024-11-24 21:11:00,419 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:00,419 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:00,420 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:00,421 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:00,421 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:00,422 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:00,796 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:00,797 - INFO - topic #8 (0.067): 0.022*\"iustitia\" + 0.020*\"virtus\" + 0.013*\"spiritus\" + 0.012*\"christus\" + 0.010*\"verbum\" + 0.010*\"larissa\" + 0.009*\"vita\" + 0.008*\"veritas\" + 0.008*\"filius\" + 0.008*\"verus\"\n",
      "2024-11-24 21:11:00,797 - INFO - topic #7 (0.067): 0.031*\"christus\" + 0.023*\"spiritus\" + 0.016*\"pater\" + 0.012*\"virtus\" + 0.012*\"vita\" + 0.011*\"mundus\" + 0.010*\"semen\" + 0.009*\"debeo\" + 0.009*\"terra\" + 0.008*\"delphi\"\n",
      "2024-11-24 21:11:00,797 - INFO - topic #5 (0.067): 0.044*\"und\" + 0.016*\"is\" + 0.016*\"verbum\" + 0.015*\"wir\" + 0.014*\"dies\" + 0.012*\"got\" + 0.009*\"spiritus\" + 0.009*\"pulchritudo\" + 0.009*\"mundus\" + 0.009*\"christus\"\n",
      "2024-11-24 21:11:00,797 - INFO - topic #14 (0.067): 0.018*\"vita\" + 0.017*\"christus\" + 0.016*\"spiritus\" + 0.012*\"natura\" + 0.011*\"fides\" + 0.010*\"veritas\" + 0.009*\"delphi\" + 0.008*\"filius\" + 0.008*\"intellectus\" + 0.007*\"petrus\"\n",
      "2024-11-24 21:11:00,798 - INFO - topic #1 (0.067): 0.035*\"delphi\" + 0.019*\"christus\" + 0.016*\"spiritus\" + 0.013*\"vita\" + 0.013*\"virtus\" + 0.013*\"corpus\" + 0.011*\"homo\" + 0.010*\"verbum\" + 0.009*\"dominus\" + 0.008*\"natura\"\n",
      "2024-11-24 21:11:00,798 - INFO - topic diff=2.396923, rho=1.000000\n",
      "2024-11-24 21:11:01,187 - INFO - -6.937 per-word bound, 122.6 perplexity estimate based on a held-out corpus of 1716 documents with 82506 words\n",
      "2024-11-24 21:11:01,187 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:01,498 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:01,499 - INFO - topic #5 (0.067): 0.034*\"und\" + 0.021*\"pulchritudo\" + 0.020*\"dies\" + 0.018*\"verbum\" + 0.014*\"is\" + 0.011*\"wir\" + 0.010*\"via\" + 0.009*\"intellectus\" + 0.009*\"got\" + 0.008*\"viator\"\n",
      "2024-11-24 21:11:01,499 - INFO - topic #2 (0.067): 0.020*\"lux\" + 0.018*\"homo\" + 0.016*\"vita\" + 0.015*\"verbum\" + 0.014*\"filius\" + 0.012*\"christus\" + 0.012*\"mundus\" + 0.011*\"venio\" + 0.010*\"sapientia\" + 0.009*\"terra\"\n",
      "2024-11-24 21:11:01,499 - INFO - topic #14 (0.067): 0.020*\"natura\" + 0.019*\"vita\" + 0.018*\"veritas\" + 0.016*\"christus\" + 0.015*\"petrus\" + 0.013*\"imago\" + 0.012*\"spiritus\" + 0.011*\"fides\" + 0.009*\"intellectus\" + 0.009*\"ratio\"\n",
      "2024-11-24 21:11:01,500 - INFO - topic #8 (0.067): 0.049*\"iustitia\" + 0.026*\"virtus\" + 0.017*\"iustus\" + 0.013*\"veritas\" + 0.011*\"larissa\" + 0.010*\"christus\" + 0.008*\"spiritus\" + 0.008*\"verus\" + 0.008*\"verbum\" + 0.007*\"vita\"\n",
      "2024-11-24 21:11:01,500 - INFO - topic #0 (0.067): 0.020*\"christus\" + 0.018*\"filius\" + 0.017*\"homo\" + 0.016*\"pater\" + 0.016*\"verbum\" + 0.015*\"sanctus\" + 0.010*\"vita\" + 0.009*\"pax\" + 0.009*\"gratia\" + 0.009*\"spiritus\"\n",
      "2024-11-24 21:11:01,500 - INFO - topic diff=0.816336, rho=0.707107\n",
      "2024-11-24 21:11:01,500 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.08s', 'datetime': '2024-11-24T21:11:01.500986', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:01,503 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:01,594 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:11:01,645 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:11:01,647 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:11:01,648 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:11:01,650 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:11:01,652 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:11:01,653 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:11:02,426 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:11:02,451 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:11:02,471 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:11:02,479 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:11:02,511 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:11:02,519 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:11:02,521 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:11:02,544 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:11:02,550 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:11:02,552 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:11:02,556 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:11:02,563 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:11:02,572 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:11:02,574 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:11:02,578 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:11:02,588 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:11:02,622 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:11:02,630 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:11:02,635 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:11:02,662 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:11:02,668 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:11:02,676 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:11:02,680 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:11:02,686 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:11:02,693 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:11:02,701 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:11:02,703 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:11:02,707 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:11:02,709 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:11:02,709 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:11:02,710 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:11:02,711 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:11:02,712 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:11:02,713 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:11:02,713 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:11:02,718 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:11:02,721 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:11:02,722 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:11:02,727 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:11:02,737 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:11:02,740 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:11:02,754 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:11:02,756 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:11:02,758 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:11:02,765 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:11:02,768 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:11:02,774 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:11:02,777 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:11:02,779 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:11:02,784 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:11:02,785 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:11:02,796 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:11:02,883 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:02,892 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:11:03,059 - INFO - 第 1 折评估完成: NPMI=0.4860, Diversity=0.4133, Optimal Score=0.4497\n",
      "实验进度:  18%|█▊        | 11/60 [00:30<02:17,  2.81s/it]2024-11-24 21:11:03,062 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:03,141 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:11:03,142 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:11:03.142202', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:03,145 - INFO - discarding 7496 tokens: [('aaron', 7), ('asper', 8), ('element', 7), ('expositio', 13), ('grando', 6), ('habitaculum', 19), ('latus', 7), ('leichnam', 2), ('noe', 12), ('perforo', 5)]...\n",
      "2024-11-24 21:11:03,145 - INFO - keeping 1400 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:03,147 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:11:03,147 - INFO - 词典过滤: 8896 -> 1400 个词\n",
      "2024-11-24 21:11:03,199 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:03,199 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:03,200 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:03,201 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:03,201 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:03,202 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:03,593 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:03,594 - INFO - topic #8 (0.067): 0.034*\"christus\" + 0.021*\"vita\" + 0.015*\"verbum\" + 0.013*\"pater\" + 0.013*\"homo\" + 0.011*\"lux\" + 0.009*\"debeo\" + 0.009*\"delphi\" + 0.007*\"stella\" + 0.007*\"rex\"\n",
      "2024-11-24 21:11:03,595 - INFO - topic #7 (0.067): 0.022*\"christus\" + 0.018*\"verbum\" + 0.015*\"filius\" + 0.014*\"virtus\" + 0.013*\"debeo\" + 0.010*\"semen\" + 0.010*\"vita\" + 0.009*\"volo\" + 0.008*\"terra\" + 0.008*\"delphi\"\n",
      "2024-11-24 21:11:03,595 - INFO - topic #5 (0.067): 0.024*\"christus\" + 0.015*\"ratio\" + 0.015*\"und\" + 0.014*\"fides\" + 0.013*\"symbatios\" + 0.012*\"peccatum\" + 0.010*\"virtus\" + 0.010*\"spiritus\" + 0.009*\"amor\" + 0.008*\"vita\"\n",
      "2024-11-24 21:11:03,595 - INFO - topic #14 (0.067): 0.033*\"pater\" + 0.026*\"filius\" + 0.022*\"christus\" + 0.022*\"vita\" + 0.015*\"veritas\" + 0.014*\"spiritus\" + 0.011*\"homo\" + 0.009*\"mundus\" + 0.008*\"dies\" + 0.008*\"opus\"\n",
      "2024-11-24 21:11:03,596 - INFO - topic #1 (0.067): 0.026*\"christus\" + 0.020*\"vita\" + 0.012*\"debeo\" + 0.012*\"virtus\" + 0.011*\"filius\" + 0.011*\"gegen\" + 0.011*\"panis\" + 0.010*\"und\" + 0.010*\"intellectus\" + 0.009*\"divinus\"\n",
      "2024-11-24 21:11:03,596 - INFO - topic diff=2.232802, rho=1.000000\n",
      "2024-11-24 21:11:03,977 - INFO - -6.935 per-word bound, 122.4 perplexity estimate based on a held-out corpus of 1716 documents with 82647 words\n",
      "2024-11-24 21:11:03,977 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:04,285 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:04,286 - INFO - topic #5 (0.067): 0.024*\"symbatios\" + 0.022*\"fides\" + 0.022*\"peccatum\" + 0.020*\"ratio\" + 0.020*\"christus\" + 0.013*\"amor\" + 0.009*\"virtus\" + 0.008*\"spiritus\" + 0.008*\"diligo\" + 0.007*\"verus\"\n",
      "2024-11-24 21:11:04,286 - INFO - topic #2 (0.067): 0.061*\"spiritus\" + 0.025*\"homo\" + 0.025*\"christus\" + 0.019*\"mundus\" + 0.013*\"dies\" + 0.012*\"vita\" + 0.012*\"venio\" + 0.011*\"filius\" + 0.010*\"motus\" + 0.008*\"veritas\"\n",
      "2024-11-24 21:11:04,287 - INFO - topic #14 (0.067): 0.057*\"pater\" + 0.042*\"filius\" + 0.027*\"christus\" + 0.020*\"veritas\" + 0.018*\"vita\" + 0.013*\"spiritus\" + 0.012*\"homo\" + 0.009*\"dies\" + 0.009*\"cognosco\" + 0.009*\"opus\"\n",
      "2024-11-24 21:11:04,287 - INFO - topic #8 (0.067): 0.041*\"christus\" + 0.020*\"vita\" + 0.016*\"verbum\" + 0.013*\"homo\" + 0.012*\"pater\" + 0.010*\"lux\" + 0.009*\"stella\" + 0.009*\"debeo\" + 0.008*\"delphi\" + 0.008*\"gaudium\"\n",
      "2024-11-24 21:11:04,287 - INFO - topic #0 (0.067): 0.035*\"verbum\" + 0.019*\"pater\" + 0.018*\"barabbas\" + 0.014*\"terra\" + 0.014*\"mundus\" + 0.013*\"christus\" + 0.013*\"lex\" + 0.012*\"filius\" + 0.011*\"vita\" + 0.011*\"delphi\"\n",
      "2024-11-24 21:11:04,288 - INFO - topic diff=0.820391, rho=0.707107\n",
      "2024-11-24 21:11:04,288 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.09s', 'datetime': '2024-11-24T21:11:04.288319', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:04,291 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:04,335 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:11:04,340 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:11:04,558 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:11:04,562 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:11:04,563 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:11:04,564 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:11:04,565 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:11:05,230 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:11:05,254 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:11:05,271 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:11:05,280 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:11:05,308 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:11:05,318 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:11:05,336 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:11:05,340 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:11:05,342 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:11:05,344 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:11:05,345 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:11:05,347 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:11:05,349 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:11:05,350 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:11:05,352 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:11:05,356 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:11:05,358 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:11:05,362 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:11:05,365 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:11:05,366 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:11:05,375 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:11:05,377 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:11:05,381 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:11:05,383 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:11:05,397 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:11:05,400 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:11:05,402 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:11:05,404 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:11:05,405 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:11:05,407 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:11:05,415 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:11:05,423 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:11:05,425 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:11:05,427 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:11:05,434 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:11:05,436 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:11:05,438 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:11:05,442 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:11:05,480 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:11:05,494 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:11:05,498 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:11:05,500 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:11:05,502 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:11:05,509 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:11:05,511 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:11:05,514 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:11:05,522 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:11:05,527 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:11:05,529 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:11:05,535 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:11:05,537 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:11:05,539 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:11:05,592 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:05,602 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:11:05,793 - INFO - 第 2 折评估完成: NPMI=0.4908, Diversity=0.4067, Optimal Score=0.4487\n",
      "实验进度:  20%|██        | 12/60 [00:33<02:13,  2.78s/it]2024-11-24 21:11:05,795 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:05,868 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:11:05,869 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:11:05.868986', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:05,872 - INFO - discarding 7434 tokens: [('apocalypsis', 13), ('element', 9), ('grando', 6), ('principalis', 17), ('specialis', 13), ('terraemotus', 6), ('aaron', 8), ('asper', 9), ('contritio', 14), ('correctio', 17)]...\n",
      "2024-11-24 21:11:05,872 - INFO - keeping 1400 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:05,873 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:11:05,873 - INFO - 词典过滤: 8834 -> 1400 个词\n",
      "2024-11-24 21:11:05,920 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:05,920 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:05,921 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:05,922 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:05,922 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:05,923 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:06,306 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:06,307 - INFO - topic #8 (0.067): 0.018*\"vita\" + 0.013*\"larissa\" + 0.013*\"homo\" + 0.012*\"christus\" + 0.012*\"iustitia\" + 0.011*\"spiritus\" + 0.010*\"debeo\" + 0.010*\"lux\" + 0.009*\"amor\" + 0.008*\"dies\"\n",
      "2024-11-24 21:11:06,308 - INFO - topic #7 (0.067): 0.028*\"christus\" + 0.019*\"mundus\" + 0.016*\"debeo\" + 0.010*\"spiritus\" + 0.009*\"ratio\" + 0.009*\"delphi\" + 0.009*\"rex\" + 0.009*\"virtus\" + 0.009*\"volo\" + 0.007*\"vita\"\n",
      "2024-11-24 21:11:06,308 - INFO - topic #5 (0.067): 0.060*\"und\" + 0.031*\"dies\" + 0.016*\"is\" + 0.014*\"verbum\" + 0.014*\"wir\" + 0.012*\"spiritus\" + 0.012*\"peccatum\" + 0.012*\"christus\" + 0.011*\"unser\" + 0.010*\"got\"\n",
      "2024-11-24 21:11:06,309 - INFO - topic #14 (0.067): 0.027*\"vita\" + 0.019*\"filius\" + 0.014*\"christus\" + 0.011*\"homo\" + 0.008*\"mundus\" + 0.008*\"symbatios\" + 0.007*\"pater\" + 0.007*\"mors\" + 0.007*\"scio\" + 0.006*\"ratio\"\n",
      "2024-11-24 21:11:06,309 - INFO - topic #1 (0.067): 0.034*\"vita\" + 0.020*\"christus\" + 0.018*\"spiritus\" + 0.015*\"mors\" + 0.014*\"delphi\" + 0.011*\"verbum\" + 0.010*\"dominus\" + 0.009*\"lex\" + 0.009*\"filius\" + 0.007*\"opus\"\n",
      "2024-11-24 21:11:06,309 - INFO - topic diff=2.470042, rho=1.000000\n",
      "2024-11-24 21:11:06,687 - INFO - -6.921 per-word bound, 121.2 perplexity estimate based on a held-out corpus of 1716 documents with 81296 words\n",
      "2024-11-24 21:11:06,688 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:06,996 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:06,997 - INFO - topic #5 (0.067): 0.078*\"dies\" + 0.038*\"und\" + 0.034*\"peccatum\" + 0.014*\"verbum\" + 0.011*\"is\" + 0.010*\"christus\" + 0.009*\"spiritus\" + 0.009*\"delphi\" + 0.009*\"wir\" + 0.009*\"motus\"\n",
      "2024-11-24 21:11:06,997 - INFO - topic #2 (0.067): 0.020*\"christus\" + 0.014*\"homo\" + 0.013*\"vita\" + 0.011*\"filius\" + 0.010*\"lex\" + 0.010*\"via\" + 0.010*\"mundus\" + 0.009*\"bonus\" + 0.009*\"iustitia\" + 0.009*\"annas\"\n",
      "2024-11-24 21:11:06,998 - INFO - topic #14 (0.067): 0.024*\"vita\" + 0.014*\"filius\" + 0.012*\"homo\" + 0.012*\"mare\" + 0.010*\"christus\" + 0.009*\"symbatios\" + 0.009*\"contemplatio\" + 0.008*\"dies\" + 0.008*\"theophilus\" + 0.007*\"gebresten\"\n",
      "2024-11-24 21:11:06,998 - INFO - topic #8 (0.067): 0.024*\"iustitia\" + 0.019*\"larissa\" + 0.015*\"vita\" + 0.014*\"sol\" + 0.013*\"homo\" + 0.012*\"lux\" + 0.012*\"iustus\" + 0.011*\"christus\" + 0.010*\"dies\" + 0.009*\"debeo\"\n",
      "2024-11-24 21:11:06,998 - INFO - topic #0 (0.067): 0.045*\"filius\" + 0.042*\"pater\" + 0.022*\"verbum\" + 0.017*\"christus\" + 0.015*\"gratia\" + 0.012*\"homo\" + 0.010*\"sanctus\" + 0.010*\"ars\" + 0.010*\"semen\" + 0.009*\"imago\"\n",
      "2024-11-24 21:11:06,998 - INFO - topic diff=0.830118, rho=0.707107\n",
      "2024-11-24 21:11:06,999 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.08s', 'datetime': '2024-11-24T21:11:06.999137', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:07,001 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:07,052 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:11:07,226 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:11:07,227 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:11:07,228 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:11:07,229 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:11:07,230 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:11:07,230 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:11:07,922 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:11:07,951 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:11:07,967 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:11:07,973 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:11:07,978 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:11:07,986 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:11:07,990 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:11:08,004 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:11:08,006 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:11:08,021 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:11:08,023 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:11:08,026 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:11:08,035 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:11:08,038 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:11:08,040 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:11:08,045 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:11:08,048 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:11:08,071 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:11:08,074 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:11:08,079 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:11:08,081 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:11:08,082 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:11:08,088 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:11:08,090 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:11:08,093 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:11:08,102 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:11:08,118 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:11:08,136 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:11:08,139 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:11:08,141 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:11:08,143 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:11:08,145 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:11:08,149 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:11:08,162 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:11:08,164 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:11:08,166 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:11:08,168 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:11:08,170 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:11:08,177 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:11:08,180 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:11:08,181 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:11:08,193 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:11:08,195 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:11:08,204 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:11:08,206 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:11:08,209 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:11:08,210 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:11:08,212 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:11:08,218 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:11:08,222 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:11:08,224 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:11:08,225 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:11:08,284 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:08,292 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:11:08,481 - INFO - 第 3 折评估完成: NPMI=0.4864, Diversity=0.4400, Optimal Score=0.4632\n",
      "实验进度:  22%|██▏       | 13/60 [00:36<02:09,  2.76s/it]2024-11-24 21:11:08,482 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:08,559 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:11:08,559 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:11:08.559812', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:08,563 - INFO - discarding 7485 tokens: [('apocalypsis', 14), ('element', 6), ('grando', 3), ('principalis', 16), ('specialis', 12), ('terraemotus', 3), ('anatomia', 1), ('caesarius', 10), ('capitaneus', 11), ('carnalitas', 7)]...\n",
      "2024-11-24 21:11:08,563 - INFO - keeping 1400 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:08,564 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:11:08,565 - INFO - 词典过滤: 8885 -> 1400 个词\n",
      "2024-11-24 21:11:08,614 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:08,615 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:08,615 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:08,617 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:08,617 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:08,617 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:08,991 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:08,992 - INFO - topic #8 (0.067): 0.020*\"christus\" + 0.020*\"lux\" + 0.011*\"virtus\" + 0.010*\"verbum\" + 0.009*\"filius\" + 0.009*\"venio\" + 0.009*\"iudico\" + 0.008*\"rex\" + 0.008*\"petrus\" + 0.008*\"intellectus\"\n",
      "2024-11-24 21:11:08,992 - INFO - topic #7 (0.067): 0.023*\"christus\" + 0.022*\"vita\" + 0.015*\"filius\" + 0.014*\"homo\" + 0.014*\"mundus\" + 0.012*\"verbum\" + 0.010*\"spiritus\" + 0.009*\"panis\" + 0.009*\"delphi\" + 0.007*\"pater\"\n",
      "2024-11-24 21:11:08,992 - INFO - topic #5 (0.067): 0.042*\"und\" + 0.023*\"dies\" + 0.021*\"pater\" + 0.020*\"christus\" + 0.018*\"spiritus\" + 0.017*\"is\" + 0.015*\"filius\" + 0.014*\"verbum\" + 0.013*\"homo\" + 0.011*\"vita\"\n",
      "2024-11-24 21:11:08,993 - INFO - topic #14 (0.067): 0.036*\"und\" + 0.029*\"dies\" + 0.011*\"gratia\" + 0.010*\"filius\" + 0.010*\"mo\" + 0.009*\"delphi\" + 0.008*\"lux\" + 0.008*\"forma\" + 0.007*\"nichtestis\" + 0.007*\"homo\"\n",
      "2024-11-24 21:11:08,993 - INFO - topic #1 (0.067): 0.028*\"homo\" + 0.021*\"christus\" + 0.012*\"veritas\" + 0.012*\"natura\" + 0.011*\"verbum\" + 0.010*\"vita\" + 0.010*\"spiritus\" + 0.009*\"sapientia\" + 0.008*\"delphi\" + 0.008*\"filius\"\n",
      "2024-11-24 21:11:08,993 - INFO - topic diff=2.501997, rho=1.000000\n",
      "2024-11-24 21:11:09,369 - INFO - -6.921 per-word bound, 121.2 perplexity estimate based on a held-out corpus of 1716 documents with 81787 words\n",
      "2024-11-24 21:11:09,369 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:09,674 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:09,675 - INFO - topic #5 (0.067): 0.039*\"pater\" + 0.037*\"dies\" + 0.026*\"und\" + 0.023*\"filius\" + 0.020*\"christus\" + 0.016*\"verbum\" + 0.015*\"spiritus\" + 0.012*\"homo\" + 0.011*\"is\" + 0.010*\"mundus\"\n",
      "2024-11-24 21:11:09,675 - INFO - topic #2 (0.067): 0.022*\"homo\" + 0.018*\"natura\" + 0.018*\"gratia\" + 0.017*\"virtus\" + 0.017*\"ars\" + 0.016*\"verbum\" + 0.013*\"intellectus\" + 0.012*\"imago\" + 0.012*\"filius\" + 0.011*\"creo\"\n",
      "2024-11-24 21:11:09,676 - INFO - topic #14 (0.067): 0.096*\"dies\" + 0.019*\"annus\" + 0.014*\"und\" + 0.011*\"gratia\" + 0.011*\"dacia\" + 0.010*\"sirenes\" + 0.010*\"octavus\" + 0.010*\"mensis\" + 0.008*\"sufficio\" + 0.008*\"hoffnung\"\n",
      "2024-11-24 21:11:09,676 - INFO - topic #8 (0.067): 0.031*\"lux\" + 0.022*\"christus\" + 0.011*\"sol\" + 0.010*\"venio\" + 0.010*\"mitto\" + 0.009*\"iudico\" + 0.009*\"filius\" + 0.009*\"tenebrae\" + 0.009*\"verbum\" + 0.008*\"petrus\"\n",
      "2024-11-24 21:11:09,676 - INFO - topic #0 (0.067): 0.035*\"nomen\" + 0.022*\"fides\" + 0.016*\"verbum\" + 0.015*\"christus\" + 0.011*\"gegen\" + 0.011*\"debeo\" + 0.010*\"dominus\" + 0.009*\"ratio\" + 0.008*\"ordo\" + 0.007*\"scribo\"\n",
      "2024-11-24 21:11:09,676 - INFO - topic diff=0.843534, rho=0.707107\n",
      "2024-11-24 21:11:09,677 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.06s', 'datetime': '2024-11-24T21:11:09.677191', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:09,680 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:09,737 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:11:09,749 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:11:09,751 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:11:09,753 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:11:09,772 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:11:09,873 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:11:09,954 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:11:10,537 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:11:10,563 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:11:10,580 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:11:10,604 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:11:10,640 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:11:10,644 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:11:10,649 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:11:10,658 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:11:10,662 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:11:10,678 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:11:10,680 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:11:10,683 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:11:10,685 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:11:10,693 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:11:10,718 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:11:10,720 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:11:10,725 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:11:10,727 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:11:10,728 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:11:10,731 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:11:10,740 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:11:10,742 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:11:10,747 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:11:10,750 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:11:10,756 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:11:10,758 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:11:10,764 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:11:10,766 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:11:10,771 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:11:10,773 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:11:10,775 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:11:10,781 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:11:10,791 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:11:10,794 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:11:10,797 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:11:10,799 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:11:10,801 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:11:10,803 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:11:10,805 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:11:10,815 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:11:10,825 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:11:10,827 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:11:10,829 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:11:10,831 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:11:10,833 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:11:10,834 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:11:10,840 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:11:10,859 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:11:10,864 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:11:10,868 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:11:10,872 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:11:10,873 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:11:10,941 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:10,955 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:11:11,144 - INFO - 第 4 折评估完成: NPMI=0.4851, Diversity=0.4600, Optimal Score=0.4725\n",
      "实验进度:  23%|██▎       | 14/60 [00:38<02:05,  2.73s/it]2024-11-24 21:11:11,146 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:11,220 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:11:11,221 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:11:11.221335', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:11,224 - INFO - discarding 7503 tokens: [('apocalypsis', 15), ('element', 9), ('grando', 7), ('principalis', 16), ('specialis', 11), ('terraemotus', 5), ('aaron', 5), ('asper', 10), ('correctio', 17), ('expositio', 12)]...\n",
      "2024-11-24 21:11:11,224 - INFO - keeping 1400 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:11,226 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:11:11,226 - INFO - 词典过滤: 8903 -> 1400 个词\n",
      "2024-11-24 21:11:11,274 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:11,274 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:11,275 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:11,276 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:11,276 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:11,276 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:11,651 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:11,652 - INFO - topic #8 (0.067): 0.022*\"filius\" + 0.021*\"spiritus\" + 0.018*\"homo\" + 0.014*\"larissa\" + 0.013*\"christus\" + 0.013*\"natura\" + 0.011*\"corpus\" + 0.011*\"regnum\" + 0.010*\"unio\" + 0.010*\"locus\"\n",
      "2024-11-24 21:11:11,653 - INFO - topic #7 (0.067): 0.030*\"christus\" + 0.023*\"virtus\" + 0.019*\"vita\" + 0.014*\"homo\" + 0.014*\"amor\" + 0.014*\"delphi\" + 0.013*\"pater\" + 0.013*\"filius\" + 0.009*\"spiritus\" + 0.008*\"verbum\"\n",
      "2024-11-24 21:11:11,653 - INFO - topic #5 (0.067): 0.051*\"und\" + 0.026*\"dies\" + 0.019*\"wir\" + 0.016*\"homo\" + 0.013*\"christus\" + 0.012*\"is\" + 0.012*\"verbum\" + 0.011*\"debeo\" + 0.011*\"got\" + 0.010*\"natura\"\n",
      "2024-11-24 21:11:11,653 - INFO - topic #14 (0.067): 0.022*\"christus\" + 0.015*\"pater\" + 0.013*\"venio\" + 0.013*\"rex\" + 0.011*\"pax\" + 0.010*\"filius\" + 0.009*\"homo\" + 0.008*\"delphi\" + 0.007*\"spiritus\" + 0.007*\"vinco\"\n",
      "2024-11-24 21:11:11,654 - INFO - topic #1 (0.067): 0.022*\"christus\" + 0.018*\"pater\" + 0.012*\"filius\" + 0.011*\"sanctus\" + 0.011*\"dominus\" + 0.011*\"virtus\" + 0.010*\"spiritus\" + 0.010*\"verbum\" + 0.009*\"natura\" + 0.007*\"homo\"\n",
      "2024-11-24 21:11:11,654 - INFO - topic diff=2.415692, rho=1.000000\n",
      "2024-11-24 21:11:12,043 - INFO - -6.939 per-word bound, 122.7 perplexity estimate based on a held-out corpus of 1716 documents with 82495 words\n",
      "2024-11-24 21:11:12,043 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:12,350 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:12,351 - INFO - topic #5 (0.067): 0.058*\"dies\" + 0.039*\"und\" + 0.014*\"wir\" + 0.013*\"homo\" + 0.012*\"christus\" + 0.011*\"verbum\" + 0.010*\"natura\" + 0.010*\"is\" + 0.010*\"debeo\" + 0.008*\"semen\"\n",
      "2024-11-24 21:11:12,351 - INFO - topic #2 (0.067): 0.028*\"verbum\" + 0.025*\"nomen\" + 0.018*\"intellectus\" + 0.016*\"vita\" + 0.013*\"lux\" + 0.011*\"divinus\" + 0.010*\"principium\" + 0.010*\"gegen\" + 0.010*\"virtus\" + 0.010*\"delphi\"\n",
      "2024-11-24 21:11:12,351 - INFO - topic #14 (0.067): 0.022*\"christus\" + 0.015*\"pater\" + 0.012*\"sirenes\" + 0.012*\"pax\" + 0.012*\"homo\" + 0.011*\"venio\" + 0.011*\"filius\" + 0.011*\"rex\" + 0.010*\"nomen\" + 0.008*\"virgo\"\n",
      "2024-11-24 21:11:12,352 - INFO - topic #8 (0.067): 0.022*\"larissa\" + 0.020*\"homo\" + 0.020*\"natura\" + 0.019*\"filius\" + 0.016*\"spiritus\" + 0.013*\"locus\" + 0.013*\"unio\" + 0.012*\"corpus\" + 0.012*\"regnum\" + 0.011*\"christus\"\n",
      "2024-11-24 21:11:12,352 - INFO - topic #0 (0.067): 0.041*\"fides\" + 0.022*\"spiritus\" + 0.022*\"verbum\" + 0.016*\"christus\" + 0.014*\"volo\" + 0.014*\"ratio\" + 0.014*\"homo\" + 0.013*\"credo\" + 0.011*\"delphi\" + 0.011*\"vita\"\n",
      "2024-11-24 21:11:12,352 - INFO - topic diff=0.810077, rho=0.707107\n",
      "2024-11-24 21:11:12,353 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.08s', 'datetime': '2024-11-24T21:11:12.353131', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:12,355 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:12,443 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:11:12,575 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:11:12,582 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:11:12,584 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:11:12,585 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:11:12,586 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:11:12,587 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:11:13,336 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:11:13,351 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:11:13,364 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:11:13,366 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:11:13,370 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:11:13,384 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:11:13,389 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:11:13,395 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:11:13,398 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:11:13,412 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:11:13,416 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:11:13,420 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:11:13,425 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:11:13,428 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:11:13,429 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:11:13,434 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:11:13,437 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:11:13,450 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:11:13,460 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:11:13,461 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:11:13,468 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:11:13,470 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:11:13,482 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:11:13,484 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:11:13,486 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:11:13,490 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:11:13,495 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:11:13,513 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:11:13,527 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:11:13,538 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:11:13,541 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:11:13,542 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:11:13,546 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:11:13,548 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:11:13,550 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:11:13,554 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:11:13,566 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:11:13,569 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:11:13,571 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:11:13,573 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:11:13,576 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:11:13,581 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:11:13,585 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:11:13,592 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:11:13,593 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:11:13,606 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:11:13,612 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:11:13,624 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:11:13,626 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:11:13,627 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:11:13,629 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:11:13,631 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:11:13,686 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:13,719 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:11:13,910 - INFO - 第 5 折评估完成: NPMI=0.4889, Diversity=0.4400, Optimal Score=0.4644\n",
      "实验进度:  25%|██▌       | 15/60 [00:41<02:03,  2.74s/it]2024-11-24 21:11:13,910 - INFO - \n",
      "评估阈值组合: min_freq=2, max_freq=2000\n",
      "2024-11-24 21:11:13,912 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:13,993 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:11:13,993 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:11:13.993833', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:13,997 - INFO - discarding 6839 tokens: [('element', 9), ('grando', 6), ('terraemotus', 5), ('aaron', 7), ('asper', 9), ('latus', 7), ('leichnam', 3), ('noe', 10), ('perforo', 7), ('phoenica', 11)]...\n",
      "2024-11-24 21:11:13,998 - INFO - keeping 2000 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:13,999 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:11:14,000 - INFO - 词典过滤: 8839 -> 2000 个词\n",
      "2024-11-24 21:11:14,067 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:14,068 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:14,069 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:14,072 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:14,072 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:14,072 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:14,483 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:14,484 - INFO - topic #0 (0.067): 0.023*\"vita\" + 0.022*\"christus\" + 0.021*\"spiritus\" + 0.019*\"pater\" + 0.014*\"filius\" + 0.010*\"veritas\" + 0.008*\"sanctus\" + 0.008*\"venio\" + 0.008*\"verbum\" + 0.007*\"cognosco\"\n",
      "2024-11-24 21:11:14,485 - INFO - topic #8 (0.067): 0.024*\"spiritus\" + 0.020*\"christus\" + 0.016*\"verbum\" + 0.015*\"vita\" + 0.012*\"intellectus\" + 0.012*\"fides\" + 0.009*\"symbatios\" + 0.009*\"panis\" + 0.007*\"cognosco\" + 0.007*\"lex\"\n",
      "2024-11-24 21:11:14,485 - INFO - topic #14 (0.067): 0.021*\"vita\" + 0.016*\"fides\" + 0.013*\"spiritus\" + 0.012*\"delphi\" + 0.011*\"gegen\" + 0.010*\"christus\" + 0.009*\"venio\" + 0.008*\"mundus\" + 0.008*\"homo\" + 0.008*\"symbatios\"\n",
      "2024-11-24 21:11:14,485 - INFO - topic #1 (0.067): 0.033*\"christus\" + 0.021*\"und\" + 0.015*\"fides\" + 0.014*\"mundus\" + 0.013*\"regnum\" + 0.012*\"dies\" + 0.011*\"filius\" + 0.010*\"verbum\" + 0.009*\"wir\" + 0.008*\"homo\"\n",
      "2024-11-24 21:11:14,486 - INFO - topic #3 (0.067): 0.037*\"spiritus\" + 0.019*\"vita\" + 0.015*\"lux\" + 0.014*\"mors\" + 0.013*\"delphi\" + 0.013*\"christus\" + 0.009*\"mundus\" + 0.008*\"filius\" + 0.008*\"verbum\" + 0.008*\"sanctus\"\n",
      "2024-11-24 21:11:14,486 - INFO - topic diff=3.569692, rho=1.000000\n",
      "2024-11-24 21:11:15,128 - INFO - -7.230 per-word bound, 150.2 perplexity estimate based on a held-out corpus of 1716 documents with 87656 words\n",
      "2024-11-24 21:11:15,134 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:15,469 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:15,471 - INFO - topic #11 (0.067): 0.019*\"christus\" + 0.017*\"rex\" + 0.013*\"homo\" + 0.013*\"locus\" + 0.012*\"corpus\" + 0.012*\"delphi\" + 0.011*\"peccatum\" + 0.011*\"natura\" + 0.010*\"ratio\" + 0.008*\"venio\"\n",
      "2024-11-24 21:11:15,471 - INFO - topic #3 (0.067): 0.048*\"spiritus\" + 0.028*\"lux\" + 0.023*\"mors\" + 0.019*\"vita\" + 0.018*\"delphi\" + 0.014*\"tenebrae\" + 0.014*\"christus\" + 0.009*\"verbum\" + 0.009*\"sanctus\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:11:15,471 - INFO - topic #14 (0.067): 0.024*\"vita\" + 0.021*\"fides\" + 0.014*\"delphi\" + 0.013*\"symbatios\" + 0.013*\"gegen\" + 0.011*\"clotho\" + 0.010*\"spiritus\" + 0.010*\"iustitia\" + 0.008*\"christus\" + 0.008*\"homo\"\n",
      "2024-11-24 21:11:15,472 - INFO - topic #7 (0.067): 0.026*\"homo\" + 0.022*\"verbum\" + 0.019*\"filius\" + 0.017*\"christus\" + 0.017*\"natura\" + 0.016*\"pater\" + 0.015*\"spiritus\" + 0.013*\"vita\" + 0.010*\"larissa\" + 0.009*\"mundus\"\n",
      "2024-11-24 21:11:15,472 - INFO - topic #0 (0.067): 0.028*\"christus\" + 0.025*\"vita\" + 0.023*\"pater\" + 0.020*\"spiritus\" + 0.016*\"filius\" + 0.014*\"veritas\" + 0.012*\"nomen\" + 0.011*\"sanctus\" + 0.010*\"venio\" + 0.009*\"credo\"\n",
      "2024-11-24 21:11:15,472 - INFO - topic diff=0.968955, rho=0.707107\n",
      "2024-11-24 21:11:15,473 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.40s', 'datetime': '2024-11-24T21:11:15.473170', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:15,476 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:16,056 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:11:16,059 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:11:16,061 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:11:16,063 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:11:16,065 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:11:16,066 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:11:16,068 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:11:16,610 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:11:16,668 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:11:16,692 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:11:16,715 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:11:16,721 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:11:16,734 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:11:16,763 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:11:16,776 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:11:16,826 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:11:16,845 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:11:16,863 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:11:16,866 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:11:16,868 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:11:16,870 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:11:16,875 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:11:16,877 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:11:16,882 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:11:16,884 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:11:16,888 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:11:16,890 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:11:16,892 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:11:16,909 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:11:16,912 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:11:16,917 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:11:16,920 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:11:16,923 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:11:16,929 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:11:16,937 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:11:16,944 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:11:16,950 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:11:16,956 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:11:16,962 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:11:16,970 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:11:16,975 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:11:16,978 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:11:16,985 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:11:16,994 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:11:16,999 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:11:17,026 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:11:17,034 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:11:17,036 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:11:17,042 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:11:17,044 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:11:17,045 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:11:17,056 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:11:17,071 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:11:17,075 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:11:17,077 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:11:17,080 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:11:17,085 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:11:17,089 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:11:17,092 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:11:17,232 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:17,248 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:11:17,451 - INFO - 第 1 折评估完成: NPMI=0.4849, Diversity=0.4400, Optimal Score=0.4625\n",
      "实验进度:  27%|██▋       | 16/60 [00:45<02:11,  2.98s/it]2024-11-24 21:11:17,452 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:17,533 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:11:17,534 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:11:17.534290', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:17,537 - INFO - discarding 6896 tokens: [('aaron', 7), ('asper', 8), ('element', 7), ('grando', 6), ('latus', 7), ('leichnam', 2), ('perforo', 5), ('phoenica', 10), ('potestativus', 1), ('primitivus', 3)]...\n",
      "2024-11-24 21:11:17,538 - INFO - keeping 2000 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:17,539 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:11:17,540 - INFO - 词典过滤: 8896 -> 2000 个词\n",
      "2024-11-24 21:11:17,593 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:17,594 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:17,595 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:17,596 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:17,596 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:17,597 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:17,980 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:17,981 - INFO - topic #0 (0.067): 0.028*\"vita\" + 0.020*\"delphi\" + 0.016*\"corpus\" + 0.013*\"spiritus\" + 0.010*\"christus\" + 0.008*\"virtus\" + 0.008*\"nomen\" + 0.008*\"vivo\" + 0.008*\"pulchritudo\" + 0.007*\"verbum\"\n",
      "2024-11-24 21:11:17,981 - INFO - topic #8 (0.067): 0.020*\"christus\" + 0.013*\"pater\" + 0.013*\"intellectus\" + 0.012*\"volo\" + 0.011*\"filius\" + 0.011*\"vita\" + 0.009*\"intellego\" + 0.009*\"mors\" + 0.008*\"verbum\" + 0.008*\"fides\"\n",
      "2024-11-24 21:11:17,982 - INFO - topic #14 (0.067): 0.016*\"christus\" + 0.014*\"debeo\" + 0.012*\"rex\" + 0.010*\"homo\" + 0.010*\"dies\" + 0.010*\"vita\" + 0.007*\"cognosco\" + 0.007*\"volo\" + 0.006*\"dominus\" + 0.006*\"veritas\"\n",
      "2024-11-24 21:11:17,982 - INFO - topic #1 (0.067): 0.015*\"christus\" + 0.014*\"verbum\" + 0.013*\"rex\" + 0.013*\"homo\" + 0.012*\"spiritus\" + 0.009*\"vita\" + 0.009*\"larissa\" + 0.009*\"sapientia\" + 0.008*\"pater\" + 0.008*\"oboedio\"\n",
      "2024-11-24 21:11:17,982 - INFO - topic #3 (0.067): 0.031*\"christus\" + 0.015*\"und\" + 0.014*\"dies\" + 0.013*\"uns\" + 0.012*\"lex\" + 0.011*\"wir\" + 0.009*\"unser\" + 0.009*\"fides\" + 0.009*\"amor\" + 0.008*\"finis\"\n",
      "2024-11-24 21:11:17,983 - INFO - topic diff=3.533654, rho=1.000000\n",
      "2024-11-24 21:11:18,529 - INFO - -7.234 per-word bound, 150.6 perplexity estimate based on a held-out corpus of 1716 documents with 87826 words\n",
      "2024-11-24 21:11:18,531 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:18,851 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:18,852 - INFO - topic #11 (0.067): 0.036*\"christus\" + 0.035*\"veritas\" + 0.015*\"vita\" + 0.010*\"via\" + 0.010*\"verus\" + 0.009*\"filius\" + 0.008*\"mundus\" + 0.008*\"intellectus\" + 0.008*\"venio\" + 0.008*\"mors\"\n",
      "2024-11-24 21:11:18,853 - INFO - topic #3 (0.067): 0.046*\"dies\" + 0.033*\"lex\" + 0.032*\"christus\" + 0.025*\"annus\" + 0.012*\"sabbatum\" + 0.011*\"iesse\" + 0.010*\"primus\" + 0.010*\"finis\" + 0.008*\"abraham\" + 0.008*\"ecclesia\"\n",
      "2024-11-24 21:11:18,853 - INFO - topic #14 (0.067): 0.020*\"christus\" + 0.018*\"dies\" + 0.016*\"debeo\" + 0.010*\"annus\" + 0.009*\"dominus\" + 0.008*\"homo\" + 0.008*\"rex\" + 0.007*\"volo\" + 0.007*\"dimitto\" + 0.006*\"sanctus\"\n",
      "2024-11-24 21:11:18,854 - INFO - topic #7 (0.067): 0.030*\"spiritus\" + 0.019*\"virtus\" + 0.017*\"vita\" + 0.016*\"ars\" + 0.015*\"delphi\" + 0.013*\"amor\" + 0.012*\"sanctus\" + 0.012*\"motus\" + 0.009*\"natura\" + 0.009*\"imago\"\n",
      "2024-11-24 21:11:18,855 - INFO - topic #0 (0.067): 0.034*\"vita\" + 0.025*\"delphi\" + 0.020*\"corpus\" + 0.015*\"nomen\" + 0.011*\"spiritus\" + 0.009*\"vivo\" + 0.009*\"christus\" + 0.008*\"amor\" + 0.008*\"gloria\" + 0.008*\"dominus\"\n",
      "2024-11-24 21:11:18,855 - INFO - topic diff=1.005497, rho=0.707107\n",
      "2024-11-24 21:11:18,856 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.26s', 'datetime': '2024-11-24T21:11:18.856743', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:18,861 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:19,365 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:11:19,369 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:11:19,371 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:11:19,372 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:11:19,373 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:11:19,374 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:11:19,378 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:11:19,871 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:11:19,976 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:11:20,022 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:11:20,069 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:11:20,092 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:11:20,127 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:11:20,163 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:11:20,213 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:11:20,225 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:11:20,235 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:11:20,245 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:11:20,247 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:11:20,249 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:11:20,251 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:11:20,261 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:11:20,267 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:11:20,277 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:11:20,279 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:11:20,283 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:11:20,286 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:11:20,297 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:11:20,309 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:11:20,312 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:11:20,314 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:11:20,319 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:11:20,324 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:11:20,329 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:11:20,333 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:11:20,336 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:11:20,340 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:11:20,345 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:11:20,365 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:11:20,374 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:11:20,377 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:11:20,400 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:11:20,403 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:11:20,406 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:11:20,420 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:11:20,425 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:11:20,435 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:11:20,439 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:11:20,441 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:11:20,445 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:11:20,448 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:11:20,462 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:11:20,467 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:11:20,468 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:11:20,471 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:11:20,477 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:11:20,484 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:11:20,499 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:11:20,501 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:11:20,561 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:20,570 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:11:20,758 - INFO - 第 2 折评估完成: NPMI=0.4907, Diversity=0.4400, Optimal Score=0.4653\n",
      "实验进度:  28%|██▊       | 17/60 [00:48<02:12,  3.08s/it]2024-11-24 21:11:20,760 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:20,840 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:11:20,840 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:11:20.840747', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:20,844 - INFO - discarding 6834 tokens: [('element', 9), ('grando', 6), ('terraemotus', 6), ('aaron', 8), ('asper', 9), ('latus', 7), ('leichnam', 2), ('noe', 10), ('perforo', 8), ('potestativus', 2)]...\n",
      "2024-11-24 21:11:20,844 - INFO - keeping 2000 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:20,845 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:11:20,846 - INFO - 词典过滤: 8834 -> 2000 个词\n",
      "2024-11-24 21:11:20,899 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:20,899 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:20,900 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:20,902 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:20,902 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:20,902 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:21,297 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:21,298 - INFO - topic #0 (0.067): 0.026*\"christus\" + 0.017*\"und\" + 0.012*\"virtus\" + 0.010*\"spiritus\" + 0.009*\"natura\" + 0.009*\"rex\" + 0.008*\"dies\" + 0.007*\"imago\" + 0.007*\"homo\" + 0.007*\"filius\"\n",
      "2024-11-24 21:11:21,299 - INFO - topic #8 (0.067): 0.022*\"delphi\" + 0.017*\"christus\" + 0.016*\"vita\" + 0.014*\"verbum\" + 0.009*\"spiritus\" + 0.009*\"amor\" + 0.009*\"sapientia\" + 0.009*\"fides\" + 0.008*\"pater\" + 0.008*\"ratio\"\n",
      "2024-11-24 21:11:21,299 - INFO - topic #14 (0.067): 0.021*\"vita\" + 0.020*\"homo\" + 0.017*\"sapientia\" + 0.014*\"spiritus\" + 0.011*\"venio\" + 0.009*\"christus\" + 0.009*\"mundus\" + 0.009*\"ratio\" + 0.008*\"amor\" + 0.007*\"scio\"\n",
      "2024-11-24 21:11:21,299 - INFO - topic #1 (0.067): 0.029*\"christus\" + 0.018*\"vita\" + 0.016*\"filius\" + 0.016*\"homo\" + 0.011*\"verbum\" + 0.011*\"mundus\" + 0.009*\"pater\" + 0.009*\"virtus\" + 0.009*\"regnum\" + 0.009*\"intellego\"\n",
      "2024-11-24 21:11:21,300 - INFO - topic #3 (0.067): 0.012*\"pulchritudo\" + 0.011*\"christus\" + 0.010*\"natura\" + 0.009*\"virtus\" + 0.008*\"finis\" + 0.007*\"delphi\" + 0.007*\"imago\" + 0.007*\"lux\" + 0.007*\"ratio\" + 0.007*\"pulcher\"\n",
      "2024-11-24 21:11:21,300 - INFO - topic diff=3.612133, rho=1.000000\n",
      "2024-11-24 21:11:21,689 - INFO - -7.224 per-word bound, 149.5 perplexity estimate based on a held-out corpus of 1716 documents with 86367 words\n",
      "2024-11-24 21:11:21,689 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:22,008 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:22,009 - INFO - topic #11 (0.067): 0.016*\"sermo\" + 0.015*\"homo\" + 0.014*\"mitto\" + 0.012*\"christus\" + 0.012*\"filius\" + 0.011*\"iudico\" + 0.011*\"dies\" + 0.011*\"misericordia\" + 0.011*\"loquor\" + 0.010*\"spiritus\"\n",
      "2024-11-24 21:11:22,010 - INFO - topic #3 (0.067): 0.020*\"ars\" + 0.016*\"pulchritudo\" + 0.014*\"imago\" + 0.010*\"natura\" + 0.009*\"annus\" + 0.008*\"perfectus\" + 0.008*\"intellectus\" + 0.007*\"virtus\" + 0.007*\"lux\" + 0.007*\"ratio\"\n",
      "2024-11-24 21:11:22,010 - INFO - topic #14 (0.067): 0.026*\"homo\" + 0.025*\"sapientia\" + 0.020*\"vita\" + 0.013*\"spiritus\" + 0.009*\"mundus\" + 0.009*\"iustitia\" + 0.009*\"amor\" + 0.008*\"annas\" + 0.008*\"trinitas\" + 0.008*\"gratia\"\n",
      "2024-11-24 21:11:22,010 - INFO - topic #7 (0.067): 0.026*\"spiritus\" + 0.020*\"pater\" + 0.020*\"filius\" + 0.020*\"christus\" + 0.020*\"verbum\" + 0.013*\"homo\" + 0.010*\"nomen\" + 0.010*\"lux\" + 0.009*\"vita\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:11:22,011 - INFO - topic #0 (0.067): 0.022*\"christus\" + 0.012*\"dies\" + 0.010*\"virtus\" + 0.008*\"rex\" + 0.007*\"und\" + 0.007*\"natura\" + 0.007*\"imago\" + 0.006*\"spiritus\" + 0.006*\"mundus\" + 0.006*\"dominus\"\n",
      "2024-11-24 21:11:22,011 - INFO - topic diff=1.002165, rho=0.707107\n",
      "2024-11-24 21:11:22,012 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.11s', 'datetime': '2024-11-24T21:11:22.011991', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:22,014 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:22,420 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:11:22,423 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:11:22,426 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:11:22,427 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:11:22,429 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:11:22,431 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:11:22,433 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:11:23,186 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:11:23,208 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:11:23,236 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:11:23,244 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:11:23,274 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:11:23,278 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:11:23,280 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:11:23,285 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:11:23,287 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:11:23,299 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:11:23,302 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:11:23,312 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:11:23,329 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:11:23,331 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:11:23,333 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:11:23,335 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:11:23,344 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:11:23,347 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:11:23,352 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:11:23,365 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:11:23,370 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:11:23,375 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:11:23,388 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:11:23,395 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:11:23,400 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:11:23,406 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:11:23,412 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:11:23,424 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:11:23,430 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:11:23,446 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:11:23,451 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:11:23,455 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:11:23,474 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:11:23,512 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:11:23,515 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:11:23,518 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:11:23,520 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:11:23,527 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:11:23,536 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:11:23,551 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:11:23,567 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:11:23,578 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:11:23,581 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:11:23,584 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:11:23,587 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:11:23,592 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:11:23,594 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:11:23,602 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:11:23,611 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:11:23,619 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:11:23,623 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:11:23,625 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:11:23,719 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:23,729 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:11:23,923 - INFO - 第 3 折评估完成: NPMI=0.4857, Diversity=0.4133, Optimal Score=0.4495\n",
      "实验进度:  30%|███       | 18/60 [00:51<02:10,  3.10s/it]2024-11-24 21:11:23,925 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:24,003 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:11:24,003 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:11:24.003844', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:24,007 - INFO - discarding 6885 tokens: [('element', 6), ('grando', 3), ('terraemotus', 3), ('anatomia', 1), ('caesarius', 10), ('carnalitas', 7), ('deauro', 4), ('durities', 4), ('foramen', 2), ('innitor', 9)]...\n",
      "2024-11-24 21:11:24,007 - INFO - keeping 2000 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:24,008 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:11:24,009 - INFO - 词典过滤: 8885 -> 2000 个词\n",
      "2024-11-24 21:11:24,059 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:24,060 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:24,060 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:24,062 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:24,062 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:24,062 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:24,451 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:24,452 - INFO - topic #0 (0.067): 0.032*\"und\" + 0.016*\"wir\" + 0.016*\"ratio\" + 0.013*\"spiritus\" + 0.012*\"dies\" + 0.010*\"christus\" + 0.008*\"delphi\" + 0.008*\"homo\" + 0.008*\"vita\" + 0.007*\"intellectus\"\n",
      "2024-11-24 21:11:24,453 - INFO - topic #8 (0.067): 0.024*\"vita\" + 0.020*\"christus\" + 0.019*\"verbum\" + 0.018*\"homo\" + 0.016*\"mundus\" + 0.012*\"filius\" + 0.011*\"pater\" + 0.010*\"spiritus\" + 0.009*\"intellectus\" + 0.009*\"panis\"\n",
      "2024-11-24 21:11:24,453 - INFO - topic #14 (0.067): 0.018*\"christus\" + 0.015*\"spiritus\" + 0.014*\"delphi\" + 0.014*\"natura\" + 0.013*\"vita\" + 0.009*\"pater\" + 0.009*\"volo\" + 0.009*\"homo\" + 0.008*\"venio\" + 0.008*\"debeo\"\n",
      "2024-11-24 21:11:24,453 - INFO - topic #1 (0.067): 0.014*\"mundus\" + 0.014*\"homo\" + 0.014*\"ratio\" + 0.013*\"spiritus\" + 0.011*\"verbum\" + 0.009*\"virtus\" + 0.009*\"christus\" + 0.008*\"volo\" + 0.008*\"vita\" + 0.008*\"larissa\"\n",
      "2024-11-24 21:11:24,454 - INFO - topic #3 (0.067): 0.016*\"filius\" + 0.014*\"christus\" + 0.014*\"delphi\" + 0.013*\"pater\" + 0.011*\"mors\" + 0.011*\"evangelium\" + 0.010*\"spiritus\" + 0.010*\"vita\" + 0.010*\"pulchritudo\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:11:24,454 - INFO - topic diff=3.390296, rho=1.000000\n",
      "2024-11-24 21:11:24,846 - INFO - -7.235 per-word bound, 150.7 perplexity estimate based on a held-out corpus of 1716 documents with 86959 words\n",
      "2024-11-24 21:11:24,846 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:25,165 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:25,167 - INFO - topic #11 (0.067): 0.027*\"homo\" + 0.019*\"spiritus\" + 0.018*\"christus\" + 0.014*\"veritas\" + 0.014*\"virtus\" + 0.013*\"sapientia\" + 0.011*\"vita\" + 0.011*\"verbum\" + 0.011*\"mundus\" + 0.010*\"fides\"\n",
      "2024-11-24 21:11:25,167 - INFO - topic #3 (0.067): 0.019*\"filius\" + 0.019*\"lex\" + 0.017*\"pater\" + 0.013*\"delphi\" + 0.013*\"mors\" + 0.013*\"veritas\" + 0.013*\"christus\" + 0.012*\"evangelium\" + 0.011*\"pulchritudo\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:11:25,167 - INFO - topic #14 (0.067): 0.018*\"delphi\" + 0.018*\"christus\" + 0.017*\"natura\" + 0.012*\"spiritus\" + 0.011*\"vita\" + 0.010*\"homo\" + 0.010*\"corpus\" + 0.009*\"debeo\" + 0.008*\"volo\" + 0.008*\"creatura\"\n",
      "2024-11-24 21:11:25,168 - INFO - topic #7 (0.067): 0.028*\"filius\" + 0.018*\"christus\" + 0.015*\"homo\" + 0.014*\"natura\" + 0.014*\"verbum\" + 0.013*\"pater\" + 0.012*\"gratia\" + 0.011*\"larissa\" + 0.011*\"fides\" + 0.009*\"gloria\"\n",
      "2024-11-24 21:11:25,168 - INFO - topic #0 (0.067): 0.028*\"ratio\" + 0.021*\"und\" + 0.013*\"dies\" + 0.011*\"wir\" + 0.009*\"sensus\" + 0.009*\"spiritus\" + 0.009*\"intellectus\" + 0.008*\"nomen\" + 0.008*\"vir\" + 0.007*\"scio\"\n",
      "2024-11-24 21:11:25,169 - INFO - topic diff=0.959596, rho=0.707107\n",
      "2024-11-24 21:11:25,169 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.11s', 'datetime': '2024-11-24T21:11:25.169502', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:25,172 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:25,586 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:11:25,589 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:11:25,590 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:11:25,591 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:11:25,592 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:11:25,594 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:11:25,596 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:11:26,364 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:11:26,420 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:11:26,434 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:11:26,476 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:11:26,478 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:11:26,493 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:11:26,506 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:11:26,508 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:11:26,510 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:11:26,515 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:11:26,519 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:11:26,531 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:11:26,535 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:11:26,536 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:11:26,538 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:11:26,544 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:11:26,545 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:11:26,548 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:11:26,549 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:11:26,556 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:11:26,561 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:11:26,575 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:11:26,577 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:11:26,590 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:11:26,596 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:11:26,599 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:11:26,601 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:11:26,602 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:11:26,615 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:11:26,617 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:11:26,621 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:11:26,627 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:11:26,632 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:11:26,635 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:11:26,645 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:11:26,661 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:11:26,666 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:11:26,668 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:11:26,672 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:11:26,675 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:11:26,677 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:11:26,678 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:11:26,684 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:11:26,691 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:11:26,699 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:11:26,701 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:11:26,704 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:11:26,705 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:11:26,708 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:11:26,715 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:11:26,721 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:11:26,725 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:11:26,812 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:26,838 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:11:27,080 - INFO - 第 4 折评估完成: NPMI=0.4823, Diversity=0.4000, Optimal Score=0.4411\n",
      "实验进度:  32%|███▏      | 19/60 [00:54<02:07,  3.12s/it]2024-11-24 21:11:27,083 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:27,171 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:11:27,172 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:11:27.172110', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:27,176 - INFO - discarding 6903 tokens: [('element', 9), ('grando', 7), ('terraemotus', 5), ('aaron', 5), ('asper', 10), ('latus', 7), ('leichnam', 3), ('perforo', 7), ('potestativus', 2), ('primitivus', 3)]...\n",
      "2024-11-24 21:11:27,176 - INFO - keeping 2000 tokens which were in no less than 2 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:27,177 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:11:27,178 - INFO - 词典过滤: 8903 -> 2000 个词\n",
      "2024-11-24 21:11:27,245 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:27,246 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:27,247 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:27,248 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:27,249 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:27,249 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:27,640 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:27,641 - INFO - topic #0 (0.067): 0.020*\"christus\" + 0.019*\"spiritus\" + 0.016*\"homo\" + 0.014*\"mors\" + 0.013*\"virtus\" + 0.013*\"vita\" + 0.010*\"volo\" + 0.010*\"filius\" + 0.009*\"delphi\" + 0.008*\"verbum\"\n",
      "2024-11-24 21:11:27,641 - INFO - topic #8 (0.067): 0.022*\"christus\" + 0.015*\"verbum\" + 0.013*\"natura\" + 0.013*\"lux\" + 0.011*\"gegen\" + 0.010*\"homo\" + 0.009*\"filius\" + 0.009*\"spiritus\" + 0.009*\"corpus\" + 0.008*\"fides\"\n",
      "2024-11-24 21:11:27,642 - INFO - topic #14 (0.067): 0.019*\"pater\" + 0.013*\"christus\" + 0.012*\"rex\" + 0.012*\"mundus\" + 0.012*\"homo\" + 0.012*\"filius\" + 0.010*\"gloria\" + 0.009*\"spiritus\" + 0.009*\"barabbas\" + 0.008*\"venio\"\n",
      "2024-11-24 21:11:27,642 - INFO - topic #1 (0.067): 0.027*\"christus\" + 0.022*\"spiritus\" + 0.011*\"verbum\" + 0.010*\"sanctus\" + 0.010*\"vita\" + 0.009*\"pater\" + 0.009*\"intellectus\" + 0.009*\"virtus\" + 0.009*\"homo\" + 0.009*\"mundus\"\n",
      "2024-11-24 21:11:27,642 - INFO - topic #3 (0.067): 0.023*\"regnum\" + 0.022*\"spiritus\" + 0.014*\"christus\" + 0.012*\"larissa\" + 0.010*\"vita\" + 0.009*\"mundus\" + 0.009*\"gratia\" + 0.008*\"delphi\" + 0.007*\"homo\" + 0.007*\"iustitia\"\n",
      "2024-11-24 21:11:27,642 - INFO - topic diff=3.291545, rho=1.000000\n",
      "2024-11-24 21:11:28,044 - INFO - -7.279 per-word bound, 155.3 perplexity estimate based on a held-out corpus of 1716 documents with 87835 words\n",
      "2024-11-24 21:11:28,044 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:28,354 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:28,355 - INFO - topic #11 (0.067): 0.019*\"spiritus\" + 0.017*\"sapientia\" + 0.014*\"magister\" + 0.012*\"homo\" + 0.012*\"christus\" + 0.011*\"delphi\" + 0.011*\"verbum\" + 0.010*\"mundus\" + 0.009*\"vita\" + 0.007*\"recipio\"\n",
      "2024-11-24 21:11:28,355 - INFO - topic #3 (0.067): 0.030*\"regnum\" + 0.019*\"spiritus\" + 0.017*\"larissa\" + 0.013*\"christus\" + 0.013*\"gratia\" + 0.009*\"vita\" + 0.009*\"dies\" + 0.008*\"peccatum\" + 0.008*\"mundus\" + 0.007*\"gaudium\"\n",
      "2024-11-24 21:11:28,356 - INFO - topic #14 (0.067): 0.018*\"pater\" + 0.014*\"gloria\" + 0.013*\"christus\" + 0.011*\"barabbas\" + 0.010*\"rex\" + 0.010*\"mundus\" + 0.010*\"homo\" + 0.010*\"larissa\" + 0.010*\"nomen\" + 0.009*\"filius\"\n",
      "2024-11-24 21:11:28,356 - INFO - topic #7 (0.067): 0.039*\"pater\" + 0.030*\"verbum\" + 0.027*\"christus\" + 0.023*\"filius\" + 0.017*\"spiritus\" + 0.015*\"homo\" + 0.010*\"loquor\" + 0.010*\"bonus\" + 0.009*\"mitto\" + 0.008*\"sanctus\"\n",
      "2024-11-24 21:11:28,356 - INFO - topic #0 (0.067): 0.019*\"mors\" + 0.019*\"spiritus\" + 0.018*\"christus\" + 0.018*\"homo\" + 0.012*\"vita\" + 0.010*\"delphi\" + 0.010*\"volo\" + 0.010*\"virtus\" + 0.009*\"amor\" + 0.007*\"filius\"\n",
      "2024-11-24 21:11:28,357 - INFO - topic diff=0.932602, rho=0.707107\n",
      "2024-11-24 21:11:28,357 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.11s', 'datetime': '2024-11-24T21:11:28.357464', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:28,360 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:28,775 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:11:28,779 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:11:28,780 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:11:28,782 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:11:28,784 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:11:28,786 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:11:28,787 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:11:29,517 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:11:29,543 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:11:29,585 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:11:29,617 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:11:29,641 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:11:29,653 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:11:29,667 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:11:29,676 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:11:29,727 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:11:29,752 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:11:29,766 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:11:29,767 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:11:29,769 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:11:29,770 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:11:29,772 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:11:29,773 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:11:29,777 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:11:29,778 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:11:29,780 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:11:29,787 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:11:29,796 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:11:29,801 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:11:29,803 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:11:29,805 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:11:29,807 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:11:29,809 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:11:29,822 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:11:29,830 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:11:29,831 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:11:29,833 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:11:29,841 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:11:29,857 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:11:29,864 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:11:29,867 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:11:29,876 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:11:29,878 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:11:29,880 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:11:29,890 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:11:29,921 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:11:29,927 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:11:29,930 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:11:29,932 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:11:30,086 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:11:30,115 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:11:30,118 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:11:30,121 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:11:30,131 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:11:30,152 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:11:30,157 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:11:30,163 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:11:30,168 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:11:30,169 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:11:30,258 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:30,272 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:11:30,458 - INFO - 第 5 折评估完成: NPMI=0.4909, Diversity=0.3733, Optimal Score=0.4321\n",
      "实验进度:  33%|███▎      | 20/60 [00:58<02:07,  3.20s/it]2024-11-24 21:11:30,459 - INFO - \n",
      "评估阈值组合: min_freq=3, max_freq=200\n",
      "2024-11-24 21:11:30,461 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:30,539 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:11:30,540 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:11:30.540289', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:30,543 - INFO - discarding 8639 tokens: [('apocalypsis', 16), ('constantinus', 35), ('corona', 25), ('element', 9), ('expono', 81), ('generalis', 29), ('gloriosus', 75), ('grando', 6), ('ioannes', 83), ('luna', 60)]...\n",
      "2024-11-24 21:11:30,543 - INFO - keeping 200 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:30,544 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'larissa']...>\n",
      "2024-11-24 21:11:30,545 - INFO - 词典过滤: 8839 -> 200 个词\n",
      "2024-11-24 21:11:30,584 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:30,584 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:30,585 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:30,585 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:30,585 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:30,586 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:30,899 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:30,900 - INFO - topic #13 (0.067): 0.067*\"amor\" + 0.037*\"filius\" + 0.031*\"pater\" + 0.025*\"spiritus\" + 0.021*\"clotho\" + 0.021*\"imago\" + 0.020*\"morior\" + 0.020*\"mors\" + 0.018*\"unio\" + 0.017*\"natura\"\n",
      "2024-11-24 21:11:30,900 - INFO - topic #8 (0.067): 0.047*\"virtus\" + 0.033*\"christus\" + 0.028*\"homo\" + 0.025*\"spiritus\" + 0.022*\"delphi\" + 0.022*\"vita\" + 0.020*\"dominus\" + 0.020*\"mens\" + 0.015*\"filius\" + 0.015*\"fides\"\n",
      "2024-11-24 21:11:30,900 - INFO - topic #14 (0.067): 0.098*\"christus\" + 0.055*\"spiritus\" + 0.029*\"vita\" + 0.020*\"homo\" + 0.017*\"fides\" + 0.017*\"filius\" + 0.015*\"mundus\" + 0.014*\"corpus\" + 0.014*\"lex\" + 0.013*\"pater\"\n",
      "2024-11-24 21:11:30,901 - INFO - topic #7 (0.067): 0.058*\"spiritus\" + 0.037*\"delphi\" + 0.025*\"gloria\" + 0.025*\"christus\" + 0.024*\"vita\" + 0.023*\"pater\" + 0.020*\"verbum\" + 0.020*\"motus\" + 0.019*\"filius\" + 0.018*\"divinus\"\n",
      "2024-11-24 21:11:30,901 - INFO - topic #9 (0.067): 0.062*\"dies\" + 0.058*\"christus\" + 0.024*\"mundus\" + 0.022*\"vita\" + 0.017*\"peccatum\" + 0.015*\"regnum\" + 0.015*\"delphi\" + 0.014*\"osdroena\" + 0.014*\"annas\" + 0.014*\"spiritus\"\n",
      "2024-11-24 21:11:30,901 - INFO - topic diff=0.791286, rho=1.000000\n",
      "2024-11-24 21:11:31,204 - INFO - -5.186 per-word bound, 36.4 perplexity estimate based on a held-out corpus of 1716 documents with 45975 words\n",
      "2024-11-24 21:11:31,205 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:31,449 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:31,450 - INFO - topic #12 (0.067): 0.085*\"spiritus\" + 0.044*\"verbum\" + 0.039*\"vita\" + 0.029*\"sanctus\" + 0.024*\"christus\" + 0.022*\"debeo\" + 0.021*\"homo\" + 0.021*\"via\" + 0.020*\"regnum\" + 0.017*\"veritas\"\n",
      "2024-11-24 21:11:31,450 - INFO - topic #6 (0.067): 0.085*\"pater\" + 0.062*\"filius\" + 0.039*\"mundus\" + 0.036*\"venio\" + 0.034*\"lux\" + 0.023*\"sanctus\" + 0.023*\"larissa\" + 0.022*\"christus\" + 0.020*\"rex\" + 0.015*\"cognosco\"\n",
      "2024-11-24 21:11:31,450 - INFO - topic #13 (0.067): 0.082*\"amor\" + 0.039*\"imago\" + 0.039*\"clotho\" + 0.035*\"pater\" + 0.034*\"filius\" + 0.028*\"spiritus\" + 0.024*\"symbatios\" + 0.023*\"unio\" + 0.022*\"morior\" + 0.020*\"sanctus\"\n",
      "2024-11-24 21:11:31,451 - INFO - topic #11 (0.067): 0.056*\"vita\" + 0.038*\"iustitia\" + 0.035*\"homo\" + 0.027*\"natura\" + 0.024*\"vivo\" + 0.022*\"finis\" + 0.017*\"gratia\" + 0.017*\"christus\" + 0.017*\"debeo\" + 0.016*\"filius\"\n",
      "2024-11-24 21:11:31,451 - INFO - topic #0 (0.067): 0.068*\"homo\" + 0.060*\"verbum\" + 0.040*\"nomen\" + 0.033*\"vita\" + 0.026*\"gegen\" + 0.026*\"christus\" + 0.024*\"filius\" + 0.020*\"pater\" + 0.016*\"lux\" + 0.014*\"spiritus\"\n",
      "2024-11-24 21:11:31,451 - INFO - topic diff=0.354127, rho=0.707107\n",
      "2024-11-24 21:11:31,451 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.87s', 'datetime': '2024-11-24T21:11:31.451837', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:31,454 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:31,502 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:11:31,596 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:11:31,599 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:11:31,601 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:11:31,603 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:11:31,605 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:11:31,607 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:11:32,425 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:11:32,445 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:11:32,469 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:11:32,483 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:11:32,499 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:11:32,522 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:11:32,525 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:11:32,527 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:11:32,530 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:11:32,537 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:11:32,545 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:11:32,547 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:11:32,549 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:11:32,555 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:11:32,557 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:11:32,563 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:11:32,567 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:11:32,569 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:11:32,573 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:11:32,579 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:11:32,581 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:11:32,588 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:11:32,593 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:11:32,598 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:11:32,599 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:11:32,605 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:11:32,617 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:11:32,622 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:11:32,624 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:11:32,625 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:11:32,632 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:11:32,635 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:11:32,701 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:11:32,704 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:11:32,716 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:11:32,718 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:11:32,721 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:11:32,728 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:11:32,741 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:11:32,748 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:11:32,766 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:11:32,768 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:11:32,770 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:11:32,776 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:11:32,792 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:11:32,803 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:11:32,807 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:11:32,810 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:11:32,812 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:11:32,830 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:11:32,834 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:11:32,835 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:11:32,906 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:32,923 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:11:33,112 - INFO - 第 1 折评估完成: NPMI=0.4980, Diversity=0.4400, Optimal Score=0.4690\n",
      "实验进度:  35%|███▌      | 21/60 [01:00<01:58,  3.03s/it]2024-11-24 21:11:33,113 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:33,189 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:11:33,189 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:11:33.189872', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:33,193 - INFO - discarding 8696 tokens: [('aaron', 7), ('asper', 8), ('conservo', 66), ('constantinus', 39), ('contritio', 22), ('conversatio', 28), ('correctio', 22), ('crux', 115), ('divinitas', 67), ('dormio', 34)]...\n",
      "2024-11-24 21:11:33,193 - INFO - keeping 200 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:33,194 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'divinus']...>\n",
      "2024-11-24 21:11:33,194 - INFO - 词典过滤: 8896 -> 200 个词\n",
      "2024-11-24 21:11:33,231 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:33,232 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:33,232 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:33,233 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:33,233 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:33,233 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:33,531 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:33,531 - INFO - topic #13 (0.067): 0.042*\"homo\" + 0.042*\"vita\" + 0.041*\"spiritus\" + 0.033*\"filius\" + 0.022*\"natura\" + 0.022*\"amor\" + 0.021*\"regnum\" + 0.017*\"delphi\" + 0.017*\"pater\" + 0.017*\"unitas\"\n",
      "2024-11-24 21:11:33,532 - INFO - topic #8 (0.067): 0.062*\"christus\" + 0.045*\"verbum\" + 0.036*\"delphi\" + 0.022*\"intellego\" + 0.021*\"vita\" + 0.020*\"virtus\" + 0.019*\"homo\" + 0.019*\"corpus\" + 0.018*\"ratio\" + 0.017*\"bonus\"\n",
      "2024-11-24 21:11:33,532 - INFO - topic #14 (0.067): 0.056*\"verbum\" + 0.034*\"christus\" + 0.034*\"pax\" + 0.027*\"spiritus\" + 0.020*\"vita\" + 0.018*\"homo\" + 0.017*\"motus\" + 0.017*\"recipio\" + 0.015*\"sanctus\" + 0.013*\"semen\"\n",
      "2024-11-24 21:11:33,532 - INFO - topic #7 (0.067): 0.042*\"christus\" + 0.027*\"venio\" + 0.022*\"homo\" + 0.021*\"debeo\" + 0.021*\"sapientia\" + 0.020*\"filius\" + 0.019*\"pater\" + 0.019*\"tempus\" + 0.019*\"spiritus\" + 0.018*\"mundus\"\n",
      "2024-11-24 21:11:33,533 - INFO - topic #9 (0.067): 0.040*\"vita\" + 0.033*\"christus\" + 0.030*\"homo\" + 0.028*\"spiritus\" + 0.025*\"delphi\" + 0.022*\"lux\" + 0.019*\"virtus\" + 0.018*\"scio\" + 0.016*\"fides\" + 0.015*\"filius\"\n",
      "2024-11-24 21:11:33,533 - INFO - topic diff=0.766767, rho=1.000000\n",
      "2024-11-24 21:11:33,843 - INFO - -5.191 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 1716 documents with 46207 words\n",
      "2024-11-24 21:11:33,843 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:34,094 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:34,094 - INFO - topic #12 (0.067): 0.081*\"homo\" + 0.057*\"mundus\" + 0.047*\"dies\" + 0.042*\"veritas\" + 0.028*\"quaero\" + 0.025*\"vita\" + 0.021*\"credo\" + 0.018*\"christus\" + 0.017*\"scio\" + 0.013*\"bonus\"\n",
      "2024-11-24 21:11:34,094 - INFO - topic #6 (0.067): 0.048*\"gratia\" + 0.044*\"delphi\" + 0.028*\"homo\" + 0.027*\"natura\" + 0.027*\"dies\" + 0.026*\"dominus\" + 0.024*\"fides\" + 0.023*\"christus\" + 0.019*\"virgo\" + 0.018*\"vita\"\n",
      "2024-11-24 21:11:34,095 - INFO - topic #13 (0.067): 0.051*\"vita\" + 0.045*\"spiritus\" + 0.042*\"homo\" + 0.037*\"amor\" + 0.028*\"natura\" + 0.028*\"filius\" + 0.026*\"regnum\" + 0.020*\"unitas\" + 0.019*\"panis\" + 0.017*\"delphi\"\n",
      "2024-11-24 21:11:34,095 - INFO - topic #11 (0.067): 0.137*\"spiritus\" + 0.037*\"sanctus\" + 0.028*\"motus\" + 0.027*\"mundus\" + 0.023*\"veritas\" + 0.022*\"domus\" + 0.019*\"dominus\" + 0.018*\"virtus\" + 0.018*\"christus\" + 0.017*\"osdroena\"\n",
      "2024-11-24 21:11:34,096 - INFO - topic #0 (0.067): 0.046*\"gegen\" + 0.044*\"intellectus\" + 0.035*\"lux\" + 0.031*\"ratio\" + 0.027*\"delphi\" + 0.026*\"mundus\" + 0.020*\"veritas\" + 0.019*\"sol\" + 0.019*\"virtus\" + 0.019*\"spiritus\"\n",
      "2024-11-24 21:11:34,096 - INFO - topic diff=0.350584, rho=0.707107\n",
      "2024-11-24 21:11:34,096 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.86s', 'datetime': '2024-11-24T21:11:34.096532', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:34,098 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:34,343 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:11:34,355 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:11:34,357 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:11:34,358 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:11:34,359 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:11:34,360 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:11:34,361 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:11:35,226 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:11:35,248 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:11:35,262 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:11:35,271 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:11:35,272 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:11:35,273 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:11:35,278 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:11:35,280 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:11:35,292 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:11:35,295 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:11:35,297 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:11:35,300 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:11:35,328 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:11:35,333 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:11:35,334 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:11:35,341 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:11:35,342 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:11:35,372 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:11:35,403 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:11:35,441 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:11:35,443 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:11:35,446 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:11:35,448 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:11:35,457 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:11:35,462 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:11:35,470 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:11:35,472 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:11:35,474 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:11:35,479 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:11:35,483 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:11:35,490 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:11:35,492 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:11:35,495 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:11:35,519 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:11:35,521 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:11:35,523 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:11:35,524 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:11:35,525 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:11:35,527 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:11:35,528 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:11:35,530 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:11:35,532 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:11:35,534 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:11:35,535 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:11:35,546 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:11:35,548 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:11:35,561 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:11:35,563 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:11:35,570 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:11:35,579 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:11:35,582 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:11:35,589 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:11:35,695 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:35,738 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:11:35,911 - INFO - 第 2 折评估完成: NPMI=0.4980, Diversity=0.4467, Optimal Score=0.4724\n",
      "实验进度:  37%|███▋      | 22/60 [01:03<01:52,  2.96s/it]2024-11-24 21:11:35,913 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:35,998 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:11:35,999 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:11:35.999244', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:36,002 - INFO - discarding 8634 tokens: [('apocalypsis', 13), ('behalten', 129), ('constantinus', 33), ('corona', 28), ('element', 9), ('expono', 80), ('generalis', 26), ('gloriosus', 72), ('grando', 6), ('ioannes', 89)]...\n",
      "2024-11-24 21:11:36,002 - INFO - keeping 200 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:36,003 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:11:36,004 - INFO - 词典过滤: 8834 -> 200 个词\n",
      "2024-11-24 21:11:36,042 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:36,042 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:36,043 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:36,044 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:36,044 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:36,044 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:36,342 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:36,343 - INFO - topic #13 (0.067): 0.040*\"amor\" + 0.038*\"delphi\" + 0.024*\"clotho\" + 0.023*\"filius\" + 0.022*\"pater\" + 0.021*\"vita\" + 0.018*\"verbum\" + 0.017*\"peccatum\" + 0.016*\"spiritus\" + 0.016*\"corpus\"\n",
      "2024-11-24 21:11:36,343 - INFO - topic #8 (0.067): 0.046*\"christus\" + 0.037*\"virtus\" + 0.031*\"debeo\" + 0.029*\"spiritus\" + 0.026*\"homo\" + 0.018*\"delphi\" + 0.016*\"sapientia\" + 0.016*\"vita\" + 0.015*\"pater\" + 0.015*\"verbum\"\n",
      "2024-11-24 21:11:36,344 - INFO - topic #14 (0.067): 0.072*\"christus\" + 0.064*\"spiritus\" + 0.033*\"vita\" + 0.030*\"fides\" + 0.019*\"mundus\" + 0.018*\"homo\" + 0.018*\"debeo\" + 0.014*\"volo\" + 0.014*\"verbum\" + 0.014*\"intellectus\"\n",
      "2024-11-24 21:11:36,344 - INFO - topic #7 (0.067): 0.054*\"spiritus\" + 0.026*\"regnum\" + 0.025*\"christus\" + 0.023*\"verbum\" + 0.023*\"mundus\" + 0.021*\"gloria\" + 0.020*\"filius\" + 0.020*\"vita\" + 0.020*\"motus\" + 0.017*\"sanctus\"\n",
      "2024-11-24 21:11:36,344 - INFO - topic #9 (0.067): 0.113*\"dies\" + 0.025*\"vita\" + 0.022*\"gratia\" + 0.019*\"iustitia\" + 0.018*\"semen\" + 0.017*\"sapientia\" + 0.017*\"annas\" + 0.017*\"mors\" + 0.016*\"reperio\" + 0.016*\"christus\"\n",
      "2024-11-24 21:11:36,345 - INFO - topic diff=0.781915, rho=1.000000\n",
      "2024-11-24 21:11:36,642 - INFO - -5.190 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 1716 documents with 45705 words\n",
      "2024-11-24 21:11:36,642 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:36,896 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:36,897 - INFO - topic #12 (0.067): 0.073*\"spiritus\" + 0.070*\"vita\" + 0.030*\"homo\" + 0.025*\"natura\" + 0.024*\"christus\" + 0.022*\"unio\" + 0.021*\"verbum\" + 0.020*\"delphi\" + 0.018*\"rationalis\" + 0.017*\"corpus\"\n",
      "2024-11-24 21:11:36,897 - INFO - topic #6 (0.067): 0.085*\"lux\" + 0.046*\"fides\" + 0.036*\"tenebrae\" + 0.030*\"intellectus\" + 0.030*\"veritas\" + 0.025*\"verus\" + 0.023*\"gegen\" + 0.023*\"ratio\" + 0.020*\"sol\" + 0.019*\"credo\"\n",
      "2024-11-24 21:11:36,897 - INFO - topic #13 (0.067): 0.056*\"amor\" + 0.045*\"delphi\" + 0.035*\"clotho\" + 0.029*\"peccatum\" + 0.023*\"symbatios\" + 0.022*\"filius\" + 0.021*\"pater\" + 0.020*\"diligo\" + 0.019*\"spiritus\" + 0.019*\"corpus\"\n",
      "2024-11-24 21:11:36,898 - INFO - topic #11 (0.067): 0.047*\"christus\" + 0.026*\"natura\" + 0.026*\"vita\" + 0.025*\"domus\" + 0.019*\"delphi\" + 0.018*\"homo\" + 0.018*\"sapientia\" + 0.017*\"via\" + 0.017*\"verbum\" + 0.017*\"tempus\"\n",
      "2024-11-24 21:11:36,898 - INFO - topic #0 (0.067): 0.098*\"homo\" + 0.040*\"ars\" + 0.028*\"forma\" + 0.023*\"christus\" + 0.023*\"vita\" + 0.019*\"perfectus\" + 0.018*\"natura\" + 0.018*\"iustitia\" + 0.018*\"mundus\" + 0.016*\"pater\"\n",
      "2024-11-24 21:11:36,898 - INFO - topic diff=0.359364, rho=0.707107\n",
      "2024-11-24 21:11:36,899 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.86s', 'datetime': '2024-11-24T21:11:36.899095', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:36,901 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:37,003 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:11:37,019 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:11:37,073 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:11:37,075 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:11:37,077 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:11:37,079 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:11:37,081 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:11:37,885 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:11:37,916 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:11:37,947 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:11:37,983 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:11:38,012 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:11:38,025 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:11:38,027 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:11:38,029 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:11:38,052 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:11:38,054 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:11:38,059 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:11:38,061 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:11:38,066 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:11:38,068 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:11:38,078 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:11:38,080 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:11:38,085 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:11:38,092 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:11:38,093 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:11:38,098 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:11:38,100 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:11:38,105 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:11:38,110 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:11:38,112 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:11:38,125 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:11:38,127 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:11:38,129 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:11:38,131 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:11:38,139 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:11:38,158 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:11:38,167 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:11:38,172 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:11:38,188 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:11:38,190 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:11:38,192 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:11:38,194 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:11:38,196 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:11:38,198 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:11:38,199 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:11:38,204 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:11:38,206 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:11:38,207 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:11:38,209 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:11:38,212 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:11:38,218 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:11:38,220 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:11:38,222 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:11:38,223 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:11:38,230 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:11:38,232 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:11:38,238 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:11:38,245 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:11:38,315 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:38,323 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:11:38,496 - INFO - 第 3 折评估完成: NPMI=0.4985, Diversity=0.4733, Optimal Score=0.4859\n",
      "实验进度:  38%|███▊      | 23/60 [01:06<01:45,  2.85s/it]2024-11-24 21:11:38,498 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:38,573 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:11:38,573 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:11:38.573903', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:38,577 - INFO - discarding 8685 tokens: [('apocalypsis', 14), ('behalten', 118), ('constantinus', 30), ('corona', 26), ('element', 6), ('expono', 79), ('generalis', 25), ('gloriosus', 80), ('grando', 3), ('ioannes', 87)]...\n",
      "2024-11-24 21:11:38,577 - INFO - keeping 200 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:38,578 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:11:38,578 - INFO - 词典过滤: 8885 -> 200 个词\n",
      "2024-11-24 21:11:38,615 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:38,615 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:38,616 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:38,617 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:38,617 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:38,617 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:38,925 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:38,926 - INFO - topic #13 (0.067): 0.034*\"pater\" + 0.030*\"verbum\" + 0.026*\"spiritus\" + 0.024*\"regnum\" + 0.022*\"ars\" + 0.019*\"annas\" + 0.018*\"unitas\" + 0.018*\"natura\" + 0.017*\"finis\" + 0.017*\"sanctus\"\n",
      "2024-11-24 21:11:38,926 - INFO - topic #8 (0.067): 0.051*\"christus\" + 0.048*\"corpus\" + 0.038*\"homo\" + 0.032*\"delphi\" + 0.023*\"ecclesia\" + 0.023*\"spiritus\" + 0.017*\"sapientia\" + 0.016*\"peccatum\" + 0.014*\"vita\" + 0.013*\"locus\"\n",
      "2024-11-24 21:11:38,926 - INFO - topic #14 (0.067): 0.076*\"spiritus\" + 0.039*\"christus\" + 0.035*\"vita\" + 0.025*\"delphi\" + 0.021*\"mundus\" + 0.020*\"homo\" + 0.020*\"osdroena\" + 0.019*\"mors\" + 0.018*\"filius\" + 0.017*\"fides\"\n",
      "2024-11-24 21:11:38,927 - INFO - topic #7 (0.067): 0.057*\"vita\" + 0.047*\"christus\" + 0.032*\"spiritus\" + 0.027*\"verbum\" + 0.022*\"filius\" + 0.020*\"iustitia\" + 0.019*\"fides\" + 0.018*\"mors\" + 0.016*\"pax\" + 0.015*\"veritas\"\n",
      "2024-11-24 21:11:38,927 - INFO - topic #9 (0.067): 0.055*\"dies\" + 0.043*\"pater\" + 0.040*\"filius\" + 0.031*\"christus\" + 0.027*\"spiritus\" + 0.023*\"sapientia\" + 0.023*\"homo\" + 0.022*\"vita\" + 0.021*\"unio\" + 0.015*\"opus\"\n",
      "2024-11-24 21:11:38,927 - INFO - topic diff=0.759201, rho=1.000000\n",
      "2024-11-24 21:11:39,230 - INFO - -5.177 per-word bound, 36.2 perplexity estimate based on a held-out corpus of 1716 documents with 46027 words\n",
      "2024-11-24 21:11:39,230 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:39,477 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:39,478 - INFO - topic #12 (0.067): 0.053*\"gegen\" + 0.040*\"lux\" + 0.036*\"veritas\" + 0.035*\"intellectus\" + 0.026*\"ratio\" + 0.025*\"christus\" + 0.022*\"natura\" + 0.019*\"verbum\" + 0.018*\"sensibilis\" + 0.018*\"motus\"\n",
      "2024-11-24 21:11:39,478 - INFO - topic #6 (0.067): 0.061*\"virtus\" + 0.033*\"spiritus\" + 0.027*\"larissa\" + 0.026*\"homo\" + 0.024*\"principium\" + 0.023*\"natura\" + 0.022*\"terra\" + 0.022*\"finis\" + 0.021*\"veritas\" + 0.020*\"creo\"\n",
      "2024-11-24 21:11:39,478 - INFO - topic #13 (0.067): 0.053*\"ars\" + 0.052*\"pater\" + 0.038*\"verbum\" + 0.033*\"nomen\" + 0.030*\"annas\" + 0.028*\"regnum\" + 0.026*\"sanctus\" + 0.022*\"natura\" + 0.021*\"spiritus\" + 0.021*\"unitas\"\n",
      "2024-11-24 21:11:39,479 - INFO - topic #11 (0.067): 0.057*\"vita\" + 0.040*\"delphi\" + 0.031*\"spiritus\" + 0.030*\"amor\" + 0.028*\"sanctus\" + 0.024*\"gratia\" + 0.024*\"symbatios\" + 0.019*\"cognosco\" + 0.019*\"clotho\" + 0.019*\"christus\"\n",
      "2024-11-24 21:11:39,479 - INFO - topic #0 (0.067): 0.077*\"christus\" + 0.071*\"panis\" + 0.032*\"forma\" + 0.029*\"nomen\" + 0.028*\"gaudium\" + 0.024*\"verbum\" + 0.024*\"natura\" + 0.023*\"bonus\" + 0.022*\"pater\" + 0.022*\"reperio\"\n",
      "2024-11-24 21:11:39,479 - INFO - topic diff=0.362373, rho=0.707107\n",
      "2024-11-24 21:11:39,480 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.86s', 'datetime': '2024-11-24T21:11:39.480178', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:39,482 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:39,519 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:11:39,521 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:11:39,523 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:11:39,525 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:11:39,527 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:11:39,529 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:11:39,531 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:11:40,504 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:11:40,513 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:11:40,520 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:11:40,525 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:11:40,541 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:11:40,549 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:11:40,563 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:11:40,583 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:11:40,586 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:11:40,589 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:11:40,591 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:11:40,593 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:11:40,595 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:11:40,602 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:11:40,604 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:11:40,606 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:11:40,611 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:11:40,617 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:11:40,623 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:11:40,629 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:11:40,630 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:11:40,635 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:11:40,637 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:11:40,639 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:11:40,646 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:11:40,652 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:11:40,654 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:11:40,656 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:11:40,658 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:11:40,659 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:11:40,667 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:11:40,684 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:11:40,686 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:11:40,688 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:11:40,690 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:11:40,697 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:11:40,698 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:11:40,708 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:11:40,711 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:11:40,714 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:11:40,717 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:11:40,719 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:11:40,725 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:11:40,731 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:11:40,745 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:11:40,748 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:11:40,750 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:11:40,757 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:11:40,760 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:11:40,772 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:11:40,776 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:11:40,781 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:11:40,862 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:40,871 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:11:41,037 - INFO - 第 4 折评估完成: NPMI=0.4990, Diversity=0.4600, Optimal Score=0.4795\n",
      "实验进度:  40%|████      | 24/60 [01:08<01:39,  2.76s/it]2024-11-24 21:11:41,039 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:41,124 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:11:41,124 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:11:41.124734', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:41,128 - INFO - discarding 8703 tokens: [('apocalypsis', 15), ('behalten', 127), ('constantinus', 35), ('corona', 26), ('element', 9), ('expono', 80), ('generalis', 24), ('gloriosus', 77), ('grando', 7), ('ioannes', 98)]...\n",
      "2024-11-24 21:11:41,128 - INFO - keeping 200 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:41,129 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:11:41,129 - INFO - 词典过滤: 8903 -> 200 个词\n",
      "2024-11-24 21:11:41,215 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:41,216 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:41,216 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:41,217 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:41,217 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:41,217 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:41,521 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:41,521 - INFO - topic #13 (0.067): 0.036*\"lux\" + 0.034*\"vita\" + 0.030*\"christus\" + 0.020*\"gegen\" + 0.020*\"verbum\" + 0.019*\"homo\" + 0.018*\"veritas\" + 0.017*\"vivo\" + 0.017*\"evangelium\" + 0.017*\"spiritus\"\n",
      "2024-11-24 21:11:41,521 - INFO - topic #8 (0.067): 0.048*\"christus\" + 0.032*\"debeo\" + 0.027*\"veritas\" + 0.023*\"nomen\" + 0.022*\"filius\" + 0.020*\"homo\" + 0.019*\"virtus\" + 0.018*\"lex\" + 0.018*\"delphi\" + 0.017*\"gratia\"\n",
      "2024-11-24 21:11:41,522 - INFO - topic #14 (0.067): 0.089*\"christus\" + 0.055*\"spiritus\" + 0.031*\"fides\" + 0.027*\"homo\" + 0.019*\"filius\" + 0.019*\"verbum\" + 0.018*\"vita\" + 0.015*\"virtus\" + 0.012*\"debeo\" + 0.012*\"volo\"\n",
      "2024-11-24 21:11:41,522 - INFO - topic #7 (0.067): 0.043*\"virtus\" + 0.037*\"verbum\" + 0.035*\"christus\" + 0.030*\"spiritus\" + 0.029*\"regnum\" + 0.021*\"delphi\" + 0.018*\"unio\" + 0.017*\"natura\" + 0.016*\"filius\" + 0.016*\"lex\"\n",
      "2024-11-24 21:11:41,522 - INFO - topic #9 (0.067): 0.037*\"pater\" + 0.026*\"sapientia\" + 0.024*\"intellectus\" + 0.024*\"rex\" + 0.023*\"christus\" + 0.020*\"debeo\" + 0.019*\"virtus\" + 0.019*\"homo\" + 0.018*\"delphi\" + 0.017*\"venio\"\n",
      "2024-11-24 21:11:41,523 - INFO - topic diff=0.738142, rho=1.000000\n",
      "2024-11-24 21:11:41,825 - INFO - -5.203 per-word bound, 36.8 perplexity estimate based on a held-out corpus of 1716 documents with 45842 words\n",
      "2024-11-24 21:11:41,825 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:42,089 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:42,089 - INFO - topic #12 (0.067): 0.080*\"filius\" + 0.077*\"pater\" + 0.036*\"homo\" + 0.032*\"christus\" + 0.031*\"natura\" + 0.026*\"mundus\" + 0.023*\"spiritus\" + 0.020*\"verbum\" + 0.019*\"venio\" + 0.017*\"veritas\"\n",
      "2024-11-24 21:11:42,090 - INFO - topic #6 (0.067): 0.064*\"dies\" + 0.047*\"spiritus\" + 0.032*\"ratio\" + 0.031*\"delphi\" + 0.028*\"dominus\" + 0.023*\"fides\" + 0.019*\"debeo\" + 0.018*\"osdroena\" + 0.018*\"sanctus\" + 0.016*\"homo\"\n",
      "2024-11-24 21:11:42,090 - INFO - topic #13 (0.067): 0.040*\"lux\" + 0.030*\"christus\" + 0.028*\"quaero\" + 0.028*\"vita\" + 0.025*\"evangelium\" + 0.025*\"gegen\" + 0.022*\"doctrina\" + 0.021*\"pars\" + 0.020*\"veritas\" + 0.017*\"primo\"\n",
      "2024-11-24 21:11:42,091 - INFO - topic #11 (0.067): 0.058*\"amor\" + 0.045*\"symbatios\" + 0.040*\"clotho\" + 0.037*\"filius\" + 0.033*\"spiritus\" + 0.031*\"christus\" + 0.030*\"pater\" + 0.023*\"diligo\" + 0.020*\"delphi\" + 0.019*\"mater\"\n",
      "2024-11-24 21:11:42,091 - INFO - topic #0 (0.067): 0.036*\"christus\" + 0.028*\"homo\" + 0.026*\"finis\" + 0.026*\"tenebrae\" + 0.023*\"volo\" + 0.022*\"mundus\" + 0.022*\"recipio\" + 0.021*\"spiritus\" + 0.017*\"vita\" + 0.017*\"debeo\"\n",
      "2024-11-24 21:11:42,091 - INFO - topic diff=0.333727, rho=0.707107\n",
      "2024-11-24 21:11:42,091 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.87s', 'datetime': '2024-11-24T21:11:42.091894', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:42,094 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:42,152 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:11:42,167 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:11:42,173 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:11:42,179 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:11:42,186 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:11:42,190 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:11:42,194 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:11:43,247 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:11:43,273 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:11:43,299 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:11:43,313 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:11:43,334 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:11:43,351 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:11:43,356 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:11:43,365 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:11:43,370 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:11:43,374 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:11:43,378 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:11:43,381 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:11:43,384 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:11:43,389 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:11:43,392 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:11:43,396 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:11:43,401 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:11:43,404 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:11:43,406 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:11:43,408 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:11:43,411 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:11:43,414 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:11:43,418 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:11:43,426 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:11:43,427 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:11:43,452 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:11:43,454 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:11:43,456 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:11:43,463 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:11:43,464 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:11:43,468 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:11:43,474 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:11:43,477 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:11:43,481 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:11:43,484 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:11:43,491 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:11:43,497 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:11:43,499 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:11:43,501 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:11:43,510 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:11:43,514 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:11:43,518 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:11:43,520 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:11:43,522 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:11:43,526 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:11:43,548 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:11:43,555 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:11:43,556 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:11:43,558 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:11:43,561 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:11:43,567 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:11:43,568 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:11:43,651 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:43,661 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:11:43,827 - INFO - 第 5 折评估完成: NPMI=0.4970, Diversity=0.4533, Optimal Score=0.4752\n",
      "实验进度:  42%|████▏     | 25/60 [01:11<01:36,  2.77s/it]2024-11-24 21:11:43,828 - INFO - \n",
      "评估阈值组合: min_freq=3, max_freq=800\n",
      "2024-11-24 21:11:43,830 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:43,905 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:11:43,905 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:11:43.905651', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:43,908 - INFO - discarding 8039 tokens: [('apocalypsis', 16), ('constantinus', 35), ('corona', 25), ('element', 9), ('generalis', 29), ('grando', 6), ('principalis', 18), ('specialis', 14), ('terraemotus', 5), ('aaron', 7)]...\n",
      "2024-11-24 21:11:43,909 - INFO - keeping 800 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:43,910 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:11:43,910 - INFO - 词典过滤: 8839 -> 800 个词\n",
      "2024-11-24 21:11:43,963 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:43,964 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:43,964 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:43,965 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:43,965 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:43,966 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:44,329 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:44,330 - INFO - topic #6 (0.067): 0.022*\"spiritus\" + 0.021*\"virtus\" + 0.017*\"christus\" + 0.017*\"delphi\" + 0.016*\"vita\" + 0.016*\"homo\" + 0.015*\"corpus\" + 0.014*\"verbum\" + 0.012*\"natura\" + 0.011*\"ratio\"\n",
      "2024-11-24 21:11:44,330 - INFO - topic #13 (0.067): 0.047*\"christus\" + 0.022*\"homo\" + 0.021*\"pater\" + 0.020*\"filius\" + 0.019*\"vita\" + 0.015*\"verbum\" + 0.013*\"virtus\" + 0.012*\"panis\" + 0.011*\"spiritus\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:11:44,331 - INFO - topic #12 (0.067): 0.030*\"spiritus\" + 0.024*\"fides\" + 0.023*\"vita\" + 0.018*\"sanctus\" + 0.017*\"verbum\" + 0.015*\"filius\" + 0.012*\"christus\" + 0.011*\"pater\" + 0.010*\"homo\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:11:44,331 - INFO - topic #10 (0.067): 0.025*\"christus\" + 0.022*\"delphi\" + 0.021*\"fides\" + 0.019*\"spiritus\" + 0.017*\"mundus\" + 0.013*\"verbum\" + 0.011*\"lux\" + 0.010*\"natura\" + 0.009*\"vita\" + 0.009*\"filius\"\n",
      "2024-11-24 21:11:44,331 - INFO - topic #2 (0.067): 0.024*\"spiritus\" + 0.023*\"homo\" + 0.021*\"vita\" + 0.017*\"christus\" + 0.011*\"ratio\" + 0.011*\"sapientia\" + 0.010*\"dominus\" + 0.009*\"gratia\" + 0.009*\"mundus\" + 0.009*\"verbum\"\n",
      "2024-11-24 21:11:44,332 - INFO - topic diff=1.635696, rho=1.000000\n",
      "2024-11-24 21:11:44,697 - INFO - -6.440 per-word bound, 86.8 perplexity estimate based on a held-out corpus of 1716 documents with 72713 words\n",
      "2024-11-24 21:11:44,697 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:45,024 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:45,025 - INFO - topic #10 (0.067): 0.030*\"fides\" + 0.024*\"christus\" + 0.023*\"delphi\" + 0.017*\"spiritus\" + 0.016*\"lux\" + 0.015*\"mundus\" + 0.013*\"natura\" + 0.013*\"gegen\" + 0.013*\"gratia\" + 0.011*\"verbum\"\n",
      "2024-11-24 21:11:45,026 - INFO - topic #1 (0.067): 0.035*\"christus\" + 0.022*\"sanctus\" + 0.019*\"dies\" + 0.014*\"spiritus\" + 0.012*\"lex\" + 0.012*\"mater\" + 0.011*\"evangelium\" + 0.011*\"ecclesia\" + 0.009*\"debeo\" + 0.008*\"osdroena\"\n",
      "2024-11-24 21:11:45,026 - INFO - topic #2 (0.067): 0.031*\"homo\" + 0.021*\"vita\" + 0.017*\"spiritus\" + 0.014*\"christus\" + 0.014*\"peccatum\" + 0.013*\"mors\" + 0.013*\"ratio\" + 0.012*\"dominus\" + 0.012*\"gratia\" + 0.011*\"sapientia\"\n",
      "2024-11-24 21:11:45,026 - INFO - topic #11 (0.067): 0.028*\"vita\" + 0.022*\"clotho\" + 0.020*\"lux\" + 0.019*\"delphi\" + 0.019*\"amor\" + 0.016*\"iustitia\" + 0.014*\"vivo\" + 0.013*\"homo\" + 0.012*\"venio\" + 0.011*\"gegen\"\n",
      "2024-11-24 21:11:45,026 - INFO - topic #0 (0.067): 0.040*\"natura\" + 0.022*\"homo\" + 0.020*\"sapientia\" + 0.016*\"creo\" + 0.013*\"vita\" + 0.013*\"gloria\" + 0.012*\"ada\" + 0.011*\"rex\" + 0.011*\"humanus\" + 0.011*\"locus\"\n",
      "2024-11-24 21:11:45,027 - INFO - topic diff=0.615809, rho=0.707107\n",
      "2024-11-24 21:11:45,027 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.06s', 'datetime': '2024-11-24T21:11:45.027465', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:45,030 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:45,087 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:11:45,089 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:11:45,093 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:11:45,097 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:11:45,101 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:11:45,102 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:11:45,110 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:11:45,967 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:11:45,995 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:11:46,021 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:11:46,040 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:11:46,053 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:11:46,061 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:11:46,067 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:11:46,100 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:11:46,103 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:11:46,105 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:11:46,107 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:11:46,112 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:11:46,114 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:11:46,118 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:11:46,128 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:11:46,130 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:11:46,134 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:11:46,149 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:11:46,151 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:11:46,158 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:11:46,187 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:11:46,205 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:11:46,236 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:11:46,289 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:11:46,291 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:11:46,293 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:11:46,305 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:11:46,325 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:11:46,330 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:11:46,331 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:11:46,336 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:11:46,357 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:11:46,360 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:11:46,362 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:11:46,364 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:11:46,366 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:11:46,373 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:11:46,378 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:11:46,414 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:11:46,419 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:11:46,420 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:11:46,421 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:11:46,422 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:11:46,424 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:11:46,425 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:11:46,426 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:11:46,427 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:11:46,428 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:11:46,444 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:11:46,450 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:11:46,454 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:11:46,465 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:11:46,594 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:46,609 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:11:46,792 - INFO - 第 1 折评估完成: NPMI=0.4902, Diversity=0.4533, Optimal Score=0.4717\n",
      "实验进度:  43%|████▎     | 26/60 [01:14<01:36,  2.83s/it]2024-11-24 21:11:46,795 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:46,871 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:11:46,872 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:11:46.872144', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:46,875 - INFO - discarding 8096 tokens: [('aaron', 7), ('asper', 8), ('contritio', 22), ('conversatio', 28), ('correctio', 22), ('dormio', 34), ('element', 7), ('eua', 23), ('expositio', 13), ('generalis', 28)]...\n",
      "2024-11-24 21:11:46,875 - INFO - keeping 800 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:46,876 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:11:46,877 - INFO - 词典过滤: 8896 -> 800 个词\n",
      "2024-11-24 21:11:46,934 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:46,935 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:46,936 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:46,937 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:46,937 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:46,937 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:47,300 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:47,301 - INFO - topic #6 (0.067): 0.024*\"spiritus\" + 0.022*\"delphi\" + 0.015*\"vita\" + 0.013*\"corpus\" + 0.012*\"christus\" + 0.011*\"verbum\" + 0.010*\"desiderium\" + 0.010*\"virtus\" + 0.010*\"mundus\" + 0.009*\"essentia\"\n",
      "2024-11-24 21:11:47,302 - INFO - topic #13 (0.067): 0.022*\"verbum\" + 0.018*\"pater\" + 0.017*\"filius\" + 0.017*\"natura\" + 0.017*\"christus\" + 0.014*\"spiritus\" + 0.014*\"vita\" + 0.014*\"dominus\" + 0.012*\"iesus\" + 0.012*\"corpus\"\n",
      "2024-11-24 21:11:47,302 - INFO - topic #12 (0.067): 0.021*\"delphi\" + 0.020*\"spiritus\" + 0.017*\"ratio\" + 0.016*\"fides\" + 0.013*\"verbum\" + 0.012*\"christus\" + 0.011*\"homo\" + 0.010*\"pax\" + 0.010*\"amor\" + 0.009*\"bonus\"\n",
      "2024-11-24 21:11:47,302 - INFO - topic #10 (0.067): 0.023*\"spiritus\" + 0.021*\"vita\" + 0.018*\"verbum\" + 0.016*\"homo\" + 0.014*\"christus\" + 0.013*\"lex\" + 0.012*\"virtus\" + 0.012*\"iustitia\" + 0.011*\"ostendo\" + 0.011*\"pater\"\n",
      "2024-11-24 21:11:47,303 - INFO - topic #2 (0.067): 0.035*\"christus\" + 0.026*\"spiritus\" + 0.016*\"verbum\" + 0.014*\"mundus\" + 0.012*\"rex\" + 0.011*\"fides\" + 0.011*\"filius\" + 0.011*\"sapientia\" + 0.010*\"homo\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:11:47,303 - INFO - topic diff=1.446414, rho=1.000000\n",
      "2024-11-24 21:11:47,671 - INFO - -6.456 per-word bound, 87.8 perplexity estimate based on a held-out corpus of 1716 documents with 73053 words\n",
      "2024-11-24 21:11:47,671 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:47,970 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:47,971 - INFO - topic #10 (0.067): 0.022*\"spiritus\" + 0.020*\"verbum\" + 0.020*\"lex\" + 0.017*\"homo\" + 0.017*\"vita\" + 0.015*\"virtus\" + 0.014*\"ostendo\" + 0.013*\"credo\" + 0.013*\"christus\" + 0.011*\"sanctus\"\n",
      "2024-11-24 21:11:47,971 - INFO - topic #1 (0.067): 0.023*\"debeo\" + 0.018*\"christus\" + 0.018*\"domus\" + 0.016*\"spiritus\" + 0.014*\"peto\" + 0.013*\"gratia\" + 0.012*\"ecclesia\" + 0.012*\"dies\" + 0.011*\"donum\" + 0.011*\"oratio\"\n",
      "2024-11-24 21:11:47,971 - INFO - topic #2 (0.067): 0.034*\"christus\" + 0.027*\"spiritus\" + 0.024*\"nomen\" + 0.018*\"verbum\" + 0.017*\"sapientia\" + 0.013*\"filius\" + 0.013*\"mundus\" + 0.012*\"fides\" + 0.010*\"virtus\" + 0.010*\"mitto\"\n",
      "2024-11-24 21:11:47,972 - INFO - topic #11 (0.067): 0.028*\"pater\" + 0.023*\"mundus\" + 0.017*\"spiritus\" + 0.016*\"christus\" + 0.013*\"homo\" + 0.013*\"filius\" + 0.012*\"peccatum\" + 0.011*\"veritas\" + 0.011*\"sanctus\" + 0.010*\"bonus\"\n",
      "2024-11-24 21:11:47,972 - INFO - topic #0 (0.067): 0.038*\"vita\" + 0.024*\"mors\" + 0.020*\"motus\" + 0.018*\"verbum\" + 0.016*\"delphi\" + 0.014*\"spiritus\" + 0.012*\"virtus\" + 0.011*\"christus\" + 0.011*\"eligo\" + 0.010*\"debeo\"\n",
      "2024-11-24 21:11:47,972 - INFO - topic diff=0.591180, rho=0.707107\n",
      "2024-11-24 21:11:47,973 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.04s', 'datetime': '2024-11-24T21:11:47.973118', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:47,975 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:48,013 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:11:48,017 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:11:48,019 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:11:48,021 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:11:48,023 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:11:48,025 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:11:48,027 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:11:48,876 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:11:48,899 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:11:48,922 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:11:48,952 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:11:48,964 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:11:48,986 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:11:48,988 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:11:48,996 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:11:48,998 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:11:49,000 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:11:49,002 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:11:49,019 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:11:49,033 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:11:49,034 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:11:49,039 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:11:49,041 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:11:49,042 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:11:49,044 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:11:49,046 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:11:49,053 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:11:49,056 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:11:49,067 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:11:49,069 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:11:49,071 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:11:49,073 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:11:49,075 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:11:49,081 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:11:49,095 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:11:49,096 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:11:49,099 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:11:49,103 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:11:49,106 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:11:49,123 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:11:49,125 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:11:49,131 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:11:49,134 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:11:49,135 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:11:49,137 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:11:49,139 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:11:49,151 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:11:49,153 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:11:49,154 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:11:49,160 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:11:49,162 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:11:49,171 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:11:49,172 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:11:49,176 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:11:49,178 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:11:49,187 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:11:49,189 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:11:49,201 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:11:49,206 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:11:49,287 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:49,296 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:11:49,459 - INFO - 第 2 折评估完成: NPMI=0.4939, Diversity=0.4000, Optimal Score=0.4469\n",
      "实验进度:  45%|████▌     | 27/60 [01:17<01:31,  2.78s/it]2024-11-24 21:11:49,461 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:49,536 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:11:49,537 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:11:49.537027', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:49,540 - INFO - discarding 8034 tokens: [('apocalypsis', 13), ('constantinus', 33), ('corona', 28), ('element', 9), ('generalis', 26), ('grando', 6), ('principalis', 17), ('specialis', 13), ('terraemotus', 6), ('aaron', 8)]...\n",
      "2024-11-24 21:11:49,540 - INFO - keeping 800 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:49,541 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:11:49,542 - INFO - 词典过滤: 8834 -> 800 个词\n",
      "2024-11-24 21:11:49,595 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:49,595 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:49,596 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:49,597 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:49,597 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:49,597 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:49,960 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:49,961 - INFO - topic #6 (0.067): 0.060*\"und\" + 0.033*\"dies\" + 0.021*\"delphi\" + 0.019*\"christus\" + 0.019*\"is\" + 0.014*\"vita\" + 0.014*\"verbum\" + 0.011*\"debeo\" + 0.011*\"spiritus\" + 0.010*\"dar\"\n",
      "2024-11-24 21:11:49,961 - INFO - topic #13 (0.067): 0.051*\"christus\" + 0.018*\"homo\" + 0.017*\"venio\" + 0.014*\"corpus\" + 0.013*\"virtus\" + 0.012*\"rex\" + 0.011*\"panis\" + 0.011*\"verbum\" + 0.011*\"spiritus\" + 0.009*\"gloria\"\n",
      "2024-11-24 21:11:49,961 - INFO - topic #12 (0.067): 0.022*\"spiritus\" + 0.021*\"vita\" + 0.019*\"verbum\" + 0.016*\"filius\" + 0.014*\"sanctus\" + 0.012*\"pater\" + 0.012*\"fides\" + 0.011*\"veritas\" + 0.011*\"homo\" + 0.010*\"natura\"\n",
      "2024-11-24 21:11:49,962 - INFO - topic #10 (0.067): 0.033*\"spiritus\" + 0.024*\"christus\" + 0.017*\"mundus\" + 0.015*\"homo\" + 0.014*\"natura\" + 0.012*\"verbum\" + 0.011*\"vita\" + 0.011*\"pater\" + 0.009*\"sapientia\" + 0.009*\"divinus\"\n",
      "2024-11-24 21:11:49,962 - INFO - topic #2 (0.067): 0.020*\"spiritus\" + 0.017*\"homo\" + 0.017*\"virtus\" + 0.017*\"christus\" + 0.015*\"filius\" + 0.013*\"fides\" + 0.012*\"natura\" + 0.011*\"dominus\" + 0.010*\"verbum\" + 0.010*\"gratia\"\n",
      "2024-11-24 21:11:49,962 - INFO - topic diff=1.418527, rho=1.000000\n",
      "2024-11-24 21:11:50,333 - INFO - -6.454 per-word bound, 87.7 perplexity estimate based on a held-out corpus of 1716 documents with 71901 words\n",
      "2024-11-24 21:11:50,334 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:50,630 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:50,631 - INFO - topic #10 (0.067): 0.031*\"spiritus\" + 0.024*\"natura\" + 0.019*\"homo\" + 0.018*\"christus\" + 0.017*\"ars\" + 0.017*\"mundus\" + 0.016*\"sapientia\" + 0.013*\"infinitus\" + 0.012*\"humanus\" + 0.011*\"verbum\"\n",
      "2024-11-24 21:11:50,631 - INFO - topic #1 (0.067): 0.033*\"christus\" + 0.015*\"mundus\" + 0.014*\"dies\" + 0.014*\"mater\" + 0.011*\"sanctus\" + 0.010*\"volo\" + 0.009*\"debeo\" + 0.009*\"ratio\" + 0.008*\"sequor\" + 0.008*\"cognosco\"\n",
      "2024-11-24 21:11:50,632 - INFO - topic #2 (0.067): 0.018*\"virtus\" + 0.016*\"filius\" + 0.016*\"dominus\" + 0.015*\"christus\" + 0.015*\"homo\" + 0.015*\"fides\" + 0.015*\"spiritus\" + 0.014*\"gratia\" + 0.011*\"natura\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:11:50,632 - INFO - topic #11 (0.067): 0.033*\"lux\" + 0.024*\"spiritus\" + 0.019*\"gratia\" + 0.017*\"gegen\" + 0.014*\"tenebrae\" + 0.012*\"fides\" + 0.011*\"veritas\" + 0.011*\"sanctus\" + 0.010*\"donum\" + 0.010*\"homo\"\n",
      "2024-11-24 21:11:50,632 - INFO - topic #0 (0.067): 0.056*\"filius\" + 0.049*\"pater\" + 0.026*\"christus\" + 0.025*\"homo\" + 0.024*\"nomen\" + 0.023*\"spiritus\" + 0.022*\"fides\" + 0.015*\"credo\" + 0.012*\"verbum\" + 0.011*\"vita\"\n",
      "2024-11-24 21:11:50,633 - INFO - topic diff=0.588845, rho=0.707107\n",
      "2024-11-24 21:11:50,633 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.04s', 'datetime': '2024-11-24T21:11:50.633531', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:50,636 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:50,693 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:11:50,768 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:11:50,907 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:11:50,909 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:11:50,911 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:11:50,913 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:11:50,915 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:11:52,350 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:11:52,363 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:11:52,366 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:11:52,392 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:11:52,399 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:11:52,401 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:11:52,403 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:11:52,408 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:11:52,410 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:11:52,412 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:11:52,414 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:11:52,417 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:11:52,448 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:11:52,449 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:11:52,450 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:11:52,451 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:11:52,453 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:11:52,454 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:11:52,466 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:11:52,469 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:11:52,489 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:11:52,491 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:11:52,494 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:11:52,496 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:11:52,499 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:11:52,501 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:11:52,503 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:11:52,519 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:11:52,535 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:11:52,539 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:11:52,543 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:11:52,552 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:11:52,554 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:11:52,557 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:11:52,558 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:11:52,561 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:11:52,569 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:11:52,572 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:11:52,579 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:11:52,598 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:11:52,630 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:11:52,656 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:11:52,661 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:11:52,663 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:11:52,665 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:11:52,667 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:11:52,669 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:11:52,670 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:11:52,677 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:11:52,686 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:11:52,690 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:11:52,692 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:11:53,019 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:53,069 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:11:53,289 - INFO - 第 3 折评估完成: NPMI=0.4922, Diversity=0.4400, Optimal Score=0.4661\n",
      "实验进度:  47%|████▋     | 28/60 [01:21<01:39,  3.09s/it]2024-11-24 21:11:53,294 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:53,382 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:11:53,383 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:11:53.383187', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:53,387 - INFO - discarding 8085 tokens: [('apocalypsis', 14), ('constantinus', 30), ('corona', 26), ('element', 6), ('generalis', 25), ('grando', 3), ('principalis', 16), ('specialis', 12), ('terraemotus', 3), ('amicitia', 23)]...\n",
      "2024-11-24 21:11:53,387 - INFO - keeping 800 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:53,389 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:11:53,389 - INFO - 词典过滤: 8885 -> 800 个词\n",
      "2024-11-24 21:11:53,443 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:53,445 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:53,449 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:53,452 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:53,453 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:53,453 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:53,866 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:53,867 - INFO - topic #6 (0.067): 0.030*\"homo\" + 0.025*\"christus\" + 0.025*\"spiritus\" + 0.020*\"vita\" + 0.016*\"delphi\" + 0.015*\"virtus\" + 0.015*\"verbum\" + 0.015*\"natura\" + 0.013*\"filius\" + 0.009*\"und\"\n",
      "2024-11-24 21:11:53,868 - INFO - topic #13 (0.067): 0.020*\"amor\" + 0.020*\"christus\" + 0.020*\"vita\" + 0.019*\"filius\" + 0.018*\"locus\" + 0.018*\"virtus\" + 0.012*\"verbum\" + 0.011*\"spiritus\" + 0.011*\"debeo\" + 0.011*\"pater\"\n",
      "2024-11-24 21:11:53,868 - INFO - topic #12 (0.067): 0.018*\"spiritus\" + 0.016*\"homo\" + 0.015*\"christus\" + 0.012*\"debeo\" + 0.012*\"pulchritudo\" + 0.011*\"pater\" + 0.011*\"dies\" + 0.010*\"verbum\" + 0.009*\"fides\" + 0.009*\"dominus\"\n",
      "2024-11-24 21:11:53,868 - INFO - topic #10 (0.067): 0.025*\"christus\" + 0.015*\"verbum\" + 0.015*\"pater\" + 0.015*\"homo\" + 0.014*\"nomen\" + 0.013*\"vita\" + 0.013*\"gloria\" + 0.012*\"spiritus\" + 0.012*\"sapientia\" + 0.012*\"principium\"\n",
      "2024-11-24 21:11:53,869 - INFO - topic #2 (0.067): 0.033*\"christus\" + 0.026*\"vita\" + 0.020*\"und\" + 0.016*\"dies\" + 0.015*\"mundus\" + 0.014*\"spiritus\" + 0.012*\"filius\" + 0.012*\"homo\" + 0.011*\"intellego\" + 0.010*\"regnum\"\n",
      "2024-11-24 21:11:53,869 - INFO - topic diff=1.573036, rho=1.000000\n",
      "2024-11-24 21:11:54,249 - INFO - -6.442 per-word bound, 86.9 perplexity estimate based on a held-out corpus of 1716 documents with 72301 words\n",
      "2024-11-24 21:11:54,250 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:54,550 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:54,551 - INFO - topic #10 (0.067): 0.032*\"nomen\" + 0.024*\"pater\" + 0.022*\"christus\" + 0.020*\"principium\" + 0.016*\"creatura\" + 0.015*\"homo\" + 0.015*\"verbum\" + 0.015*\"larissa\" + 0.015*\"tempus\" + 0.014*\"sapientia\"\n",
      "2024-11-24 21:11:54,551 - INFO - topic #1 (0.067): 0.035*\"spiritus\" + 0.024*\"gratia\" + 0.022*\"vita\" + 0.016*\"dies\" + 0.015*\"panis\" + 0.013*\"delphi\" + 0.013*\"sanctus\" + 0.011*\"iustitia\" + 0.010*\"christus\" + 0.010*\"misericordia\"\n",
      "2024-11-24 21:11:54,551 - INFO - topic #2 (0.067): 0.046*\"christus\" + 0.034*\"dies\" + 0.028*\"vita\" + 0.013*\"sanctus\" + 0.012*\"mundus\" + 0.011*\"intellego\" + 0.010*\"mors\" + 0.010*\"homo\" + 0.010*\"venio\" + 0.010*\"filius\"\n",
      "2024-11-24 21:11:54,552 - INFO - topic #11 (0.067): 0.033*\"natura\" + 0.028*\"christus\" + 0.026*\"pater\" + 0.025*\"filius\" + 0.017*\"debeo\" + 0.014*\"corpus\" + 0.014*\"homo\" + 0.011*\"mundus\" + 0.009*\"delphi\" + 0.009*\"dominus\"\n",
      "2024-11-24 21:11:54,552 - INFO - topic #0 (0.067): 0.024*\"pax\" + 0.021*\"terra\" + 0.016*\"christus\" + 0.015*\"voluntas\" + 0.013*\"vita\" + 0.011*\"homo\" + 0.011*\"pater\" + 0.011*\"evangelium\" + 0.010*\"larissa\" + 0.010*\"quaero\"\n",
      "2024-11-24 21:11:54,552 - INFO - topic diff=0.613584, rho=0.707107\n",
      "2024-11-24 21:11:54,553 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.10s', 'datetime': '2024-11-24T21:11:54.553114', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:54,556 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:54,607 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:11:54,611 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:11:54,614 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:11:54,615 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:11:54,618 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:11:54,723 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:11:54,789 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:11:55,414 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:11:55,440 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:11:55,470 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:11:55,492 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:11:55,521 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:11:55,528 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:11:55,550 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:11:55,553 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:11:55,556 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:11:55,561 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:11:55,563 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:11:55,566 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:11:55,589 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:11:55,596 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:11:55,603 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:11:55,608 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:11:55,610 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:11:55,615 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:11:55,617 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:11:55,620 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:11:55,622 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:11:55,628 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:11:55,631 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:11:55,637 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:11:55,639 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:11:55,643 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:11:55,652 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:11:55,658 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:11:55,660 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:11:55,666 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:11:55,668 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:11:55,670 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:11:55,672 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:11:55,819 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:11:55,859 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:11:55,874 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:11:55,883 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:11:55,885 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:11:55,887 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:11:55,892 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:11:55,899 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:11:55,901 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:11:55,904 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:11:55,908 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:11:55,910 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:11:55,916 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:11:55,921 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:11:55,924 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:11:55,930 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:11:55,932 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:11:55,934 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:11:55,935 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:11:56,003 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:56,013 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:11:56,196 - INFO - 第 4 折评估完成: NPMI=0.4890, Diversity=0.4200, Optimal Score=0.4545\n",
      "实验进度:  48%|████▊     | 29/60 [01:23<01:34,  3.04s/it]2024-11-24 21:11:56,198 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:56,277 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:11:56,278 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:11:56.278344', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:56,282 - INFO - discarding 8103 tokens: [('apocalypsis', 15), ('constantinus', 35), ('corona', 26), ('element', 9), ('generalis', 24), ('grando', 7), ('principalis', 16), ('specialis', 11), ('terraemotus', 5), ('aaron', 5)]...\n",
      "2024-11-24 21:11:56,282 - INFO - keeping 800 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:56,284 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:11:56,284 - INFO - 词典过滤: 8903 -> 800 个词\n",
      "2024-11-24 21:11:56,331 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:56,331 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:56,332 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:56,333 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:56,333 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:56,334 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:56,710 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:56,711 - INFO - topic #6 (0.067): 0.027*\"homo\" + 0.024*\"filius\" + 0.021*\"christus\" + 0.020*\"pater\" + 0.016*\"verbum\" + 0.016*\"virtus\" + 0.011*\"vita\" + 0.010*\"imago\" + 0.010*\"intellego\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:11:56,712 - INFO - topic #13 (0.067): 0.047*\"christus\" + 0.025*\"virtus\" + 0.018*\"homo\" + 0.017*\"spiritus\" + 0.014*\"verbum\" + 0.012*\"vita\" + 0.011*\"corpus\" + 0.011*\"delphi\" + 0.009*\"natura\" + 0.009*\"ratio\"\n",
      "2024-11-24 21:11:56,712 - INFO - topic #12 (0.067): 0.029*\"vita\" + 0.023*\"fides\" + 0.022*\"spiritus\" + 0.020*\"verbum\" + 0.016*\"homo\" + 0.015*\"lux\" + 0.013*\"christus\" + 0.013*\"pater\" + 0.013*\"filius\" + 0.012*\"veritas\"\n",
      "2024-11-24 21:11:56,712 - INFO - topic #10 (0.067): 0.030*\"spiritus\" + 0.025*\"christus\" + 0.025*\"filius\" + 0.023*\"vita\" + 0.016*\"fides\" + 0.015*\"verbum\" + 0.015*\"pater\" + 0.014*\"delphi\" + 0.013*\"mundus\" + 0.011*\"natura\"\n",
      "2024-11-24 21:11:56,713 - INFO - topic #2 (0.067): 0.017*\"intellectus\" + 0.016*\"cognosco\" + 0.016*\"christus\" + 0.015*\"dominus\" + 0.013*\"lux\" + 0.013*\"pater\" + 0.012*\"virtus\" + 0.012*\"fides\" + 0.011*\"clotho\" + 0.011*\"iudico\"\n",
      "2024-11-24 21:11:56,713 - INFO - topic diff=1.539441, rho=1.000000\n",
      "2024-11-24 21:11:57,091 - INFO - -6.459 per-word bound, 88.0 perplexity estimate based on a held-out corpus of 1716 documents with 72659 words\n",
      "2024-11-24 21:11:57,092 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:11:57,407 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:57,409 - INFO - topic #10 (0.067): 0.029*\"christus\" + 0.028*\"filius\" + 0.026*\"spiritus\" + 0.026*\"vita\" + 0.020*\"pater\" + 0.018*\"delphi\" + 0.017*\"fides\" + 0.016*\"verbum\" + 0.014*\"corpus\" + 0.014*\"veritas\"\n",
      "2024-11-24 21:11:57,409 - INFO - topic #1 (0.067): 0.039*\"christus\" + 0.021*\"debeo\" + 0.020*\"mater\" + 0.016*\"nomen\" + 0.016*\"sanctus\" + 0.016*\"vita\" + 0.014*\"pater\" + 0.014*\"domus\" + 0.014*\"und\" + 0.013*\"symbatios\"\n",
      "2024-11-24 21:11:57,409 - INFO - topic #2 (0.067): 0.029*\"intellectus\" + 0.021*\"cognosco\" + 0.019*\"dominus\" + 0.014*\"pater\" + 0.013*\"nomen\" + 0.013*\"iudico\" + 0.013*\"lux\" + 0.013*\"christus\" + 0.012*\"fides\" + 0.010*\"delphi\"\n",
      "2024-11-24 21:11:57,410 - INFO - topic #11 (0.067): 0.020*\"christus\" + 0.018*\"dies\" + 0.017*\"nomen\" + 0.017*\"delphi\" + 0.014*\"dominus\" + 0.012*\"debeo\" + 0.011*\"vita\" + 0.010*\"peccatum\" + 0.008*\"voluntas\" + 0.008*\"vivo\"\n",
      "2024-11-24 21:11:57,410 - INFO - topic #0 (0.067): 0.041*\"pater\" + 0.037*\"filius\" + 0.019*\"sanctus\" + 0.018*\"nomen\" + 0.015*\"spiritus\" + 0.011*\"christus\" + 0.010*\"gratia\" + 0.009*\"tertius\" + 0.008*\"dies\" + 0.008*\"vita\"\n",
      "2024-11-24 21:11:57,410 - INFO - topic diff=0.615090, rho=0.707107\n",
      "2024-11-24 21:11:57,411 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.08s', 'datetime': '2024-11-24T21:11:57.411086', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:57,413 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:11:57,468 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:11:57,473 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:11:57,477 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:11:57,505 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:11:57,640 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:11:57,668 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:11:57,670 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:11:58,387 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:11:58,402 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:11:58,406 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:11:58,412 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:11:58,419 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:11:58,422 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:11:58,429 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:11:58,433 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:11:58,438 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:11:58,450 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:11:58,454 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:11:58,457 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:11:58,467 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:11:58,469 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:11:58,473 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:11:58,477 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:11:58,484 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:11:58,485 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:11:58,486 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:11:58,488 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:11:58,491 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:11:58,508 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:11:58,513 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:11:58,518 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:11:58,523 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:11:58,526 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:11:58,530 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:11:58,534 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:11:58,537 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:11:58,540 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:11:58,542 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:11:58,550 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:11:58,558 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:11:58,561 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:11:58,567 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:11:58,579 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:11:58,588 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:11:58,595 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:11:58,597 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:11:58,602 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:11:58,609 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:11:58,610 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:11:58,612 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:11:58,616 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:11:58,631 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:11:58,635 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:11:58,636 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:11:58,639 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:11:58,642 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:11:58,646 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:11:58,651 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:11:58,652 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:11:58,732 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:11:58,751 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:11:58,925 - INFO - 第 5 折评估完成: NPMI=0.4891, Diversity=0.3933, Optimal Score=0.4412\n",
      "实验进度:  50%|█████     | 30/60 [01:26<01:28,  2.95s/it]2024-11-24 21:11:58,926 - INFO - \n",
      "评估阈值组合: min_freq=3, max_freq=1400\n",
      "2024-11-24 21:11:58,928 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:11:59,021 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:11:59,022 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:11:59.022142', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:11:59,026 - INFO - discarding 7439 tokens: [('apocalypsis', 16), ('element', 9), ('grando', 6), ('principalis', 18), ('specialis', 14), ('terraemotus', 5), ('aaron', 7), ('asper', 9), ('correctio', 16), ('expositio', 14)]...\n",
      "2024-11-24 21:11:59,026 - INFO - keeping 1400 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:11:59,028 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:11:59,028 - INFO - 词典过滤: 8839 -> 1400 个词\n",
      "2024-11-24 21:11:59,081 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:11:59,081 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:11:59,082 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:11:59,083 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:11:59,083 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:11:59,084 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:11:59,472 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:11:59,474 - INFO - topic #8 (0.067): 0.022*\"iustitia\" + 0.020*\"virtus\" + 0.013*\"spiritus\" + 0.012*\"christus\" + 0.010*\"verbum\" + 0.010*\"larissa\" + 0.009*\"vita\" + 0.008*\"veritas\" + 0.008*\"filius\" + 0.008*\"verus\"\n",
      "2024-11-24 21:11:59,474 - INFO - topic #7 (0.067): 0.031*\"christus\" + 0.023*\"spiritus\" + 0.016*\"pater\" + 0.012*\"virtus\" + 0.012*\"vita\" + 0.011*\"mundus\" + 0.010*\"semen\" + 0.009*\"debeo\" + 0.009*\"terra\" + 0.008*\"delphi\"\n",
      "2024-11-24 21:11:59,474 - INFO - topic #5 (0.067): 0.044*\"und\" + 0.016*\"is\" + 0.016*\"verbum\" + 0.015*\"wir\" + 0.014*\"dies\" + 0.012*\"got\" + 0.009*\"spiritus\" + 0.009*\"pulchritudo\" + 0.009*\"mundus\" + 0.009*\"christus\"\n",
      "2024-11-24 21:11:59,475 - INFO - topic #14 (0.067): 0.018*\"vita\" + 0.017*\"christus\" + 0.016*\"spiritus\" + 0.012*\"natura\" + 0.011*\"fides\" + 0.010*\"veritas\" + 0.009*\"delphi\" + 0.008*\"filius\" + 0.008*\"intellectus\" + 0.007*\"petrus\"\n",
      "2024-11-24 21:11:59,475 - INFO - topic #1 (0.067): 0.035*\"delphi\" + 0.019*\"christus\" + 0.016*\"spiritus\" + 0.013*\"vita\" + 0.013*\"virtus\" + 0.013*\"corpus\" + 0.011*\"homo\" + 0.010*\"verbum\" + 0.009*\"dominus\" + 0.008*\"natura\"\n",
      "2024-11-24 21:11:59,475 - INFO - topic diff=2.396923, rho=1.000000\n",
      "2024-11-24 21:11:59,878 - INFO - -6.937 per-word bound, 122.6 perplexity estimate based on a held-out corpus of 1716 documents with 82506 words\n",
      "2024-11-24 21:11:59,878 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:00,199 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:00,200 - INFO - topic #5 (0.067): 0.034*\"und\" + 0.021*\"pulchritudo\" + 0.020*\"dies\" + 0.018*\"verbum\" + 0.014*\"is\" + 0.011*\"wir\" + 0.010*\"via\" + 0.009*\"intellectus\" + 0.009*\"got\" + 0.008*\"viator\"\n",
      "2024-11-24 21:12:00,200 - INFO - topic #2 (0.067): 0.020*\"lux\" + 0.018*\"homo\" + 0.016*\"vita\" + 0.015*\"verbum\" + 0.014*\"filius\" + 0.012*\"christus\" + 0.012*\"mundus\" + 0.011*\"venio\" + 0.010*\"sapientia\" + 0.009*\"terra\"\n",
      "2024-11-24 21:12:00,201 - INFO - topic #14 (0.067): 0.020*\"natura\" + 0.019*\"vita\" + 0.018*\"veritas\" + 0.016*\"christus\" + 0.015*\"petrus\" + 0.013*\"imago\" + 0.012*\"spiritus\" + 0.011*\"fides\" + 0.009*\"intellectus\" + 0.009*\"ratio\"\n",
      "2024-11-24 21:12:00,201 - INFO - topic #8 (0.067): 0.049*\"iustitia\" + 0.026*\"virtus\" + 0.017*\"iustus\" + 0.013*\"veritas\" + 0.011*\"larissa\" + 0.010*\"christus\" + 0.008*\"spiritus\" + 0.008*\"verus\" + 0.008*\"verbum\" + 0.007*\"vita\"\n",
      "2024-11-24 21:12:00,201 - INFO - topic #0 (0.067): 0.020*\"christus\" + 0.018*\"filius\" + 0.017*\"homo\" + 0.016*\"pater\" + 0.016*\"verbum\" + 0.015*\"sanctus\" + 0.010*\"vita\" + 0.009*\"pax\" + 0.009*\"gratia\" + 0.009*\"spiritus\"\n",
      "2024-11-24 21:12:00,202 - INFO - topic diff=0.816336, rho=0.707107\n",
      "2024-11-24 21:12:00,202 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.12s', 'datetime': '2024-11-24T21:12:00.202506', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:00,205 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:00,252 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:12:00,255 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:12:00,259 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:12:00,261 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:12:00,262 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:12:00,265 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:12:00,385 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:12:01,527 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:12:01,615 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:12:01,705 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:12:01,785 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:12:01,815 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:12:01,819 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:12:01,840 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:12:01,854 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:12:01,862 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:12:01,902 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:12:01,918 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:12:01,919 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:12:01,934 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:12:01,951 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:12:01,961 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:12:01,964 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:12:01,968 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:12:01,970 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:12:01,977 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:12:01,980 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:12:01,996 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:12:02,016 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:12:02,034 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:12:02,036 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:12:02,038 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:12:02,045 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:12:02,050 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:12:02,055 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:12:02,065 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:12:02,067 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:12:02,070 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:12:02,074 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:12:02,077 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:12:02,081 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:12:02,089 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:12:02,101 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:12:02,111 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:12:02,113 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:12:02,117 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:12:02,120 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:12:02,122 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:12:02,142 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:12:02,147 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:12:02,152 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:12:02,161 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:12:02,185 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:12:02,199 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:12:02,205 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:12:02,249 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:12:02,258 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:12:02,260 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:12:02,267 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:12:02,593 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:02,703 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:12:02,871 - INFO - 第 1 折评估完成: NPMI=0.4860, Diversity=0.4133, Optimal Score=0.4497\n",
      "实验进度:  52%|█████▏    | 31/60 [01:30<01:34,  3.25s/it]2024-11-24 21:12:02,876 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:02,964 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:12:02,965 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:12:02.965139', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:02,968 - INFO - discarding 7496 tokens: [('aaron', 7), ('asper', 8), ('element', 7), ('expositio', 13), ('grando', 6), ('habitaculum', 19), ('latus', 7), ('leichnam', 2), ('noe', 12), ('perforo', 5)]...\n",
      "2024-11-24 21:12:02,968 - INFO - keeping 1400 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:02,970 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:12:02,970 - INFO - 词典过滤: 8896 -> 1400 个词\n",
      "2024-11-24 21:12:03,036 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:03,037 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:03,038 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:03,039 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:03,039 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:03,039 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:03,437 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:03,439 - INFO - topic #8 (0.067): 0.034*\"christus\" + 0.021*\"vita\" + 0.015*\"verbum\" + 0.013*\"pater\" + 0.013*\"homo\" + 0.011*\"lux\" + 0.009*\"debeo\" + 0.009*\"delphi\" + 0.007*\"stella\" + 0.007*\"rex\"\n",
      "2024-11-24 21:12:03,440 - INFO - topic #7 (0.067): 0.022*\"christus\" + 0.018*\"verbum\" + 0.015*\"filius\" + 0.014*\"virtus\" + 0.013*\"debeo\" + 0.010*\"semen\" + 0.010*\"vita\" + 0.009*\"volo\" + 0.008*\"terra\" + 0.008*\"delphi\"\n",
      "2024-11-24 21:12:03,440 - INFO - topic #5 (0.067): 0.024*\"christus\" + 0.015*\"ratio\" + 0.015*\"und\" + 0.014*\"fides\" + 0.013*\"symbatios\" + 0.012*\"peccatum\" + 0.010*\"virtus\" + 0.010*\"spiritus\" + 0.009*\"amor\" + 0.008*\"vita\"\n",
      "2024-11-24 21:12:03,440 - INFO - topic #14 (0.067): 0.033*\"pater\" + 0.026*\"filius\" + 0.022*\"christus\" + 0.022*\"vita\" + 0.015*\"veritas\" + 0.014*\"spiritus\" + 0.011*\"homo\" + 0.009*\"mundus\" + 0.008*\"dies\" + 0.008*\"opus\"\n",
      "2024-11-24 21:12:03,441 - INFO - topic #1 (0.067): 0.026*\"christus\" + 0.020*\"vita\" + 0.012*\"debeo\" + 0.012*\"virtus\" + 0.011*\"filius\" + 0.011*\"gegen\" + 0.011*\"panis\" + 0.010*\"und\" + 0.010*\"intellectus\" + 0.009*\"divinus\"\n",
      "2024-11-24 21:12:03,441 - INFO - topic diff=2.232802, rho=1.000000\n",
      "2024-11-24 21:12:03,857 - INFO - -6.935 per-word bound, 122.4 perplexity estimate based on a held-out corpus of 1716 documents with 82647 words\n",
      "2024-11-24 21:12:03,858 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:04,189 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:04,190 - INFO - topic #5 (0.067): 0.024*\"symbatios\" + 0.022*\"fides\" + 0.022*\"peccatum\" + 0.020*\"ratio\" + 0.020*\"christus\" + 0.013*\"amor\" + 0.009*\"virtus\" + 0.008*\"spiritus\" + 0.008*\"diligo\" + 0.007*\"verus\"\n",
      "2024-11-24 21:12:04,191 - INFO - topic #2 (0.067): 0.061*\"spiritus\" + 0.025*\"homo\" + 0.025*\"christus\" + 0.019*\"mundus\" + 0.013*\"dies\" + 0.012*\"vita\" + 0.012*\"venio\" + 0.011*\"filius\" + 0.010*\"motus\" + 0.008*\"veritas\"\n",
      "2024-11-24 21:12:04,191 - INFO - topic #14 (0.067): 0.057*\"pater\" + 0.042*\"filius\" + 0.027*\"christus\" + 0.020*\"veritas\" + 0.018*\"vita\" + 0.013*\"spiritus\" + 0.012*\"homo\" + 0.009*\"dies\" + 0.009*\"cognosco\" + 0.009*\"opus\"\n",
      "2024-11-24 21:12:04,191 - INFO - topic #8 (0.067): 0.041*\"christus\" + 0.020*\"vita\" + 0.016*\"verbum\" + 0.013*\"homo\" + 0.012*\"pater\" + 0.010*\"lux\" + 0.009*\"stella\" + 0.009*\"debeo\" + 0.008*\"delphi\" + 0.008*\"gaudium\"\n",
      "2024-11-24 21:12:04,192 - INFO - topic #0 (0.067): 0.035*\"verbum\" + 0.019*\"pater\" + 0.018*\"barabbas\" + 0.014*\"terra\" + 0.014*\"mundus\" + 0.013*\"christus\" + 0.013*\"lex\" + 0.012*\"filius\" + 0.011*\"vita\" + 0.011*\"delphi\"\n",
      "2024-11-24 21:12:04,192 - INFO - topic diff=0.820391, rho=0.707107\n",
      "2024-11-24 21:12:04,192 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.15s', 'datetime': '2024-11-24T21:12:04.192837', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:04,195 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:04,416 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:12:04,450 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:12:04,522 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:12:04,583 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:12:04,585 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:12:04,586 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:12:04,587 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:12:05,381 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:12:05,401 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:12:05,404 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:12:05,414 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:12:05,421 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:12:05,437 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:12:05,444 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:12:05,447 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:12:05,451 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:12:05,456 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:12:05,461 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:12:05,469 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:12:05,473 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:12:05,481 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:12:05,483 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:12:05,494 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:12:05,496 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:12:05,500 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:12:05,517 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:12:05,519 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:12:05,527 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:12:05,533 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:12:05,538 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:12:05,542 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:12:05,556 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:12:05,564 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:12:05,570 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:12:05,602 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:12:05,773 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:12:05,788 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:12:05,800 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:12:05,805 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:12:05,810 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:12:05,811 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:12:05,812 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:12:05,813 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:12:05,814 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:12:05,815 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:12:05,816 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:12:05,824 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:12:05,831 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:12:05,850 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:12:05,871 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:12:05,877 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:12:05,883 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:12:05,885 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:12:05,890 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:12:05,892 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:12:05,905 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:12:05,917 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:12:05,933 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:12:05,939 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:12:06,146 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:06,158 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:12:06,354 - INFO - 第 2 折评估完成: NPMI=0.4908, Diversity=0.4067, Optimal Score=0.4487\n",
      "实验进度:  53%|█████▎    | 32/60 [01:34<01:32,  3.32s/it]2024-11-24 21:12:06,358 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:06,440 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:12:06,440 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:12:06.440768', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:06,444 - INFO - discarding 7434 tokens: [('apocalypsis', 13), ('element', 9), ('grando', 6), ('principalis', 17), ('specialis', 13), ('terraemotus', 6), ('aaron', 8), ('asper', 9), ('contritio', 14), ('correctio', 17)]...\n",
      "2024-11-24 21:12:06,444 - INFO - keeping 1400 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:06,446 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:12:06,447 - INFO - 词典过滤: 8834 -> 1400 个词\n",
      "2024-11-24 21:12:06,703 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:06,704 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:06,704 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:06,705 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:06,706 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:06,706 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:07,266 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:07,268 - INFO - topic #8 (0.067): 0.018*\"vita\" + 0.013*\"larissa\" + 0.013*\"homo\" + 0.012*\"christus\" + 0.012*\"iustitia\" + 0.011*\"spiritus\" + 0.010*\"debeo\" + 0.010*\"lux\" + 0.009*\"amor\" + 0.008*\"dies\"\n",
      "2024-11-24 21:12:07,268 - INFO - topic #7 (0.067): 0.028*\"christus\" + 0.019*\"mundus\" + 0.016*\"debeo\" + 0.010*\"spiritus\" + 0.009*\"ratio\" + 0.009*\"delphi\" + 0.009*\"rex\" + 0.009*\"virtus\" + 0.009*\"volo\" + 0.007*\"vita\"\n",
      "2024-11-24 21:12:07,268 - INFO - topic #5 (0.067): 0.060*\"und\" + 0.031*\"dies\" + 0.016*\"is\" + 0.014*\"verbum\" + 0.014*\"wir\" + 0.012*\"spiritus\" + 0.012*\"peccatum\" + 0.012*\"christus\" + 0.011*\"unser\" + 0.010*\"got\"\n",
      "2024-11-24 21:12:07,269 - INFO - topic #14 (0.067): 0.027*\"vita\" + 0.019*\"filius\" + 0.014*\"christus\" + 0.011*\"homo\" + 0.008*\"mundus\" + 0.008*\"symbatios\" + 0.007*\"pater\" + 0.007*\"mors\" + 0.007*\"scio\" + 0.006*\"ratio\"\n",
      "2024-11-24 21:12:07,269 - INFO - topic #1 (0.067): 0.034*\"vita\" + 0.020*\"christus\" + 0.018*\"spiritus\" + 0.015*\"mors\" + 0.014*\"delphi\" + 0.011*\"verbum\" + 0.010*\"dominus\" + 0.009*\"lex\" + 0.009*\"filius\" + 0.007*\"opus\"\n",
      "2024-11-24 21:12:07,269 - INFO - topic diff=2.470042, rho=1.000000\n",
      "2024-11-24 21:12:07,685 - INFO - -6.921 per-word bound, 121.2 perplexity estimate based on a held-out corpus of 1716 documents with 81296 words\n",
      "2024-11-24 21:12:07,686 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:08,001 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:08,002 - INFO - topic #5 (0.067): 0.078*\"dies\" + 0.038*\"und\" + 0.034*\"peccatum\" + 0.014*\"verbum\" + 0.011*\"is\" + 0.010*\"christus\" + 0.009*\"spiritus\" + 0.009*\"delphi\" + 0.009*\"wir\" + 0.009*\"motus\"\n",
      "2024-11-24 21:12:08,003 - INFO - topic #2 (0.067): 0.020*\"christus\" + 0.014*\"homo\" + 0.013*\"vita\" + 0.011*\"filius\" + 0.010*\"lex\" + 0.010*\"via\" + 0.010*\"mundus\" + 0.009*\"bonus\" + 0.009*\"iustitia\" + 0.009*\"annas\"\n",
      "2024-11-24 21:12:08,003 - INFO - topic #14 (0.067): 0.024*\"vita\" + 0.014*\"filius\" + 0.012*\"homo\" + 0.012*\"mare\" + 0.010*\"christus\" + 0.009*\"symbatios\" + 0.009*\"contemplatio\" + 0.008*\"dies\" + 0.008*\"theophilus\" + 0.007*\"gebresten\"\n",
      "2024-11-24 21:12:08,003 - INFO - topic #8 (0.067): 0.024*\"iustitia\" + 0.019*\"larissa\" + 0.015*\"vita\" + 0.014*\"sol\" + 0.013*\"homo\" + 0.012*\"lux\" + 0.012*\"iustus\" + 0.011*\"christus\" + 0.010*\"dies\" + 0.009*\"debeo\"\n",
      "2024-11-24 21:12:08,004 - INFO - topic #0 (0.067): 0.045*\"filius\" + 0.042*\"pater\" + 0.022*\"verbum\" + 0.017*\"christus\" + 0.015*\"gratia\" + 0.012*\"homo\" + 0.010*\"sanctus\" + 0.010*\"ars\" + 0.010*\"semen\" + 0.009*\"imago\"\n",
      "2024-11-24 21:12:08,004 - INFO - topic diff=0.830118, rho=0.707107\n",
      "2024-11-24 21:12:08,004 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.30s', 'datetime': '2024-11-24T21:12:08.004946', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:08,008 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:08,072 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:12:08,090 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:12:08,115 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:12:08,125 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:12:08,166 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:12:08,198 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:12:08,200 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:12:09,070 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:12:09,097 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:12:09,135 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:12:09,150 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:12:09,153 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:12:09,169 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:12:09,171 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:12:09,188 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:12:09,191 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:12:09,194 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:12:09,199 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:12:09,211 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:12:09,219 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:12:09,232 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:12:09,410 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:12:09,437 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:12:09,450 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:12:09,451 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:12:09,453 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:12:09,453 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:12:09,456 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:12:09,466 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:12:09,474 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:12:09,476 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:12:09,478 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:12:09,483 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:12:09,490 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:12:09,492 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:12:09,495 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:12:09,506 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:12:09,520 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:12:09,524 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:12:09,527 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:12:09,532 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:12:09,534 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:12:09,549 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:12:09,567 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:12:09,570 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:12:09,573 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:12:09,583 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:12:09,610 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:12:09,654 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:12:09,657 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:12:09,665 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:12:09,667 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:12:09,670 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:12:09,674 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:12:09,681 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:12:09,684 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:12:09,699 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:12:09,701 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:12:09,702 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:12:09,958 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:09,992 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:12:10,179 - INFO - 第 3 折评估完成: NPMI=0.4864, Diversity=0.4400, Optimal Score=0.4632\n",
      "实验进度:  55%|█████▌    | 33/60 [01:37<01:33,  3.47s/it]2024-11-24 21:12:10,182 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:10,290 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:12:10,291 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:12:10.291623', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:10,296 - INFO - discarding 7485 tokens: [('apocalypsis', 14), ('element', 6), ('grando', 3), ('principalis', 16), ('specialis', 12), ('terraemotus', 3), ('anatomia', 1), ('caesarius', 10), ('capitaneus', 11), ('carnalitas', 7)]...\n",
      "2024-11-24 21:12:10,297 - INFO - keeping 1400 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:10,299 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:12:10,300 - INFO - 词典过滤: 8885 -> 1400 个词\n",
      "2024-11-24 21:12:10,355 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:10,355 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:10,356 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:10,357 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:10,358 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:10,358 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:10,745 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:10,746 - INFO - topic #8 (0.067): 0.020*\"christus\" + 0.020*\"lux\" + 0.011*\"virtus\" + 0.010*\"verbum\" + 0.009*\"filius\" + 0.009*\"venio\" + 0.009*\"iudico\" + 0.008*\"rex\" + 0.008*\"petrus\" + 0.008*\"intellectus\"\n",
      "2024-11-24 21:12:10,746 - INFO - topic #7 (0.067): 0.023*\"christus\" + 0.022*\"vita\" + 0.015*\"filius\" + 0.014*\"homo\" + 0.014*\"mundus\" + 0.012*\"verbum\" + 0.010*\"spiritus\" + 0.009*\"panis\" + 0.009*\"delphi\" + 0.007*\"pater\"\n",
      "2024-11-24 21:12:10,747 - INFO - topic #5 (0.067): 0.042*\"und\" + 0.023*\"dies\" + 0.021*\"pater\" + 0.020*\"christus\" + 0.018*\"spiritus\" + 0.017*\"is\" + 0.015*\"filius\" + 0.014*\"verbum\" + 0.013*\"homo\" + 0.011*\"vita\"\n",
      "2024-11-24 21:12:10,747 - INFO - topic #14 (0.067): 0.036*\"und\" + 0.029*\"dies\" + 0.011*\"gratia\" + 0.010*\"filius\" + 0.010*\"mo\" + 0.009*\"delphi\" + 0.008*\"lux\" + 0.008*\"forma\" + 0.007*\"nichtestis\" + 0.007*\"homo\"\n",
      "2024-11-24 21:12:10,747 - INFO - topic #1 (0.067): 0.028*\"homo\" + 0.021*\"christus\" + 0.012*\"veritas\" + 0.012*\"natura\" + 0.011*\"verbum\" + 0.010*\"vita\" + 0.010*\"spiritus\" + 0.009*\"sapientia\" + 0.008*\"delphi\" + 0.008*\"filius\"\n",
      "2024-11-24 21:12:10,748 - INFO - topic diff=2.501997, rho=1.000000\n",
      "2024-11-24 21:12:11,150 - INFO - -6.921 per-word bound, 121.2 perplexity estimate based on a held-out corpus of 1716 documents with 81787 words\n",
      "2024-11-24 21:12:11,150 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:11,469 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:11,470 - INFO - topic #5 (0.067): 0.039*\"pater\" + 0.037*\"dies\" + 0.026*\"und\" + 0.023*\"filius\" + 0.020*\"christus\" + 0.016*\"verbum\" + 0.015*\"spiritus\" + 0.012*\"homo\" + 0.011*\"is\" + 0.010*\"mundus\"\n",
      "2024-11-24 21:12:11,471 - INFO - topic #2 (0.067): 0.022*\"homo\" + 0.018*\"natura\" + 0.018*\"gratia\" + 0.017*\"virtus\" + 0.017*\"ars\" + 0.016*\"verbum\" + 0.013*\"intellectus\" + 0.012*\"imago\" + 0.012*\"filius\" + 0.011*\"creo\"\n",
      "2024-11-24 21:12:11,471 - INFO - topic #14 (0.067): 0.096*\"dies\" + 0.019*\"annus\" + 0.014*\"und\" + 0.011*\"gratia\" + 0.011*\"dacia\" + 0.010*\"sirenes\" + 0.010*\"octavus\" + 0.010*\"mensis\" + 0.008*\"sufficio\" + 0.008*\"hoffnung\"\n",
      "2024-11-24 21:12:11,472 - INFO - topic #8 (0.067): 0.031*\"lux\" + 0.022*\"christus\" + 0.011*\"sol\" + 0.010*\"venio\" + 0.010*\"mitto\" + 0.009*\"iudico\" + 0.009*\"filius\" + 0.009*\"tenebrae\" + 0.009*\"verbum\" + 0.008*\"petrus\"\n",
      "2024-11-24 21:12:11,472 - INFO - topic #0 (0.067): 0.035*\"nomen\" + 0.022*\"fides\" + 0.016*\"verbum\" + 0.015*\"christus\" + 0.011*\"gegen\" + 0.011*\"debeo\" + 0.010*\"dominus\" + 0.009*\"ratio\" + 0.008*\"ordo\" + 0.007*\"scribo\"\n",
      "2024-11-24 21:12:11,472 - INFO - topic diff=0.843534, rho=0.707107\n",
      "2024-11-24 21:12:11,473 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.12s', 'datetime': '2024-11-24T21:12:11.473045', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:11,475 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:11,625 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:12:11,631 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:12:11,636 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:12:11,639 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:12:11,641 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:12:11,643 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:12:11,736 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:12:12,544 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:12:12,560 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:12:12,569 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:12:12,580 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:12:12,587 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:12:12,597 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:12:12,609 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:12:12,623 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:12:12,625 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:12:12,631 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:12:12,660 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:12:12,662 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:12:12,670 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:12:12,675 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:12:12,677 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:12:12,681 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:12:12,688 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:12:12,694 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:12:12,699 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:12:12,715 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:12:12,735 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:12:12,787 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:12:12,796 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:12:12,810 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:12:12,920 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:12:12,923 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:12:12,928 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:12:12,931 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:12:12,957 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:12:12,962 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:12:12,965 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:12:12,966 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:12:12,967 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:12:12,968 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:12:12,969 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:12:12,970 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:12:12,974 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:12:12,980 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:12:12,982 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:12:13,008 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:12:13,009 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:12:13,013 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:12:13,016 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:12:13,024 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:12:13,037 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:12:13,039 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:12:13,044 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:12:13,050 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:12:13,051 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:12:13,054 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:12:13,070 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:12:13,071 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:12:13,345 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:13,362 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:12:13,540 - INFO - 第 4 折评估完成: NPMI=0.4851, Diversity=0.4600, Optimal Score=0.4725\n",
      "实验进度:  57%|█████▋    | 34/60 [01:41<01:29,  3.44s/it]2024-11-24 21:12:13,542 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:13,624 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:12:13,625 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:12:13.624995', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:13,628 - INFO - discarding 7503 tokens: [('apocalypsis', 15), ('element', 9), ('grando', 7), ('principalis', 16), ('specialis', 11), ('terraemotus', 5), ('aaron', 5), ('asper', 10), ('correctio', 17), ('expositio', 12)]...\n",
      "2024-11-24 21:12:13,628 - INFO - keeping 1400 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:13,629 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:12:13,630 - INFO - 词典过滤: 8903 -> 1400 个词\n",
      "2024-11-24 21:12:13,685 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:13,685 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:13,686 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:13,687 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:13,688 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:13,688 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:14,076 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:14,077 - INFO - topic #8 (0.067): 0.022*\"filius\" + 0.021*\"spiritus\" + 0.018*\"homo\" + 0.014*\"larissa\" + 0.013*\"christus\" + 0.013*\"natura\" + 0.011*\"corpus\" + 0.011*\"regnum\" + 0.010*\"unio\" + 0.010*\"locus\"\n",
      "2024-11-24 21:12:14,078 - INFO - topic #7 (0.067): 0.030*\"christus\" + 0.023*\"virtus\" + 0.019*\"vita\" + 0.014*\"homo\" + 0.014*\"amor\" + 0.014*\"delphi\" + 0.013*\"pater\" + 0.013*\"filius\" + 0.009*\"spiritus\" + 0.008*\"verbum\"\n",
      "2024-11-24 21:12:14,078 - INFO - topic #5 (0.067): 0.051*\"und\" + 0.026*\"dies\" + 0.019*\"wir\" + 0.016*\"homo\" + 0.013*\"christus\" + 0.012*\"is\" + 0.012*\"verbum\" + 0.011*\"debeo\" + 0.011*\"got\" + 0.010*\"natura\"\n",
      "2024-11-24 21:12:14,078 - INFO - topic #14 (0.067): 0.022*\"christus\" + 0.015*\"pater\" + 0.013*\"venio\" + 0.013*\"rex\" + 0.011*\"pax\" + 0.010*\"filius\" + 0.009*\"homo\" + 0.008*\"delphi\" + 0.007*\"spiritus\" + 0.007*\"vinco\"\n",
      "2024-11-24 21:12:14,079 - INFO - topic #1 (0.067): 0.022*\"christus\" + 0.018*\"pater\" + 0.012*\"filius\" + 0.011*\"sanctus\" + 0.011*\"dominus\" + 0.011*\"virtus\" + 0.010*\"spiritus\" + 0.010*\"verbum\" + 0.009*\"natura\" + 0.007*\"homo\"\n",
      "2024-11-24 21:12:14,079 - INFO - topic diff=2.415692, rho=1.000000\n",
      "2024-11-24 21:12:14,486 - INFO - -6.939 per-word bound, 122.7 perplexity estimate based on a held-out corpus of 1716 documents with 82495 words\n",
      "2024-11-24 21:12:14,487 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:14,803 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:14,804 - INFO - topic #5 (0.067): 0.058*\"dies\" + 0.039*\"und\" + 0.014*\"wir\" + 0.013*\"homo\" + 0.012*\"christus\" + 0.011*\"verbum\" + 0.010*\"natura\" + 0.010*\"is\" + 0.010*\"debeo\" + 0.008*\"semen\"\n",
      "2024-11-24 21:12:14,804 - INFO - topic #2 (0.067): 0.028*\"verbum\" + 0.025*\"nomen\" + 0.018*\"intellectus\" + 0.016*\"vita\" + 0.013*\"lux\" + 0.011*\"divinus\" + 0.010*\"principium\" + 0.010*\"gegen\" + 0.010*\"virtus\" + 0.010*\"delphi\"\n",
      "2024-11-24 21:12:14,805 - INFO - topic #14 (0.067): 0.022*\"christus\" + 0.015*\"pater\" + 0.012*\"sirenes\" + 0.012*\"pax\" + 0.012*\"homo\" + 0.011*\"venio\" + 0.011*\"filius\" + 0.011*\"rex\" + 0.010*\"nomen\" + 0.008*\"virgo\"\n",
      "2024-11-24 21:12:14,805 - INFO - topic #8 (0.067): 0.022*\"larissa\" + 0.020*\"homo\" + 0.020*\"natura\" + 0.019*\"filius\" + 0.016*\"spiritus\" + 0.013*\"locus\" + 0.013*\"unio\" + 0.012*\"corpus\" + 0.012*\"regnum\" + 0.011*\"christus\"\n",
      "2024-11-24 21:12:14,805 - INFO - topic #0 (0.067): 0.041*\"fides\" + 0.022*\"spiritus\" + 0.022*\"verbum\" + 0.016*\"christus\" + 0.014*\"volo\" + 0.014*\"ratio\" + 0.014*\"homo\" + 0.013*\"credo\" + 0.011*\"delphi\" + 0.011*\"vita\"\n",
      "2024-11-24 21:12:14,806 - INFO - topic diff=0.810077, rho=0.707107\n",
      "2024-11-24 21:12:14,806 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.12s', 'datetime': '2024-11-24T21:12:14.806622', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:14,809 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:14,857 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:12:14,868 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:12:14,875 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:12:14,886 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:12:14,889 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:12:14,916 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:12:15,062 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:12:15,804 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:12:15,832 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:12:15,871 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:12:15,906 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:12:15,924 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:12:15,951 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:12:15,957 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:12:15,969 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:12:15,982 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:12:16,029 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:12:16,041 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:12:16,059 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:12:16,072 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:12:16,079 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:12:16,083 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:12:16,085 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:12:16,088 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:12:16,090 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:12:16,092 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:12:16,094 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:12:16,096 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:12:16,098 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:12:16,100 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:12:16,102 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:12:16,120 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:12:16,125 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:12:16,128 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:12:16,137 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:12:16,139 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:12:16,140 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:12:16,154 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:12:16,158 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:12:16,161 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:12:16,162 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:12:16,187 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:12:16,198 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:12:16,201 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:12:16,203 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:12:16,217 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:12:16,367 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:12:16,369 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:12:16,391 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:12:16,394 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:12:16,395 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:12:16,397 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:12:16,419 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:12:16,442 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:12:16,444 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:12:16,449 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:12:16,451 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:12:16,462 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:12:16,468 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:12:16,681 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:16,694 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:12:16,852 - INFO - 第 5 折评估完成: NPMI=0.4889, Diversity=0.4400, Optimal Score=0.4644\n",
      "实验进度:  58%|█████▊    | 35/60 [01:44<01:24,  3.40s/it]2024-11-24 21:12:16,853 - INFO - \n",
      "评估阈值组合: min_freq=3, max_freq=2000\n",
      "2024-11-24 21:12:16,858 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:16,954 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:12:16,955 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:12:16.955023', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:16,958 - INFO - discarding 6839 tokens: [('element', 9), ('grando', 6), ('terraemotus', 5), ('aaron', 7), ('asper', 9), ('latus', 7), ('leichnam', 3), ('noe', 10), ('perforo', 7), ('phoenica', 11)]...\n",
      "2024-11-24 21:12:16,958 - INFO - keeping 2000 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:16,959 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:12:16,960 - INFO - 词典过滤: 8839 -> 2000 个词\n",
      "2024-11-24 21:12:17,015 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:17,016 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:17,017 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:17,019 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:17,019 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:17,019 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:17,419 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:17,420 - INFO - topic #0 (0.067): 0.023*\"vita\" + 0.022*\"christus\" + 0.021*\"spiritus\" + 0.019*\"pater\" + 0.014*\"filius\" + 0.010*\"veritas\" + 0.008*\"sanctus\" + 0.008*\"venio\" + 0.008*\"verbum\" + 0.007*\"cognosco\"\n",
      "2024-11-24 21:12:17,421 - INFO - topic #8 (0.067): 0.024*\"spiritus\" + 0.020*\"christus\" + 0.016*\"verbum\" + 0.015*\"vita\" + 0.012*\"intellectus\" + 0.012*\"fides\" + 0.009*\"symbatios\" + 0.009*\"panis\" + 0.007*\"cognosco\" + 0.007*\"lex\"\n",
      "2024-11-24 21:12:17,421 - INFO - topic #14 (0.067): 0.021*\"vita\" + 0.016*\"fides\" + 0.013*\"spiritus\" + 0.012*\"delphi\" + 0.011*\"gegen\" + 0.010*\"christus\" + 0.009*\"venio\" + 0.008*\"mundus\" + 0.008*\"homo\" + 0.008*\"symbatios\"\n",
      "2024-11-24 21:12:17,421 - INFO - topic #1 (0.067): 0.033*\"christus\" + 0.021*\"und\" + 0.015*\"fides\" + 0.014*\"mundus\" + 0.013*\"regnum\" + 0.012*\"dies\" + 0.011*\"filius\" + 0.010*\"verbum\" + 0.009*\"wir\" + 0.008*\"homo\"\n",
      "2024-11-24 21:12:17,422 - INFO - topic #3 (0.067): 0.037*\"spiritus\" + 0.019*\"vita\" + 0.015*\"lux\" + 0.014*\"mors\" + 0.013*\"delphi\" + 0.013*\"christus\" + 0.009*\"mundus\" + 0.008*\"filius\" + 0.008*\"verbum\" + 0.008*\"sanctus\"\n",
      "2024-11-24 21:12:17,422 - INFO - topic diff=3.569692, rho=1.000000\n",
      "2024-11-24 21:12:17,924 - INFO - -7.230 per-word bound, 150.2 perplexity estimate based on a held-out corpus of 1716 documents with 87656 words\n",
      "2024-11-24 21:12:17,925 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:18,244 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:18,246 - INFO - topic #11 (0.067): 0.019*\"christus\" + 0.017*\"rex\" + 0.013*\"homo\" + 0.013*\"locus\" + 0.012*\"corpus\" + 0.012*\"delphi\" + 0.011*\"peccatum\" + 0.011*\"natura\" + 0.010*\"ratio\" + 0.008*\"venio\"\n",
      "2024-11-24 21:12:18,246 - INFO - topic #3 (0.067): 0.048*\"spiritus\" + 0.028*\"lux\" + 0.023*\"mors\" + 0.019*\"vita\" + 0.018*\"delphi\" + 0.014*\"tenebrae\" + 0.014*\"christus\" + 0.009*\"verbum\" + 0.009*\"sanctus\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:12:18,247 - INFO - topic #14 (0.067): 0.024*\"vita\" + 0.021*\"fides\" + 0.014*\"delphi\" + 0.013*\"symbatios\" + 0.013*\"gegen\" + 0.011*\"clotho\" + 0.010*\"spiritus\" + 0.010*\"iustitia\" + 0.008*\"christus\" + 0.008*\"homo\"\n",
      "2024-11-24 21:12:18,247 - INFO - topic #7 (0.067): 0.026*\"homo\" + 0.022*\"verbum\" + 0.019*\"filius\" + 0.017*\"christus\" + 0.017*\"natura\" + 0.016*\"pater\" + 0.015*\"spiritus\" + 0.013*\"vita\" + 0.010*\"larissa\" + 0.009*\"mundus\"\n",
      "2024-11-24 21:12:18,247 - INFO - topic #0 (0.067): 0.028*\"christus\" + 0.025*\"vita\" + 0.023*\"pater\" + 0.020*\"spiritus\" + 0.016*\"filius\" + 0.014*\"veritas\" + 0.012*\"nomen\" + 0.011*\"sanctus\" + 0.010*\"venio\" + 0.009*\"credo\"\n",
      "2024-11-24 21:12:18,248 - INFO - topic diff=0.968955, rho=0.707107\n",
      "2024-11-24 21:12:18,248 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.23s', 'datetime': '2024-11-24T21:12:18.248391', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:18,251 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:18,706 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:12:18,709 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:12:18,710 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:12:18,711 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:12:18,712 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:12:18,713 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:12:18,809 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:12:19,374 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:12:19,410 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:12:19,443 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:12:19,445 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:12:19,453 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:12:19,475 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:12:19,490 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:12:19,512 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:12:19,527 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:12:19,532 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:12:19,544 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:12:19,564 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:12:19,568 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:12:19,570 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:12:19,575 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:12:19,580 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:12:19,586 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:12:19,592 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:12:19,594 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:12:19,595 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:12:19,597 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:12:19,599 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:12:19,601 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:12:19,602 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:12:19,604 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:12:19,606 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:12:19,612 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:12:19,615 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:12:19,624 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:12:19,627 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:12:19,630 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:12:19,642 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:12:19,646 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:12:19,662 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:12:19,668 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:12:19,819 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:12:19,848 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:12:19,852 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:12:19,855 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:12:19,861 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:12:19,868 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:12:19,872 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:12:19,874 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:12:19,887 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:12:19,896 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:12:19,899 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:12:19,908 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:12:19,911 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:12:19,917 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:12:19,922 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:12:19,925 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:12:19,932 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:12:20,081 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:20,097 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:12:20,279 - INFO - 第 1 折评估完成: NPMI=0.4849, Diversity=0.4400, Optimal Score=0.4625\n",
      "实验进度:  60%|██████    | 36/60 [01:48<01:21,  3.41s/it]2024-11-24 21:12:20,282 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:20,377 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:12:20,378 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:12:20.378100', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:20,383 - INFO - discarding 6896 tokens: [('aaron', 7), ('asper', 8), ('element', 7), ('grando', 6), ('latus', 7), ('leichnam', 2), ('perforo', 5), ('phoenica', 10), ('potestativus', 1), ('primitivus', 3)]...\n",
      "2024-11-24 21:12:20,384 - INFO - keeping 2000 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:20,386 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:12:20,387 - INFO - 词典过滤: 8896 -> 2000 个词\n",
      "2024-11-24 21:12:20,559 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:20,559 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:20,560 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:20,561 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:20,562 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:20,562 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:20,964 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:20,966 - INFO - topic #0 (0.067): 0.028*\"vita\" + 0.020*\"delphi\" + 0.016*\"corpus\" + 0.013*\"spiritus\" + 0.010*\"christus\" + 0.008*\"virtus\" + 0.008*\"nomen\" + 0.008*\"vivo\" + 0.008*\"pulchritudo\" + 0.007*\"verbum\"\n",
      "2024-11-24 21:12:20,966 - INFO - topic #8 (0.067): 0.020*\"christus\" + 0.013*\"pater\" + 0.013*\"intellectus\" + 0.012*\"volo\" + 0.011*\"filius\" + 0.011*\"vita\" + 0.009*\"intellego\" + 0.009*\"mors\" + 0.008*\"verbum\" + 0.008*\"fides\"\n",
      "2024-11-24 21:12:20,967 - INFO - topic #14 (0.067): 0.016*\"christus\" + 0.014*\"debeo\" + 0.012*\"rex\" + 0.010*\"homo\" + 0.010*\"dies\" + 0.010*\"vita\" + 0.007*\"cognosco\" + 0.007*\"volo\" + 0.006*\"dominus\" + 0.006*\"veritas\"\n",
      "2024-11-24 21:12:20,967 - INFO - topic #1 (0.067): 0.015*\"christus\" + 0.014*\"verbum\" + 0.013*\"rex\" + 0.013*\"homo\" + 0.012*\"spiritus\" + 0.009*\"vita\" + 0.009*\"larissa\" + 0.009*\"sapientia\" + 0.008*\"pater\" + 0.008*\"oboedio\"\n",
      "2024-11-24 21:12:20,968 - INFO - topic #3 (0.067): 0.031*\"christus\" + 0.015*\"und\" + 0.014*\"dies\" + 0.013*\"uns\" + 0.012*\"lex\" + 0.011*\"wir\" + 0.009*\"unser\" + 0.009*\"fides\" + 0.009*\"amor\" + 0.008*\"finis\"\n",
      "2024-11-24 21:12:20,968 - INFO - topic diff=3.533654, rho=1.000000\n",
      "2024-11-24 21:12:21,375 - INFO - -7.234 per-word bound, 150.6 perplexity estimate based on a held-out corpus of 1716 documents with 87826 words\n",
      "2024-11-24 21:12:21,375 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:21,698 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:21,699 - INFO - topic #11 (0.067): 0.036*\"christus\" + 0.035*\"veritas\" + 0.015*\"vita\" + 0.010*\"via\" + 0.010*\"verus\" + 0.009*\"filius\" + 0.008*\"mundus\" + 0.008*\"intellectus\" + 0.008*\"venio\" + 0.008*\"mors\"\n",
      "2024-11-24 21:12:21,700 - INFO - topic #3 (0.067): 0.046*\"dies\" + 0.033*\"lex\" + 0.032*\"christus\" + 0.025*\"annus\" + 0.012*\"sabbatum\" + 0.011*\"iesse\" + 0.010*\"primus\" + 0.010*\"finis\" + 0.008*\"abraham\" + 0.008*\"ecclesia\"\n",
      "2024-11-24 21:12:21,700 - INFO - topic #14 (0.067): 0.020*\"christus\" + 0.018*\"dies\" + 0.016*\"debeo\" + 0.010*\"annus\" + 0.009*\"dominus\" + 0.008*\"homo\" + 0.008*\"rex\" + 0.007*\"volo\" + 0.007*\"dimitto\" + 0.006*\"sanctus\"\n",
      "2024-11-24 21:12:21,701 - INFO - topic #7 (0.067): 0.030*\"spiritus\" + 0.019*\"virtus\" + 0.017*\"vita\" + 0.016*\"ars\" + 0.015*\"delphi\" + 0.013*\"amor\" + 0.012*\"sanctus\" + 0.012*\"motus\" + 0.009*\"natura\" + 0.009*\"imago\"\n",
      "2024-11-24 21:12:21,701 - INFO - topic #0 (0.067): 0.034*\"vita\" + 0.025*\"delphi\" + 0.020*\"corpus\" + 0.015*\"nomen\" + 0.011*\"spiritus\" + 0.009*\"vivo\" + 0.009*\"christus\" + 0.008*\"amor\" + 0.008*\"gloria\" + 0.008*\"dominus\"\n",
      "2024-11-24 21:12:21,701 - INFO - topic diff=1.005497, rho=0.707107\n",
      "2024-11-24 21:12:21,702 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.14s', 'datetime': '2024-11-24T21:12:21.702274', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:21,704 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:22,161 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:12:22,164 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:12:22,165 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:12:22,167 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:12:22,169 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:12:22,170 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:12:22,172 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:12:22,725 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:12:22,772 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:12:22,799 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:12:22,836 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:12:22,876 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:12:23,038 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:12:23,074 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:12:23,097 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:12:23,139 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:12:23,143 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:12:23,158 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:12:23,163 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:12:23,189 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:12:23,192 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:12:23,194 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:12:23,206 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:12:23,211 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:12:23,216 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:12:23,229 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:12:23,285 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:12:23,301 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:12:23,312 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:12:23,401 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:12:23,402 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:12:23,403 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:12:23,405 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:12:23,426 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:12:23,429 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:12:23,431 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:12:23,445 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:12:23,449 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:12:23,467 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:12:23,483 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:12:23,544 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:12:23,579 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:12:23,603 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:12:23,606 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:12:23,610 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:12:23,611 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:12:23,613 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:12:23,615 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:12:23,616 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:12:23,618 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:12:23,634 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:12:23,635 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:12:23,640 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:12:23,647 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:12:23,675 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:12:23,694 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:12:23,699 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:12:23,707 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:12:23,715 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:12:23,899 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:23,911 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:12:24,104 - INFO - 第 2 折评估完成: NPMI=0.4907, Diversity=0.4400, Optimal Score=0.4653\n",
      "实验进度:  62%|██████▏   | 37/60 [01:51<01:21,  3.53s/it]2024-11-24 21:12:24,108 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:24,290 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:12:24,291 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:12:24.291099', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:24,294 - INFO - discarding 6834 tokens: [('element', 9), ('grando', 6), ('terraemotus', 6), ('aaron', 8), ('asper', 9), ('latus', 7), ('leichnam', 2), ('noe', 10), ('perforo', 8), ('potestativus', 2)]...\n",
      "2024-11-24 21:12:24,294 - INFO - keeping 2000 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:24,296 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:12:24,296 - INFO - 词典过滤: 8834 -> 2000 个词\n",
      "2024-11-24 21:12:24,352 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:24,353 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:24,353 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:24,355 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:24,355 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:24,356 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:24,763 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:24,764 - INFO - topic #0 (0.067): 0.026*\"christus\" + 0.017*\"und\" + 0.012*\"virtus\" + 0.010*\"spiritus\" + 0.009*\"natura\" + 0.009*\"rex\" + 0.008*\"dies\" + 0.007*\"imago\" + 0.007*\"homo\" + 0.007*\"filius\"\n",
      "2024-11-24 21:12:24,765 - INFO - topic #8 (0.067): 0.022*\"delphi\" + 0.017*\"christus\" + 0.016*\"vita\" + 0.014*\"verbum\" + 0.009*\"spiritus\" + 0.009*\"amor\" + 0.009*\"sapientia\" + 0.009*\"fides\" + 0.008*\"pater\" + 0.008*\"ratio\"\n",
      "2024-11-24 21:12:24,765 - INFO - topic #14 (0.067): 0.021*\"vita\" + 0.020*\"homo\" + 0.017*\"sapientia\" + 0.014*\"spiritus\" + 0.011*\"venio\" + 0.009*\"christus\" + 0.009*\"mundus\" + 0.009*\"ratio\" + 0.008*\"amor\" + 0.007*\"scio\"\n",
      "2024-11-24 21:12:24,765 - INFO - topic #1 (0.067): 0.029*\"christus\" + 0.018*\"vita\" + 0.016*\"filius\" + 0.016*\"homo\" + 0.011*\"verbum\" + 0.011*\"mundus\" + 0.009*\"pater\" + 0.009*\"virtus\" + 0.009*\"regnum\" + 0.009*\"intellego\"\n",
      "2024-11-24 21:12:24,766 - INFO - topic #3 (0.067): 0.012*\"pulchritudo\" + 0.011*\"christus\" + 0.010*\"natura\" + 0.009*\"virtus\" + 0.008*\"finis\" + 0.007*\"delphi\" + 0.007*\"imago\" + 0.007*\"lux\" + 0.007*\"ratio\" + 0.007*\"pulcher\"\n",
      "2024-11-24 21:12:24,766 - INFO - topic diff=3.612133, rho=1.000000\n",
      "2024-11-24 21:12:25,164 - INFO - -7.224 per-word bound, 149.5 perplexity estimate based on a held-out corpus of 1716 documents with 86367 words\n",
      "2024-11-24 21:12:25,164 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:25,483 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:25,484 - INFO - topic #11 (0.067): 0.016*\"sermo\" + 0.015*\"homo\" + 0.014*\"mitto\" + 0.012*\"christus\" + 0.012*\"filius\" + 0.011*\"iudico\" + 0.011*\"dies\" + 0.011*\"misericordia\" + 0.011*\"loquor\" + 0.010*\"spiritus\"\n",
      "2024-11-24 21:12:25,485 - INFO - topic #3 (0.067): 0.020*\"ars\" + 0.016*\"pulchritudo\" + 0.014*\"imago\" + 0.010*\"natura\" + 0.009*\"annus\" + 0.008*\"perfectus\" + 0.008*\"intellectus\" + 0.007*\"virtus\" + 0.007*\"lux\" + 0.007*\"ratio\"\n",
      "2024-11-24 21:12:25,485 - INFO - topic #14 (0.067): 0.026*\"homo\" + 0.025*\"sapientia\" + 0.020*\"vita\" + 0.013*\"spiritus\" + 0.009*\"mundus\" + 0.009*\"iustitia\" + 0.009*\"amor\" + 0.008*\"annas\" + 0.008*\"trinitas\" + 0.008*\"gratia\"\n",
      "2024-11-24 21:12:25,486 - INFO - topic #7 (0.067): 0.026*\"spiritus\" + 0.020*\"pater\" + 0.020*\"filius\" + 0.020*\"christus\" + 0.020*\"verbum\" + 0.013*\"homo\" + 0.010*\"nomen\" + 0.010*\"lux\" + 0.009*\"vita\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:12:25,486 - INFO - topic #0 (0.067): 0.022*\"christus\" + 0.012*\"dies\" + 0.010*\"virtus\" + 0.008*\"rex\" + 0.007*\"und\" + 0.007*\"natura\" + 0.007*\"imago\" + 0.006*\"spiritus\" + 0.006*\"mundus\" + 0.006*\"dominus\"\n",
      "2024-11-24 21:12:25,486 - INFO - topic diff=1.002165, rho=0.707107\n",
      "2024-11-24 21:12:25,486 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.13s', 'datetime': '2024-11-24T21:12:25.486887', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:25,489 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:25,928 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:12:25,931 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:12:25,933 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:12:25,935 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:12:25,938 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:12:25,940 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:12:25,942 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:12:26,582 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:12:26,598 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:12:26,623 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:12:26,660 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:12:26,684 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:12:26,701 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:12:26,723 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:12:26,755 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:12:26,780 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:12:26,783 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:12:26,795 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:12:26,807 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:12:26,811 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:12:26,823 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:12:26,832 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:12:26,834 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:12:26,837 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:12:26,839 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:12:26,841 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:12:26,843 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:12:26,849 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:12:26,876 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:12:26,879 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:12:26,906 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:12:26,919 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:12:26,923 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:12:27,002 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:12:27,106 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:12:27,112 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:12:27,116 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:12:27,119 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:12:27,121 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:12:27,123 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:12:27,125 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:12:27,127 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:12:27,129 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:12:27,132 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:12:27,162 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:12:27,172 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:12:27,183 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:12:27,187 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:12:27,192 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:12:27,218 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:12:27,246 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:12:27,275 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:12:27,286 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:12:27,295 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:12:27,307 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:12:27,311 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:12:27,313 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:12:27,316 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:12:27,329 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:12:27,416 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:27,432 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:12:27,612 - INFO - 第 3 折评估完成: NPMI=0.4857, Diversity=0.4133, Optimal Score=0.4495\n",
      "实验进度:  63%|██████▎   | 38/60 [01:55<01:17,  3.53s/it]2024-11-24 21:12:27,615 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:27,699 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:12:27,699 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:12:27.699827', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:27,702 - INFO - discarding 6885 tokens: [('element', 6), ('grando', 3), ('terraemotus', 3), ('anatomia', 1), ('caesarius', 10), ('carnalitas', 7), ('deauro', 4), ('durities', 4), ('foramen', 2), ('innitor', 9)]...\n",
      "2024-11-24 21:12:27,703 - INFO - keeping 2000 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:27,704 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:12:27,705 - INFO - 词典过滤: 8885 -> 2000 个词\n",
      "2024-11-24 21:12:27,857 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:27,858 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:27,858 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:27,860 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:27,860 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:27,861 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:28,263 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:28,264 - INFO - topic #0 (0.067): 0.032*\"und\" + 0.016*\"wir\" + 0.016*\"ratio\" + 0.013*\"spiritus\" + 0.012*\"dies\" + 0.010*\"christus\" + 0.008*\"delphi\" + 0.008*\"homo\" + 0.008*\"vita\" + 0.007*\"intellectus\"\n",
      "2024-11-24 21:12:28,265 - INFO - topic #8 (0.067): 0.024*\"vita\" + 0.020*\"christus\" + 0.019*\"verbum\" + 0.018*\"homo\" + 0.016*\"mundus\" + 0.012*\"filius\" + 0.011*\"pater\" + 0.010*\"spiritus\" + 0.009*\"intellectus\" + 0.009*\"panis\"\n",
      "2024-11-24 21:12:28,265 - INFO - topic #14 (0.067): 0.018*\"christus\" + 0.015*\"spiritus\" + 0.014*\"delphi\" + 0.014*\"natura\" + 0.013*\"vita\" + 0.009*\"pater\" + 0.009*\"volo\" + 0.009*\"homo\" + 0.008*\"venio\" + 0.008*\"debeo\"\n",
      "2024-11-24 21:12:28,266 - INFO - topic #1 (0.067): 0.014*\"mundus\" + 0.014*\"homo\" + 0.014*\"ratio\" + 0.013*\"spiritus\" + 0.011*\"verbum\" + 0.009*\"virtus\" + 0.009*\"christus\" + 0.008*\"volo\" + 0.008*\"vita\" + 0.008*\"larissa\"\n",
      "2024-11-24 21:12:28,266 - INFO - topic #3 (0.067): 0.016*\"filius\" + 0.014*\"christus\" + 0.014*\"delphi\" + 0.013*\"pater\" + 0.011*\"mors\" + 0.011*\"evangelium\" + 0.010*\"spiritus\" + 0.010*\"vita\" + 0.010*\"pulchritudo\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:12:28,266 - INFO - topic diff=3.390296, rho=1.000000\n",
      "2024-11-24 21:12:28,668 - INFO - -7.235 per-word bound, 150.7 perplexity estimate based on a held-out corpus of 1716 documents with 86959 words\n",
      "2024-11-24 21:12:28,669 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:28,993 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:28,994 - INFO - topic #11 (0.067): 0.027*\"homo\" + 0.019*\"spiritus\" + 0.018*\"christus\" + 0.014*\"veritas\" + 0.014*\"virtus\" + 0.013*\"sapientia\" + 0.011*\"vita\" + 0.011*\"verbum\" + 0.011*\"mundus\" + 0.010*\"fides\"\n",
      "2024-11-24 21:12:28,995 - INFO - topic #3 (0.067): 0.019*\"filius\" + 0.019*\"lex\" + 0.017*\"pater\" + 0.013*\"delphi\" + 0.013*\"mors\" + 0.013*\"veritas\" + 0.013*\"christus\" + 0.012*\"evangelium\" + 0.011*\"pulchritudo\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:12:28,995 - INFO - topic #14 (0.067): 0.018*\"delphi\" + 0.018*\"christus\" + 0.017*\"natura\" + 0.012*\"spiritus\" + 0.011*\"vita\" + 0.010*\"homo\" + 0.010*\"corpus\" + 0.009*\"debeo\" + 0.008*\"volo\" + 0.008*\"creatura\"\n",
      "2024-11-24 21:12:28,996 - INFO - topic #7 (0.067): 0.028*\"filius\" + 0.018*\"christus\" + 0.015*\"homo\" + 0.014*\"natura\" + 0.014*\"verbum\" + 0.013*\"pater\" + 0.012*\"gratia\" + 0.011*\"larissa\" + 0.011*\"fides\" + 0.009*\"gloria\"\n",
      "2024-11-24 21:12:28,996 - INFO - topic #0 (0.067): 0.028*\"ratio\" + 0.021*\"und\" + 0.013*\"dies\" + 0.011*\"wir\" + 0.009*\"sensus\" + 0.009*\"spiritus\" + 0.009*\"intellectus\" + 0.008*\"nomen\" + 0.008*\"vir\" + 0.007*\"scio\"\n",
      "2024-11-24 21:12:28,996 - INFO - topic diff=0.959596, rho=0.707107\n",
      "2024-11-24 21:12:28,997 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.14s', 'datetime': '2024-11-24T21:12:28.997123', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:28,999 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:29,368 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:12:29,410 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:12:29,418 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:12:29,419 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:12:29,422 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:12:29,423 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:12:29,425 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:12:29,975 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:12:30,000 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:12:30,033 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:12:30,073 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:12:30,099 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:12:30,114 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:12:30,256 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:12:30,269 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:12:30,308 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:12:30,315 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:12:30,343 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:12:30,369 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:12:30,388 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:12:30,394 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:12:30,407 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:12:30,424 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:12:30,438 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:12:30,448 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:12:30,478 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:12:30,488 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:12:30,492 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:12:30,504 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:12:30,517 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:12:30,520 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:12:30,523 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:12:30,527 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:12:30,529 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:12:30,534 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:12:30,535 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:12:30,562 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:12:30,568 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:12:30,573 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:12:30,576 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:12:30,582 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:12:30,584 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:12:30,587 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:12:30,590 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:12:30,604 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:12:30,643 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:12:30,647 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:12:30,689 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:12:30,693 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:12:30,713 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:12:30,715 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:12:30,716 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:12:30,718 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:12:30,721 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:12:30,723 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:12:30,767 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:12:30,769 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:12:30,778 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:12:30,804 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:12:30,890 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:30,906 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:12:31,110 - INFO - 第 4 折评估完成: NPMI=0.4823, Diversity=0.4000, Optimal Score=0.4411\n",
      "实验进度:  65%|██████▌   | 39/60 [01:58<01:13,  3.52s/it]2024-11-24 21:12:31,113 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:31,199 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:12:31,200 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:12:31.200260', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:31,203 - INFO - discarding 6903 tokens: [('element', 9), ('grando', 7), ('terraemotus', 5), ('aaron', 5), ('asper', 10), ('latus', 7), ('leichnam', 3), ('perforo', 7), ('potestativus', 2), ('primitivus', 3)]...\n",
      "2024-11-24 21:12:31,203 - INFO - keeping 2000 tokens which were in no less than 3 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:31,205 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:12:31,205 - INFO - 词典过滤: 8903 -> 2000 个词\n",
      "2024-11-24 21:12:31,261 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:31,262 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:31,263 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:31,265 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:31,265 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:31,266 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:31,676 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:31,678 - INFO - topic #0 (0.067): 0.020*\"christus\" + 0.019*\"spiritus\" + 0.016*\"homo\" + 0.014*\"mors\" + 0.013*\"virtus\" + 0.013*\"vita\" + 0.010*\"volo\" + 0.010*\"filius\" + 0.009*\"delphi\" + 0.008*\"verbum\"\n",
      "2024-11-24 21:12:31,678 - INFO - topic #8 (0.067): 0.022*\"christus\" + 0.015*\"verbum\" + 0.013*\"natura\" + 0.013*\"lux\" + 0.011*\"gegen\" + 0.010*\"homo\" + 0.009*\"filius\" + 0.009*\"spiritus\" + 0.009*\"corpus\" + 0.008*\"fides\"\n",
      "2024-11-24 21:12:31,678 - INFO - topic #14 (0.067): 0.019*\"pater\" + 0.013*\"christus\" + 0.012*\"rex\" + 0.012*\"mundus\" + 0.012*\"homo\" + 0.012*\"filius\" + 0.010*\"gloria\" + 0.009*\"spiritus\" + 0.009*\"barabbas\" + 0.008*\"venio\"\n",
      "2024-11-24 21:12:31,679 - INFO - topic #1 (0.067): 0.027*\"christus\" + 0.022*\"spiritus\" + 0.011*\"verbum\" + 0.010*\"sanctus\" + 0.010*\"vita\" + 0.009*\"pater\" + 0.009*\"intellectus\" + 0.009*\"virtus\" + 0.009*\"homo\" + 0.009*\"mundus\"\n",
      "2024-11-24 21:12:31,679 - INFO - topic #3 (0.067): 0.023*\"regnum\" + 0.022*\"spiritus\" + 0.014*\"christus\" + 0.012*\"larissa\" + 0.010*\"vita\" + 0.009*\"mundus\" + 0.009*\"gratia\" + 0.008*\"delphi\" + 0.007*\"homo\" + 0.007*\"iustitia\"\n",
      "2024-11-24 21:12:31,679 - INFO - topic diff=3.291545, rho=1.000000\n",
      "2024-11-24 21:12:32,166 - INFO - -7.279 per-word bound, 155.3 perplexity estimate based on a held-out corpus of 1716 documents with 87835 words\n",
      "2024-11-24 21:12:32,166 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:32,488 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:32,490 - INFO - topic #11 (0.067): 0.019*\"spiritus\" + 0.017*\"sapientia\" + 0.014*\"magister\" + 0.012*\"homo\" + 0.012*\"christus\" + 0.011*\"delphi\" + 0.011*\"verbum\" + 0.010*\"mundus\" + 0.009*\"vita\" + 0.007*\"recipio\"\n",
      "2024-11-24 21:12:32,490 - INFO - topic #3 (0.067): 0.030*\"regnum\" + 0.019*\"spiritus\" + 0.017*\"larissa\" + 0.013*\"christus\" + 0.013*\"gratia\" + 0.009*\"vita\" + 0.009*\"dies\" + 0.008*\"peccatum\" + 0.008*\"mundus\" + 0.007*\"gaudium\"\n",
      "2024-11-24 21:12:32,491 - INFO - topic #14 (0.067): 0.018*\"pater\" + 0.014*\"gloria\" + 0.013*\"christus\" + 0.011*\"barabbas\" + 0.010*\"rex\" + 0.010*\"mundus\" + 0.010*\"homo\" + 0.010*\"larissa\" + 0.010*\"nomen\" + 0.009*\"filius\"\n",
      "2024-11-24 21:12:32,491 - INFO - topic #7 (0.067): 0.039*\"pater\" + 0.030*\"verbum\" + 0.027*\"christus\" + 0.023*\"filius\" + 0.017*\"spiritus\" + 0.015*\"homo\" + 0.010*\"loquor\" + 0.010*\"bonus\" + 0.009*\"mitto\" + 0.008*\"sanctus\"\n",
      "2024-11-24 21:12:32,491 - INFO - topic #0 (0.067): 0.019*\"mors\" + 0.019*\"spiritus\" + 0.018*\"christus\" + 0.018*\"homo\" + 0.012*\"vita\" + 0.010*\"delphi\" + 0.010*\"volo\" + 0.010*\"virtus\" + 0.009*\"amor\" + 0.007*\"filius\"\n",
      "2024-11-24 21:12:32,491 - INFO - topic diff=0.932602, rho=0.707107\n",
      "2024-11-24 21:12:32,492 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.23s', 'datetime': '2024-11-24T21:12:32.492356', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:32,495 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:32,870 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:12:32,873 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:12:32,875 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:12:32,878 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:12:32,880 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:12:32,886 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:12:32,958 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:12:33,536 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:12:33,557 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:12:33,606 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:12:33,645 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:12:33,657 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:12:33,675 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:12:33,728 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:12:33,733 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:12:33,738 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:12:33,758 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:12:33,787 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:12:33,789 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:12:33,791 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:12:33,793 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:12:33,796 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:12:33,809 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:12:33,821 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:12:33,843 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:12:33,845 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:12:33,847 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:12:33,851 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:12:33,859 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:12:33,874 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:12:33,890 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:12:33,916 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:12:33,940 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:12:33,962 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:12:33,980 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:12:34,005 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:12:34,006 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:12:34,007 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:12:34,008 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:12:34,009 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:12:34,038 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:12:34,040 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:12:34,053 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:12:34,069 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:12:34,071 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:12:34,079 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:12:34,087 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:12:34,092 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:12:34,097 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:12:34,101 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:12:34,103 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:12:34,108 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:12:34,125 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:12:34,132 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:12:34,142 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:12:34,160 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:12:34,178 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:12:34,185 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:12:34,195 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:12:34,296 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:34,316 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:12:34,588 - INFO - 第 5 折评估完成: NPMI=0.4909, Diversity=0.3733, Optimal Score=0.4321\n",
      "实验进度:  67%|██████▋   | 40/60 [02:02<01:10,  3.51s/it]2024-11-24 21:12:34,589 - INFO - \n",
      "评估阈值组合: min_freq=4, max_freq=200\n",
      "2024-11-24 21:12:34,591 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:34,676 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:12:34,677 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:12:34.677612', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:34,681 - INFO - discarding 8639 tokens: [('apocalypsis', 16), ('constantinus', 35), ('corona', 25), ('element', 9), ('expono', 81), ('generalis', 29), ('gloriosus', 75), ('grando', 6), ('ioannes', 83), ('luna', 60)]...\n",
      "2024-11-24 21:12:34,682 - INFO - keeping 200 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:34,683 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'larissa']...>\n",
      "2024-11-24 21:12:34,683 - INFO - 词典过滤: 8839 -> 200 个词\n",
      "2024-11-24 21:12:34,788 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:34,789 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:34,789 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:34,790 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:34,790 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:34,790 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:35,112 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:35,113 - INFO - topic #13 (0.067): 0.067*\"amor\" + 0.037*\"filius\" + 0.031*\"pater\" + 0.025*\"spiritus\" + 0.021*\"clotho\" + 0.021*\"imago\" + 0.020*\"morior\" + 0.020*\"mors\" + 0.018*\"unio\" + 0.017*\"natura\"\n",
      "2024-11-24 21:12:35,113 - INFO - topic #8 (0.067): 0.047*\"virtus\" + 0.033*\"christus\" + 0.028*\"homo\" + 0.025*\"spiritus\" + 0.022*\"delphi\" + 0.022*\"vita\" + 0.020*\"dominus\" + 0.020*\"mens\" + 0.015*\"filius\" + 0.015*\"fides\"\n",
      "2024-11-24 21:12:35,113 - INFO - topic #14 (0.067): 0.098*\"christus\" + 0.055*\"spiritus\" + 0.029*\"vita\" + 0.020*\"homo\" + 0.017*\"fides\" + 0.017*\"filius\" + 0.015*\"mundus\" + 0.014*\"corpus\" + 0.014*\"lex\" + 0.013*\"pater\"\n",
      "2024-11-24 21:12:35,114 - INFO - topic #7 (0.067): 0.058*\"spiritus\" + 0.037*\"delphi\" + 0.025*\"gloria\" + 0.025*\"christus\" + 0.024*\"vita\" + 0.023*\"pater\" + 0.020*\"verbum\" + 0.020*\"motus\" + 0.019*\"filius\" + 0.018*\"divinus\"\n",
      "2024-11-24 21:12:35,114 - INFO - topic #9 (0.067): 0.062*\"dies\" + 0.058*\"christus\" + 0.024*\"mundus\" + 0.022*\"vita\" + 0.017*\"peccatum\" + 0.015*\"regnum\" + 0.015*\"delphi\" + 0.014*\"osdroena\" + 0.014*\"annas\" + 0.014*\"spiritus\"\n",
      "2024-11-24 21:12:35,114 - INFO - topic diff=0.791286, rho=1.000000\n",
      "2024-11-24 21:12:35,421 - INFO - -5.186 per-word bound, 36.4 perplexity estimate based on a held-out corpus of 1716 documents with 45975 words\n",
      "2024-11-24 21:12:35,422 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:35,676 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:35,677 - INFO - topic #12 (0.067): 0.085*\"spiritus\" + 0.044*\"verbum\" + 0.039*\"vita\" + 0.029*\"sanctus\" + 0.024*\"christus\" + 0.022*\"debeo\" + 0.021*\"homo\" + 0.021*\"via\" + 0.020*\"regnum\" + 0.017*\"veritas\"\n",
      "2024-11-24 21:12:35,677 - INFO - topic #6 (0.067): 0.085*\"pater\" + 0.062*\"filius\" + 0.039*\"mundus\" + 0.036*\"venio\" + 0.034*\"lux\" + 0.023*\"sanctus\" + 0.023*\"larissa\" + 0.022*\"christus\" + 0.020*\"rex\" + 0.015*\"cognosco\"\n",
      "2024-11-24 21:12:35,678 - INFO - topic #13 (0.067): 0.082*\"amor\" + 0.039*\"imago\" + 0.039*\"clotho\" + 0.035*\"pater\" + 0.034*\"filius\" + 0.028*\"spiritus\" + 0.024*\"symbatios\" + 0.023*\"unio\" + 0.022*\"morior\" + 0.020*\"sanctus\"\n",
      "2024-11-24 21:12:35,678 - INFO - topic #11 (0.067): 0.056*\"vita\" + 0.038*\"iustitia\" + 0.035*\"homo\" + 0.027*\"natura\" + 0.024*\"vivo\" + 0.022*\"finis\" + 0.017*\"gratia\" + 0.017*\"christus\" + 0.017*\"debeo\" + 0.016*\"filius\"\n",
      "2024-11-24 21:12:35,678 - INFO - topic #0 (0.067): 0.068*\"homo\" + 0.060*\"verbum\" + 0.040*\"nomen\" + 0.033*\"vita\" + 0.026*\"gegen\" + 0.026*\"christus\" + 0.024*\"filius\" + 0.020*\"pater\" + 0.016*\"lux\" + 0.014*\"spiritus\"\n",
      "2024-11-24 21:12:35,679 - INFO - topic diff=0.354127, rho=0.707107\n",
      "2024-11-24 21:12:35,679 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.89s', 'datetime': '2024-11-24T21:12:35.679302', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:35,681 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:35,728 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:12:35,816 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:12:35,841 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:12:35,843 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:12:35,876 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:12:35,913 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:12:35,915 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:12:36,726 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:12:36,754 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:12:36,817 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:12:36,845 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:12:36,884 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:12:36,890 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:12:36,892 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:12:36,894 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:12:36,897 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:12:36,906 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:12:36,915 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:12:36,921 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:12:36,942 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:12:36,958 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:12:36,968 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:12:36,970 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:12:36,979 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:12:36,981 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:12:36,983 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:12:36,998 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:12:37,002 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:12:37,006 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:12:37,008 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:12:37,010 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:12:37,011 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:12:37,014 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:12:37,016 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:12:37,017 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:12:37,019 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:12:37,021 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:12:37,022 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:12:37,024 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:12:37,031 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:12:37,033 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:12:37,043 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:12:37,048 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:12:37,060 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:12:37,062 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:12:37,063 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:12:37,069 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:12:37,194 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:12:37,201 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:12:37,231 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:12:37,238 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:12:37,243 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:12:37,244 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:12:37,246 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:12:37,251 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:12:37,262 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:12:37,265 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:12:37,273 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:12:37,294 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:12:37,426 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:37,444 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:12:37,635 - INFO - 第 1 折评估完成: NPMI=0.4980, Diversity=0.4400, Optimal Score=0.4690\n",
      "实验进度:  68%|██████▊   | 41/60 [02:05<01:03,  3.37s/it]2024-11-24 21:12:37,637 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:37,721 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:12:37,722 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:12:37.722040', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:37,725 - INFO - discarding 8696 tokens: [('aaron', 7), ('asper', 8), ('conservo', 66), ('constantinus', 39), ('contritio', 22), ('conversatio', 28), ('correctio', 22), ('crux', 115), ('divinitas', 67), ('dormio', 34)]...\n",
      "2024-11-24 21:12:37,725 - INFO - keeping 200 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:37,726 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'divinus']...>\n",
      "2024-11-24 21:12:37,727 - INFO - 词典过滤: 8896 -> 200 个词\n",
      "2024-11-24 21:12:37,850 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:37,850 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:37,851 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:37,851 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:37,852 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:37,852 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:38,192 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:38,192 - INFO - topic #13 (0.067): 0.042*\"homo\" + 0.042*\"vita\" + 0.041*\"spiritus\" + 0.033*\"filius\" + 0.022*\"natura\" + 0.022*\"amor\" + 0.021*\"regnum\" + 0.017*\"delphi\" + 0.017*\"pater\" + 0.017*\"unitas\"\n",
      "2024-11-24 21:12:38,193 - INFO - topic #8 (0.067): 0.062*\"christus\" + 0.045*\"verbum\" + 0.036*\"delphi\" + 0.022*\"intellego\" + 0.021*\"vita\" + 0.020*\"virtus\" + 0.019*\"homo\" + 0.019*\"corpus\" + 0.018*\"ratio\" + 0.017*\"bonus\"\n",
      "2024-11-24 21:12:38,193 - INFO - topic #14 (0.067): 0.056*\"verbum\" + 0.034*\"christus\" + 0.034*\"pax\" + 0.027*\"spiritus\" + 0.020*\"vita\" + 0.018*\"homo\" + 0.017*\"motus\" + 0.017*\"recipio\" + 0.015*\"sanctus\" + 0.013*\"semen\"\n",
      "2024-11-24 21:12:38,194 - INFO - topic #7 (0.067): 0.042*\"christus\" + 0.027*\"venio\" + 0.022*\"homo\" + 0.021*\"debeo\" + 0.021*\"sapientia\" + 0.020*\"filius\" + 0.019*\"pater\" + 0.019*\"tempus\" + 0.019*\"spiritus\" + 0.018*\"mundus\"\n",
      "2024-11-24 21:12:38,194 - INFO - topic #9 (0.067): 0.040*\"vita\" + 0.033*\"christus\" + 0.030*\"homo\" + 0.028*\"spiritus\" + 0.025*\"delphi\" + 0.022*\"lux\" + 0.019*\"virtus\" + 0.018*\"scio\" + 0.016*\"fides\" + 0.015*\"filius\"\n",
      "2024-11-24 21:12:38,194 - INFO - topic diff=0.766767, rho=1.000000\n",
      "2024-11-24 21:12:38,505 - INFO - -5.191 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 1716 documents with 46207 words\n",
      "2024-11-24 21:12:38,505 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:38,763 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:38,764 - INFO - topic #12 (0.067): 0.081*\"homo\" + 0.057*\"mundus\" + 0.047*\"dies\" + 0.042*\"veritas\" + 0.028*\"quaero\" + 0.025*\"vita\" + 0.021*\"credo\" + 0.018*\"christus\" + 0.017*\"scio\" + 0.013*\"bonus\"\n",
      "2024-11-24 21:12:38,764 - INFO - topic #6 (0.067): 0.048*\"gratia\" + 0.044*\"delphi\" + 0.028*\"homo\" + 0.027*\"natura\" + 0.027*\"dies\" + 0.026*\"dominus\" + 0.024*\"fides\" + 0.023*\"christus\" + 0.019*\"virgo\" + 0.018*\"vita\"\n",
      "2024-11-24 21:12:38,764 - INFO - topic #13 (0.067): 0.051*\"vita\" + 0.045*\"spiritus\" + 0.042*\"homo\" + 0.037*\"amor\" + 0.028*\"natura\" + 0.028*\"filius\" + 0.026*\"regnum\" + 0.020*\"unitas\" + 0.019*\"panis\" + 0.017*\"delphi\"\n",
      "2024-11-24 21:12:38,765 - INFO - topic #11 (0.067): 0.137*\"spiritus\" + 0.037*\"sanctus\" + 0.028*\"motus\" + 0.027*\"mundus\" + 0.023*\"veritas\" + 0.022*\"domus\" + 0.019*\"dominus\" + 0.018*\"virtus\" + 0.018*\"christus\" + 0.017*\"osdroena\"\n",
      "2024-11-24 21:12:38,765 - INFO - topic #0 (0.067): 0.046*\"gegen\" + 0.044*\"intellectus\" + 0.035*\"lux\" + 0.031*\"ratio\" + 0.027*\"delphi\" + 0.026*\"mundus\" + 0.020*\"veritas\" + 0.019*\"sol\" + 0.019*\"virtus\" + 0.019*\"spiritus\"\n",
      "2024-11-24 21:12:38,765 - INFO - topic diff=0.350584, rho=0.707107\n",
      "2024-11-24 21:12:38,766 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.91s', 'datetime': '2024-11-24T21:12:38.766068', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:38,768 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:38,811 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:12:38,831 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:12:38,904 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:12:38,930 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:12:38,976 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:12:39,014 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:12:39,016 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:12:39,820 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:12:39,833 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:12:39,836 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:12:39,838 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:12:39,849 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:12:39,851 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:12:39,877 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:12:39,905 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:12:39,944 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:12:40,026 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:12:40,058 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:12:40,059 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:12:40,080 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:12:40,083 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:12:40,085 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:12:40,086 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:12:40,103 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:12:40,105 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:12:40,107 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:12:40,108 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:12:40,111 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:12:40,115 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:12:40,117 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:12:40,127 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:12:40,140 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:12:40,151 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:12:40,156 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:12:40,158 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:12:40,164 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:12:40,166 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:12:40,168 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:12:40,182 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:12:40,184 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:12:40,186 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:12:40,210 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:12:40,224 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:12:40,237 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:12:40,239 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:12:40,245 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:12:40,247 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:12:40,250 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:12:40,253 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:12:40,255 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:12:40,268 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:12:40,289 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:12:40,414 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:12:40,415 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:12:40,416 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:12:40,418 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:12:40,419 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:12:40,420 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:12:40,423 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:12:40,566 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:40,590 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:12:40,764 - INFO - 第 2 折评估完成: NPMI=0.4980, Diversity=0.4467, Optimal Score=0.4724\n",
      "实验进度:  70%|███████   | 42/60 [02:08<00:59,  3.30s/it]2024-11-24 21:12:40,766 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:40,851 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:12:40,851 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:12:40.851868', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:40,855 - INFO - discarding 8634 tokens: [('apocalypsis', 13), ('behalten', 129), ('constantinus', 33), ('corona', 28), ('element', 9), ('expono', 80), ('generalis', 26), ('gloriosus', 72), ('grando', 6), ('ioannes', 89)]...\n",
      "2024-11-24 21:12:40,855 - INFO - keeping 200 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:40,857 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:12:40,857 - INFO - 词典过滤: 8834 -> 200 个词\n",
      "2024-11-24 21:12:40,897 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:40,897 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:40,898 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:40,898 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:40,899 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:40,899 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:41,337 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:41,338 - INFO - topic #13 (0.067): 0.040*\"amor\" + 0.038*\"delphi\" + 0.024*\"clotho\" + 0.023*\"filius\" + 0.022*\"pater\" + 0.021*\"vita\" + 0.018*\"verbum\" + 0.017*\"peccatum\" + 0.016*\"spiritus\" + 0.016*\"corpus\"\n",
      "2024-11-24 21:12:41,338 - INFO - topic #8 (0.067): 0.046*\"christus\" + 0.037*\"virtus\" + 0.031*\"debeo\" + 0.029*\"spiritus\" + 0.026*\"homo\" + 0.018*\"delphi\" + 0.016*\"sapientia\" + 0.016*\"vita\" + 0.015*\"pater\" + 0.015*\"verbum\"\n",
      "2024-11-24 21:12:41,338 - INFO - topic #14 (0.067): 0.072*\"christus\" + 0.064*\"spiritus\" + 0.033*\"vita\" + 0.030*\"fides\" + 0.019*\"mundus\" + 0.018*\"homo\" + 0.018*\"debeo\" + 0.014*\"volo\" + 0.014*\"verbum\" + 0.014*\"intellectus\"\n",
      "2024-11-24 21:12:41,339 - INFO - topic #7 (0.067): 0.054*\"spiritus\" + 0.026*\"regnum\" + 0.025*\"christus\" + 0.023*\"verbum\" + 0.023*\"mundus\" + 0.021*\"gloria\" + 0.020*\"filius\" + 0.020*\"vita\" + 0.020*\"motus\" + 0.017*\"sanctus\"\n",
      "2024-11-24 21:12:41,339 - INFO - topic #9 (0.067): 0.113*\"dies\" + 0.025*\"vita\" + 0.022*\"gratia\" + 0.019*\"iustitia\" + 0.018*\"semen\" + 0.017*\"sapientia\" + 0.017*\"annas\" + 0.017*\"mors\" + 0.016*\"reperio\" + 0.016*\"christus\"\n",
      "2024-11-24 21:12:41,340 - INFO - topic diff=0.781915, rho=1.000000\n",
      "2024-11-24 21:12:41,648 - INFO - -5.190 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 1716 documents with 45705 words\n",
      "2024-11-24 21:12:41,649 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:41,904 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:41,904 - INFO - topic #12 (0.067): 0.073*\"spiritus\" + 0.070*\"vita\" + 0.030*\"homo\" + 0.025*\"natura\" + 0.024*\"christus\" + 0.022*\"unio\" + 0.021*\"verbum\" + 0.020*\"delphi\" + 0.018*\"rationalis\" + 0.017*\"corpus\"\n",
      "2024-11-24 21:12:41,904 - INFO - topic #6 (0.067): 0.085*\"lux\" + 0.046*\"fides\" + 0.036*\"tenebrae\" + 0.030*\"intellectus\" + 0.030*\"veritas\" + 0.025*\"verus\" + 0.023*\"gegen\" + 0.023*\"ratio\" + 0.020*\"sol\" + 0.019*\"credo\"\n",
      "2024-11-24 21:12:41,905 - INFO - topic #13 (0.067): 0.056*\"amor\" + 0.045*\"delphi\" + 0.035*\"clotho\" + 0.029*\"peccatum\" + 0.023*\"symbatios\" + 0.022*\"filius\" + 0.021*\"pater\" + 0.020*\"diligo\" + 0.019*\"spiritus\" + 0.019*\"corpus\"\n",
      "2024-11-24 21:12:41,905 - INFO - topic #11 (0.067): 0.047*\"christus\" + 0.026*\"natura\" + 0.026*\"vita\" + 0.025*\"domus\" + 0.019*\"delphi\" + 0.018*\"homo\" + 0.018*\"sapientia\" + 0.017*\"via\" + 0.017*\"verbum\" + 0.017*\"tempus\"\n",
      "2024-11-24 21:12:41,905 - INFO - topic #0 (0.067): 0.098*\"homo\" + 0.040*\"ars\" + 0.028*\"forma\" + 0.023*\"christus\" + 0.023*\"vita\" + 0.019*\"perfectus\" + 0.018*\"natura\" + 0.018*\"iustitia\" + 0.018*\"mundus\" + 0.016*\"pater\"\n",
      "2024-11-24 21:12:41,906 - INFO - topic diff=0.359364, rho=0.707107\n",
      "2024-11-24 21:12:41,906 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 1.01s', 'datetime': '2024-11-24T21:12:41.906412', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:41,908 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:41,952 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:12:41,964 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:12:42,033 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:12:42,060 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:12:42,061 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:12:42,063 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:12:42,064 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:12:42,888 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:12:42,898 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:12:42,908 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:12:42,916 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:12:42,938 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:12:42,941 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:12:42,957 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:12:42,971 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:12:42,975 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:12:42,996 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:12:43,006 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:12:43,016 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:12:43,021 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:12:43,029 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:12:43,090 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:12:43,147 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:12:43,179 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:12:43,182 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:12:43,185 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:12:43,187 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:12:43,220 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:12:43,226 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:12:43,237 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:12:43,245 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:12:43,252 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:12:43,255 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:12:43,256 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:12:43,261 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:12:43,266 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:12:43,268 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:12:43,270 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:12:43,272 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:12:43,274 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:12:43,276 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:12:43,278 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:12:43,280 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:12:43,282 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:12:43,287 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:12:43,291 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:12:43,297 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:12:43,299 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:12:43,301 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:12:43,305 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:12:43,330 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:12:43,343 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:12:43,345 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:12:43,348 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:12:43,354 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:12:43,356 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:12:43,358 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:12:43,368 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:12:43,383 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:12:43,619 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:43,639 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:12:43,829 - INFO - 第 3 折评估完成: NPMI=0.4985, Diversity=0.4733, Optimal Score=0.4859\n",
      "实验进度:  72%|███████▏  | 43/60 [02:11<00:54,  3.23s/it]2024-11-24 21:12:43,831 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:43,923 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:12:43,924 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:12:43.924209', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:43,927 - INFO - discarding 8685 tokens: [('apocalypsis', 14), ('behalten', 118), ('constantinus', 30), ('corona', 26), ('element', 6), ('expono', 79), ('generalis', 25), ('gloriosus', 80), ('grando', 3), ('ioannes', 87)]...\n",
      "2024-11-24 21:12:43,927 - INFO - keeping 200 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:43,929 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:12:43,929 - INFO - 词典过滤: 8885 -> 200 个词\n",
      "2024-11-24 21:12:43,968 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:43,968 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:43,969 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:43,969 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:43,969 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:43,970 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:44,309 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:44,310 - INFO - topic #13 (0.067): 0.034*\"pater\" + 0.030*\"verbum\" + 0.026*\"spiritus\" + 0.024*\"regnum\" + 0.022*\"ars\" + 0.019*\"annas\" + 0.018*\"unitas\" + 0.018*\"natura\" + 0.017*\"finis\" + 0.017*\"sanctus\"\n",
      "2024-11-24 21:12:44,310 - INFO - topic #8 (0.067): 0.051*\"christus\" + 0.048*\"corpus\" + 0.038*\"homo\" + 0.032*\"delphi\" + 0.023*\"ecclesia\" + 0.023*\"spiritus\" + 0.017*\"sapientia\" + 0.016*\"peccatum\" + 0.014*\"vita\" + 0.013*\"locus\"\n",
      "2024-11-24 21:12:44,310 - INFO - topic #14 (0.067): 0.076*\"spiritus\" + 0.039*\"christus\" + 0.035*\"vita\" + 0.025*\"delphi\" + 0.021*\"mundus\" + 0.020*\"homo\" + 0.020*\"osdroena\" + 0.019*\"mors\" + 0.018*\"filius\" + 0.017*\"fides\"\n",
      "2024-11-24 21:12:44,311 - INFO - topic #7 (0.067): 0.057*\"vita\" + 0.047*\"christus\" + 0.032*\"spiritus\" + 0.027*\"verbum\" + 0.022*\"filius\" + 0.020*\"iustitia\" + 0.019*\"fides\" + 0.018*\"mors\" + 0.016*\"pax\" + 0.015*\"veritas\"\n",
      "2024-11-24 21:12:44,311 - INFO - topic #9 (0.067): 0.055*\"dies\" + 0.043*\"pater\" + 0.040*\"filius\" + 0.031*\"christus\" + 0.027*\"spiritus\" + 0.023*\"sapientia\" + 0.023*\"homo\" + 0.022*\"vita\" + 0.021*\"unio\" + 0.015*\"opus\"\n",
      "2024-11-24 21:12:44,311 - INFO - topic diff=0.759201, rho=1.000000\n",
      "2024-11-24 21:12:44,704 - INFO - -5.177 per-word bound, 36.2 perplexity estimate based on a held-out corpus of 1716 documents with 46027 words\n",
      "2024-11-24 21:12:44,705 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:44,976 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:44,977 - INFO - topic #12 (0.067): 0.053*\"gegen\" + 0.040*\"lux\" + 0.036*\"veritas\" + 0.035*\"intellectus\" + 0.026*\"ratio\" + 0.025*\"christus\" + 0.022*\"natura\" + 0.019*\"verbum\" + 0.018*\"sensibilis\" + 0.018*\"motus\"\n",
      "2024-11-24 21:12:44,977 - INFO - topic #6 (0.067): 0.061*\"virtus\" + 0.033*\"spiritus\" + 0.027*\"larissa\" + 0.026*\"homo\" + 0.024*\"principium\" + 0.023*\"natura\" + 0.022*\"terra\" + 0.022*\"finis\" + 0.021*\"veritas\" + 0.020*\"creo\"\n",
      "2024-11-24 21:12:44,977 - INFO - topic #13 (0.067): 0.053*\"ars\" + 0.052*\"pater\" + 0.038*\"verbum\" + 0.033*\"nomen\" + 0.030*\"annas\" + 0.028*\"regnum\" + 0.026*\"sanctus\" + 0.022*\"natura\" + 0.021*\"spiritus\" + 0.021*\"unitas\"\n",
      "2024-11-24 21:12:44,978 - INFO - topic #11 (0.067): 0.057*\"vita\" + 0.040*\"delphi\" + 0.031*\"spiritus\" + 0.030*\"amor\" + 0.028*\"sanctus\" + 0.024*\"gratia\" + 0.024*\"symbatios\" + 0.019*\"cognosco\" + 0.019*\"clotho\" + 0.019*\"christus\"\n",
      "2024-11-24 21:12:44,978 - INFO - topic #0 (0.067): 0.077*\"christus\" + 0.071*\"panis\" + 0.032*\"forma\" + 0.029*\"nomen\" + 0.028*\"gaudium\" + 0.024*\"verbum\" + 0.024*\"natura\" + 0.023*\"bonus\" + 0.022*\"pater\" + 0.022*\"reperio\"\n",
      "2024-11-24 21:12:44,978 - INFO - topic diff=0.362373, rho=0.707107\n",
      "2024-11-24 21:12:44,978 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 1.01s', 'datetime': '2024-11-24T21:12:44.978941', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:44,981 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:45,094 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:12:45,103 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:12:45,253 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:12:45,257 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:12:45,259 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:12:45,260 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:12:45,261 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:12:46,006 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:12:46,027 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:12:46,033 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:12:46,056 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:12:46,069 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:12:46,088 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:12:46,118 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:12:46,132 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:12:46,144 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:12:46,147 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:12:46,149 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:12:46,153 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:12:46,170 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:12:46,172 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:12:46,174 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:12:46,177 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:12:46,181 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:12:46,185 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:12:46,193 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:12:46,202 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:12:46,209 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:12:46,213 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:12:46,214 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:12:46,227 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:12:46,229 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:12:46,239 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:12:46,252 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:12:46,276 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:12:46,396 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:12:46,413 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:12:46,415 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:12:46,417 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:12:46,419 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:12:46,439 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:12:46,465 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:12:46,468 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:12:46,476 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:12:46,477 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:12:46,479 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:12:46,483 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:12:46,495 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:12:46,498 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:12:46,502 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:12:46,513 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:12:46,514 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:12:46,537 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:12:46,549 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:12:46,567 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:12:46,589 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:12:46,614 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:12:46,618 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:12:46,619 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:12:46,700 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:46,717 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:12:47,022 - INFO - 第 4 折评估完成: NPMI=0.4990, Diversity=0.4600, Optimal Score=0.4795\n",
      "实验进度:  73%|███████▎  | 44/60 [02:14<00:51,  3.22s/it]2024-11-24 21:12:47,025 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:47,111 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:12:47,111 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:12:47.111880', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:47,116 - INFO - discarding 8703 tokens: [('apocalypsis', 15), ('behalten', 127), ('constantinus', 35), ('corona', 26), ('element', 9), ('expono', 80), ('generalis', 24), ('gloriosus', 77), ('grando', 7), ('ioannes', 98)]...\n",
      "2024-11-24 21:12:47,116 - INFO - keeping 200 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:47,117 - INFO - resulting dictionary: Dictionary<200 unique tokens: ['appareo', 'dominus', 'ecclesia', 'larissa', 'magnus']...>\n",
      "2024-11-24 21:12:47,118 - INFO - 词典过滤: 8903 -> 200 个词\n",
      "2024-11-24 21:12:47,158 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:47,158 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:47,159 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:47,159 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:47,160 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:47,160 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:47,494 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:47,495 - INFO - topic #13 (0.067): 0.036*\"lux\" + 0.034*\"vita\" + 0.030*\"christus\" + 0.020*\"gegen\" + 0.020*\"verbum\" + 0.019*\"homo\" + 0.018*\"veritas\" + 0.017*\"vivo\" + 0.017*\"evangelium\" + 0.017*\"spiritus\"\n",
      "2024-11-24 21:12:47,495 - INFO - topic #8 (0.067): 0.048*\"christus\" + 0.032*\"debeo\" + 0.027*\"veritas\" + 0.023*\"nomen\" + 0.022*\"filius\" + 0.020*\"homo\" + 0.019*\"virtus\" + 0.018*\"lex\" + 0.018*\"delphi\" + 0.017*\"gratia\"\n",
      "2024-11-24 21:12:47,495 - INFO - topic #14 (0.067): 0.089*\"christus\" + 0.055*\"spiritus\" + 0.031*\"fides\" + 0.027*\"homo\" + 0.019*\"filius\" + 0.019*\"verbum\" + 0.018*\"vita\" + 0.015*\"virtus\" + 0.012*\"debeo\" + 0.012*\"volo\"\n",
      "2024-11-24 21:12:47,496 - INFO - topic #7 (0.067): 0.043*\"virtus\" + 0.037*\"verbum\" + 0.035*\"christus\" + 0.030*\"spiritus\" + 0.029*\"regnum\" + 0.021*\"delphi\" + 0.018*\"unio\" + 0.017*\"natura\" + 0.016*\"filius\" + 0.016*\"lex\"\n",
      "2024-11-24 21:12:47,496 - INFO - topic #9 (0.067): 0.037*\"pater\" + 0.026*\"sapientia\" + 0.024*\"intellectus\" + 0.024*\"rex\" + 0.023*\"christus\" + 0.020*\"debeo\" + 0.019*\"virtus\" + 0.019*\"homo\" + 0.018*\"delphi\" + 0.017*\"venio\"\n",
      "2024-11-24 21:12:47,496 - INFO - topic diff=0.738142, rho=1.000000\n",
      "2024-11-24 21:12:47,817 - INFO - -5.203 per-word bound, 36.8 perplexity estimate based on a held-out corpus of 1716 documents with 45842 words\n",
      "2024-11-24 21:12:47,817 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:48,130 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:48,131 - INFO - topic #12 (0.067): 0.080*\"filius\" + 0.077*\"pater\" + 0.036*\"homo\" + 0.032*\"christus\" + 0.031*\"natura\" + 0.026*\"mundus\" + 0.023*\"spiritus\" + 0.020*\"verbum\" + 0.019*\"venio\" + 0.017*\"veritas\"\n",
      "2024-11-24 21:12:48,132 - INFO - topic #6 (0.067): 0.064*\"dies\" + 0.047*\"spiritus\" + 0.032*\"ratio\" + 0.031*\"delphi\" + 0.028*\"dominus\" + 0.023*\"fides\" + 0.019*\"debeo\" + 0.018*\"osdroena\" + 0.018*\"sanctus\" + 0.016*\"homo\"\n",
      "2024-11-24 21:12:48,132 - INFO - topic #13 (0.067): 0.040*\"lux\" + 0.030*\"christus\" + 0.028*\"quaero\" + 0.028*\"vita\" + 0.025*\"evangelium\" + 0.025*\"gegen\" + 0.022*\"doctrina\" + 0.021*\"pars\" + 0.020*\"veritas\" + 0.017*\"primo\"\n",
      "2024-11-24 21:12:48,132 - INFO - topic #11 (0.067): 0.058*\"amor\" + 0.045*\"symbatios\" + 0.040*\"clotho\" + 0.037*\"filius\" + 0.033*\"spiritus\" + 0.031*\"christus\" + 0.030*\"pater\" + 0.023*\"diligo\" + 0.020*\"delphi\" + 0.019*\"mater\"\n",
      "2024-11-24 21:12:48,133 - INFO - topic #0 (0.067): 0.036*\"christus\" + 0.028*\"homo\" + 0.026*\"finis\" + 0.026*\"tenebrae\" + 0.023*\"volo\" + 0.022*\"mundus\" + 0.022*\"recipio\" + 0.021*\"spiritus\" + 0.017*\"vita\" + 0.017*\"debeo\"\n",
      "2024-11-24 21:12:48,133 - INFO - topic diff=0.333727, rho=0.707107\n",
      "2024-11-24 21:12:48,133 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=200, num_topics=15, decay=0.5, chunksize=2000> in 0.97s', 'datetime': '2024-11-24T21:12:48.133671', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:48,136 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:48,354 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:12:48,359 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:12:48,361 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:12:48,363 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:12:48,365 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:12:48,368 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:12:48,369 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:12:49,230 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:12:49,253 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:12:49,301 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:12:49,334 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:12:49,339 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:12:49,345 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:12:49,347 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:12:49,356 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:12:49,389 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:12:49,398 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:12:49,400 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:12:49,402 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:12:49,405 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:12:49,407 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:12:49,409 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:12:49,411 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:12:49,423 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:12:49,439 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:12:49,441 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:12:49,454 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:12:49,458 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:12:49,460 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:12:49,461 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:12:49,466 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:12:49,484 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:12:49,486 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:12:49,488 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:12:49,492 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:12:49,498 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:12:49,500 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:12:49,505 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:12:49,523 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:12:49,534 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:12:49,685 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:12:49,686 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:12:49,687 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:12:49,689 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:12:49,690 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:12:49,691 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:12:49,726 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:12:49,728 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:12:49,736 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:12:49,746 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:12:49,749 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:12:49,752 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:12:49,758 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:12:49,771 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:12:49,774 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:12:49,787 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:12:49,789 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:12:49,795 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:12:49,798 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:12:49,975 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:49,993 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:12:50,256 - INFO - 第 5 折评估完成: NPMI=0.4970, Diversity=0.4533, Optimal Score=0.4752\n",
      "实验进度:  75%|███████▌  | 45/60 [02:17<00:48,  3.22s/it]2024-11-24 21:12:50,257 - INFO - \n",
      "评估阈值组合: min_freq=4, max_freq=800\n",
      "2024-11-24 21:12:50,261 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:50,359 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:12:50,360 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:12:50.360126', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:50,363 - INFO - discarding 8039 tokens: [('apocalypsis', 16), ('constantinus', 35), ('corona', 25), ('element', 9), ('generalis', 29), ('grando', 6), ('principalis', 18), ('specialis', 14), ('terraemotus', 5), ('aaron', 7)]...\n",
      "2024-11-24 21:12:50,364 - INFO - keeping 800 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:50,365 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:12:50,365 - INFO - 词典过滤: 8839 -> 800 个词\n",
      "2024-11-24 21:12:50,418 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:50,419 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:50,420 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:50,422 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:50,423 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:50,424 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:50,836 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:50,837 - INFO - topic #6 (0.067): 0.022*\"spiritus\" + 0.021*\"virtus\" + 0.017*\"christus\" + 0.017*\"delphi\" + 0.016*\"vita\" + 0.016*\"homo\" + 0.015*\"corpus\" + 0.014*\"verbum\" + 0.012*\"natura\" + 0.011*\"ratio\"\n",
      "2024-11-24 21:12:50,837 - INFO - topic #13 (0.067): 0.047*\"christus\" + 0.022*\"homo\" + 0.021*\"pater\" + 0.020*\"filius\" + 0.019*\"vita\" + 0.015*\"verbum\" + 0.013*\"virtus\" + 0.012*\"panis\" + 0.011*\"spiritus\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:12:50,837 - INFO - topic #12 (0.067): 0.030*\"spiritus\" + 0.024*\"fides\" + 0.023*\"vita\" + 0.018*\"sanctus\" + 0.017*\"verbum\" + 0.015*\"filius\" + 0.012*\"christus\" + 0.011*\"pater\" + 0.010*\"homo\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:12:50,838 - INFO - topic #10 (0.067): 0.025*\"christus\" + 0.022*\"delphi\" + 0.021*\"fides\" + 0.019*\"spiritus\" + 0.017*\"mundus\" + 0.013*\"verbum\" + 0.011*\"lux\" + 0.010*\"natura\" + 0.009*\"vita\" + 0.009*\"filius\"\n",
      "2024-11-24 21:12:50,838 - INFO - topic #2 (0.067): 0.024*\"spiritus\" + 0.023*\"homo\" + 0.021*\"vita\" + 0.017*\"christus\" + 0.011*\"ratio\" + 0.011*\"sapientia\" + 0.010*\"dominus\" + 0.009*\"gratia\" + 0.009*\"mundus\" + 0.009*\"verbum\"\n",
      "2024-11-24 21:12:50,838 - INFO - topic diff=1.635696, rho=1.000000\n",
      "2024-11-24 21:12:51,207 - INFO - -6.440 per-word bound, 86.8 perplexity estimate based on a held-out corpus of 1716 documents with 72713 words\n",
      "2024-11-24 21:12:51,208 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:51,513 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:51,514 - INFO - topic #10 (0.067): 0.030*\"fides\" + 0.024*\"christus\" + 0.023*\"delphi\" + 0.017*\"spiritus\" + 0.016*\"lux\" + 0.015*\"mundus\" + 0.013*\"natura\" + 0.013*\"gegen\" + 0.013*\"gratia\" + 0.011*\"verbum\"\n",
      "2024-11-24 21:12:51,514 - INFO - topic #1 (0.067): 0.035*\"christus\" + 0.022*\"sanctus\" + 0.019*\"dies\" + 0.014*\"spiritus\" + 0.012*\"lex\" + 0.012*\"mater\" + 0.011*\"evangelium\" + 0.011*\"ecclesia\" + 0.009*\"debeo\" + 0.008*\"osdroena\"\n",
      "2024-11-24 21:12:51,515 - INFO - topic #2 (0.067): 0.031*\"homo\" + 0.021*\"vita\" + 0.017*\"spiritus\" + 0.014*\"christus\" + 0.014*\"peccatum\" + 0.013*\"mors\" + 0.013*\"ratio\" + 0.012*\"dominus\" + 0.012*\"gratia\" + 0.011*\"sapientia\"\n",
      "2024-11-24 21:12:51,515 - INFO - topic #11 (0.067): 0.028*\"vita\" + 0.022*\"clotho\" + 0.020*\"lux\" + 0.019*\"delphi\" + 0.019*\"amor\" + 0.016*\"iustitia\" + 0.014*\"vivo\" + 0.013*\"homo\" + 0.012*\"venio\" + 0.011*\"gegen\"\n",
      "2024-11-24 21:12:51,515 - INFO - topic #0 (0.067): 0.040*\"natura\" + 0.022*\"homo\" + 0.020*\"sapientia\" + 0.016*\"creo\" + 0.013*\"vita\" + 0.013*\"gloria\" + 0.012*\"ada\" + 0.011*\"rex\" + 0.011*\"humanus\" + 0.011*\"locus\"\n",
      "2024-11-24 21:12:51,515 - INFO - topic diff=0.615809, rho=0.707107\n",
      "2024-11-24 21:12:51,516 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.09s', 'datetime': '2024-11-24T21:12:51.516323', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:51,518 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:51,687 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:12:51,695 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:12:51,698 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:12:51,700 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:12:51,739 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:12:51,808 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:12:51,834 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:12:52,607 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:12:52,641 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:12:52,668 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:12:52,684 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:12:52,697 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:12:52,729 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:12:52,767 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:12:52,771 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:12:52,780 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:12:52,781 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:12:52,783 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:12:52,786 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:12:52,788 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:12:52,790 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:12:52,791 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:12:52,793 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:12:52,795 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:12:52,798 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:12:52,805 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:12:52,807 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:12:52,810 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:12:52,818 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:12:52,827 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:12:52,836 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:12:52,840 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:12:52,843 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:12:52,865 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:12:52,867 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:12:52,876 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:12:52,881 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:12:52,883 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:12:52,888 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:12:52,893 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:12:52,901 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:12:52,920 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:12:53,067 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:12:53,071 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:12:53,072 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:12:53,080 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:12:53,097 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:12:53,099 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:12:53,111 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:12:53,114 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:12:53,116 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:12:53,118 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:12:53,130 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:12:53,145 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:12:53,155 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:12:53,157 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:12:53,175 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:12:53,192 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:12:53,221 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:12:53,327 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:53,354 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:12:53,663 - INFO - 第 1 折评估完成: NPMI=0.4902, Diversity=0.4533, Optimal Score=0.4717\n",
      "实验进度:  77%|███████▋  | 46/60 [02:21<00:45,  3.28s/it]2024-11-24 21:12:53,666 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:53,759 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:12:53,759 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:12:53.759770', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:53,763 - INFO - discarding 8096 tokens: [('aaron', 7), ('asper', 8), ('contritio', 22), ('conversatio', 28), ('correctio', 22), ('dormio', 34), ('element', 7), ('eua', 23), ('expositio', 13), ('generalis', 28)]...\n",
      "2024-11-24 21:12:53,764 - INFO - keeping 800 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:53,765 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:12:53,765 - INFO - 词典过滤: 8896 -> 800 个词\n",
      "2024-11-24 21:12:53,828 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:53,828 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:53,829 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:53,831 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:53,831 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:53,831 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:54,245 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:54,247 - INFO - topic #6 (0.067): 0.024*\"spiritus\" + 0.022*\"delphi\" + 0.015*\"vita\" + 0.013*\"corpus\" + 0.012*\"christus\" + 0.011*\"verbum\" + 0.010*\"desiderium\" + 0.010*\"virtus\" + 0.010*\"mundus\" + 0.009*\"essentia\"\n",
      "2024-11-24 21:12:54,247 - INFO - topic #13 (0.067): 0.022*\"verbum\" + 0.018*\"pater\" + 0.017*\"filius\" + 0.017*\"natura\" + 0.017*\"christus\" + 0.014*\"spiritus\" + 0.014*\"vita\" + 0.014*\"dominus\" + 0.012*\"iesus\" + 0.012*\"corpus\"\n",
      "2024-11-24 21:12:54,247 - INFO - topic #12 (0.067): 0.021*\"delphi\" + 0.020*\"spiritus\" + 0.017*\"ratio\" + 0.016*\"fides\" + 0.013*\"verbum\" + 0.012*\"christus\" + 0.011*\"homo\" + 0.010*\"pax\" + 0.010*\"amor\" + 0.009*\"bonus\"\n",
      "2024-11-24 21:12:54,248 - INFO - topic #10 (0.067): 0.023*\"spiritus\" + 0.021*\"vita\" + 0.018*\"verbum\" + 0.016*\"homo\" + 0.014*\"christus\" + 0.013*\"lex\" + 0.012*\"virtus\" + 0.012*\"iustitia\" + 0.011*\"ostendo\" + 0.011*\"pater\"\n",
      "2024-11-24 21:12:54,248 - INFO - topic #2 (0.067): 0.035*\"christus\" + 0.026*\"spiritus\" + 0.016*\"verbum\" + 0.014*\"mundus\" + 0.012*\"rex\" + 0.011*\"fides\" + 0.011*\"filius\" + 0.011*\"sapientia\" + 0.010*\"homo\" + 0.009*\"delphi\"\n",
      "2024-11-24 21:12:54,248 - INFO - topic diff=1.446414, rho=1.000000\n",
      "2024-11-24 21:12:54,648 - INFO - -6.456 per-word bound, 87.8 perplexity estimate based on a held-out corpus of 1716 documents with 73053 words\n",
      "2024-11-24 21:12:54,648 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:54,967 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:54,968 - INFO - topic #10 (0.067): 0.022*\"spiritus\" + 0.020*\"verbum\" + 0.020*\"lex\" + 0.017*\"homo\" + 0.017*\"vita\" + 0.015*\"virtus\" + 0.014*\"ostendo\" + 0.013*\"credo\" + 0.013*\"christus\" + 0.011*\"sanctus\"\n",
      "2024-11-24 21:12:54,968 - INFO - topic #1 (0.067): 0.023*\"debeo\" + 0.018*\"christus\" + 0.018*\"domus\" + 0.016*\"spiritus\" + 0.014*\"peto\" + 0.013*\"gratia\" + 0.012*\"ecclesia\" + 0.012*\"dies\" + 0.011*\"donum\" + 0.011*\"oratio\"\n",
      "2024-11-24 21:12:54,969 - INFO - topic #2 (0.067): 0.034*\"christus\" + 0.027*\"spiritus\" + 0.024*\"nomen\" + 0.018*\"verbum\" + 0.017*\"sapientia\" + 0.013*\"filius\" + 0.013*\"mundus\" + 0.012*\"fides\" + 0.010*\"virtus\" + 0.010*\"mitto\"\n",
      "2024-11-24 21:12:54,969 - INFO - topic #11 (0.067): 0.028*\"pater\" + 0.023*\"mundus\" + 0.017*\"spiritus\" + 0.016*\"christus\" + 0.013*\"homo\" + 0.013*\"filius\" + 0.012*\"peccatum\" + 0.011*\"veritas\" + 0.011*\"sanctus\" + 0.010*\"bonus\"\n",
      "2024-11-24 21:12:54,969 - INFO - topic #0 (0.067): 0.038*\"vita\" + 0.024*\"mors\" + 0.020*\"motus\" + 0.018*\"verbum\" + 0.016*\"delphi\" + 0.014*\"spiritus\" + 0.012*\"virtus\" + 0.011*\"christus\" + 0.011*\"eligo\" + 0.010*\"debeo\"\n",
      "2024-11-24 21:12:54,970 - INFO - topic diff=0.591180, rho=0.707107\n",
      "2024-11-24 21:12:54,970 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.14s', 'datetime': '2024-11-24T21:12:54.970372', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:54,973 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:55,190 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:12:55,191 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:12:55,194 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:12:55,196 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:12:55,198 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:12:55,200 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:12:55,201 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:12:56,240 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:12:56,257 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:12:56,274 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:12:56,319 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:12:56,367 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:12:56,428 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:12:56,432 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:12:56,453 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:12:56,460 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:12:56,558 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:12:56,569 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:12:56,623 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:12:56,641 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:12:56,643 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:12:56,645 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:12:56,672 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:12:56,674 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:12:56,693 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:12:56,706 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:12:56,725 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:12:56,754 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:12:56,760 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:12:56,765 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:12:56,776 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:12:56,780 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:12:56,782 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:12:56,784 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:12:56,787 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:12:56,788 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:12:56,789 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:12:56,791 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:12:56,792 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:12:56,805 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:12:56,807 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:12:56,809 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:12:56,814 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:12:56,819 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:12:56,829 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:12:56,839 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:12:56,847 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:12:56,849 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:12:56,851 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:12:56,855 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:12:56,870 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:12:56,883 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:12:56,885 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:12:56,889 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:12:56,891 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:12:56,893 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:12:56,900 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:12:56,903 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:12:56,918 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:12:57,053 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:12:57,070 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:12:57,363 - INFO - 第 2 折评估完成: NPMI=0.4939, Diversity=0.4000, Optimal Score=0.4469\n",
      "实验进度:  78%|███████▊  | 47/60 [02:25<00:44,  3.40s/it]2024-11-24 21:12:57,366 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:12:57,470 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:12:57,471 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:12:57.471221', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:57,476 - INFO - discarding 8034 tokens: [('apocalypsis', 13), ('constantinus', 33), ('corona', 28), ('element', 9), ('generalis', 26), ('grando', 6), ('principalis', 17), ('specialis', 13), ('terraemotus', 6), ('aaron', 8)]...\n",
      "2024-11-24 21:12:57,477 - INFO - keeping 800 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:12:57,480 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:12:57,481 - INFO - 词典过滤: 8834 -> 800 个词\n",
      "2024-11-24 21:12:57,551 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:12:57,551 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:12:57,552 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:12:57,553 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:12:57,553 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:12:57,554 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:12:57,954 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:57,955 - INFO - topic #6 (0.067): 0.060*\"und\" + 0.033*\"dies\" + 0.021*\"delphi\" + 0.019*\"christus\" + 0.019*\"is\" + 0.014*\"vita\" + 0.014*\"verbum\" + 0.011*\"debeo\" + 0.011*\"spiritus\" + 0.010*\"dar\"\n",
      "2024-11-24 21:12:57,956 - INFO - topic #13 (0.067): 0.051*\"christus\" + 0.018*\"homo\" + 0.017*\"venio\" + 0.014*\"corpus\" + 0.013*\"virtus\" + 0.012*\"rex\" + 0.011*\"panis\" + 0.011*\"verbum\" + 0.011*\"spiritus\" + 0.009*\"gloria\"\n",
      "2024-11-24 21:12:57,956 - INFO - topic #12 (0.067): 0.022*\"spiritus\" + 0.021*\"vita\" + 0.019*\"verbum\" + 0.016*\"filius\" + 0.014*\"sanctus\" + 0.012*\"pater\" + 0.012*\"fides\" + 0.011*\"veritas\" + 0.011*\"homo\" + 0.010*\"natura\"\n",
      "2024-11-24 21:12:57,956 - INFO - topic #10 (0.067): 0.033*\"spiritus\" + 0.024*\"christus\" + 0.017*\"mundus\" + 0.015*\"homo\" + 0.014*\"natura\" + 0.012*\"verbum\" + 0.011*\"vita\" + 0.011*\"pater\" + 0.009*\"sapientia\" + 0.009*\"divinus\"\n",
      "2024-11-24 21:12:57,957 - INFO - topic #2 (0.067): 0.020*\"spiritus\" + 0.017*\"homo\" + 0.017*\"virtus\" + 0.017*\"christus\" + 0.015*\"filius\" + 0.013*\"fides\" + 0.012*\"natura\" + 0.011*\"dominus\" + 0.010*\"verbum\" + 0.010*\"gratia\"\n",
      "2024-11-24 21:12:57,957 - INFO - topic diff=1.418527, rho=1.000000\n",
      "2024-11-24 21:12:58,425 - INFO - -6.454 per-word bound, 87.7 perplexity estimate based on a held-out corpus of 1716 documents with 71901 words\n",
      "2024-11-24 21:12:58,426 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:12:58,736 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:12:58,737 - INFO - topic #10 (0.067): 0.031*\"spiritus\" + 0.024*\"natura\" + 0.019*\"homo\" + 0.018*\"christus\" + 0.017*\"ars\" + 0.017*\"mundus\" + 0.016*\"sapientia\" + 0.013*\"infinitus\" + 0.012*\"humanus\" + 0.011*\"verbum\"\n",
      "2024-11-24 21:12:58,737 - INFO - topic #1 (0.067): 0.033*\"christus\" + 0.015*\"mundus\" + 0.014*\"dies\" + 0.014*\"mater\" + 0.011*\"sanctus\" + 0.010*\"volo\" + 0.009*\"debeo\" + 0.009*\"ratio\" + 0.008*\"sequor\" + 0.008*\"cognosco\"\n",
      "2024-11-24 21:12:58,737 - INFO - topic #2 (0.067): 0.018*\"virtus\" + 0.016*\"filius\" + 0.016*\"dominus\" + 0.015*\"christus\" + 0.015*\"homo\" + 0.015*\"fides\" + 0.015*\"spiritus\" + 0.014*\"gratia\" + 0.011*\"natura\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:12:58,738 - INFO - topic #11 (0.067): 0.033*\"lux\" + 0.024*\"spiritus\" + 0.019*\"gratia\" + 0.017*\"gegen\" + 0.014*\"tenebrae\" + 0.012*\"fides\" + 0.011*\"veritas\" + 0.011*\"sanctus\" + 0.010*\"donum\" + 0.010*\"homo\"\n",
      "2024-11-24 21:12:58,738 - INFO - topic #0 (0.067): 0.056*\"filius\" + 0.049*\"pater\" + 0.026*\"christus\" + 0.025*\"homo\" + 0.024*\"nomen\" + 0.023*\"spiritus\" + 0.022*\"fides\" + 0.015*\"credo\" + 0.012*\"verbum\" + 0.011*\"vita\"\n",
      "2024-11-24 21:12:58,738 - INFO - topic diff=0.588845, rho=0.707107\n",
      "2024-11-24 21:12:58,739 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.19s', 'datetime': '2024-11-24T21:12:58.739200', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:12:58,741 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:12:58,786 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:12:58,790 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:12:58,795 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:12:58,807 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:12:58,854 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:12:58,930 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:12:58,935 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:12:59,802 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:12:59,815 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:12:59,828 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:12:59,841 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:12:59,856 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:12:59,868 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:12:59,897 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:12:59,903 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:12:59,907 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:12:59,913 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:12:59,916 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:12:59,917 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:12:59,919 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:12:59,921 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:12:59,931 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:12:59,941 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:12:59,944 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:12:59,947 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:12:59,949 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:12:59,955 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:12:59,970 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:12:59,971 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:12:59,975 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:12:59,977 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:12:59,985 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:13:00,023 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:13:00,090 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:13:00,180 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:13:00,181 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:13:00,191 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:13:00,192 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:13:00,223 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:13:00,225 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:13:00,227 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:13:00,229 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:13:00,230 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:13:00,233 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:13:00,250 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:13:00,252 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:13:00,270 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:13:00,273 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:13:00,275 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:13:00,278 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:13:00,308 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:13:00,318 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:13:00,319 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:13:00,340 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:13:00,348 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:13:00,350 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:13:00,351 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:13:00,353 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:13:00,357 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:13:00,489 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:00,624 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:13:00,847 - INFO - 第 3 折评估完成: NPMI=0.4922, Diversity=0.4400, Optimal Score=0.4661\n",
      "实验进度:  80%|████████  | 48/60 [02:28<00:41,  3.43s/it]2024-11-24 21:13:00,850 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:00,936 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:13:00,937 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:13:00.937174', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:00,940 - INFO - discarding 8085 tokens: [('apocalypsis', 14), ('constantinus', 30), ('corona', 26), ('element', 6), ('generalis', 25), ('grando', 3), ('principalis', 16), ('specialis', 12), ('terraemotus', 3), ('amicitia', 23)]...\n",
      "2024-11-24 21:13:00,941 - INFO - keeping 800 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:00,942 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:13:00,943 - INFO - 词典过滤: 8885 -> 800 个词\n",
      "2024-11-24 21:13:00,991 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:00,991 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:00,992 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:00,995 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:00,996 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:00,997 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:01,392 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:01,393 - INFO - topic #6 (0.067): 0.030*\"homo\" + 0.025*\"christus\" + 0.025*\"spiritus\" + 0.020*\"vita\" + 0.016*\"delphi\" + 0.015*\"virtus\" + 0.015*\"verbum\" + 0.015*\"natura\" + 0.013*\"filius\" + 0.009*\"und\"\n",
      "2024-11-24 21:13:01,393 - INFO - topic #13 (0.067): 0.020*\"amor\" + 0.020*\"christus\" + 0.020*\"vita\" + 0.019*\"filius\" + 0.018*\"locus\" + 0.018*\"virtus\" + 0.012*\"verbum\" + 0.011*\"spiritus\" + 0.011*\"debeo\" + 0.011*\"pater\"\n",
      "2024-11-24 21:13:01,394 - INFO - topic #12 (0.067): 0.018*\"spiritus\" + 0.016*\"homo\" + 0.015*\"christus\" + 0.012*\"debeo\" + 0.012*\"pulchritudo\" + 0.011*\"pater\" + 0.011*\"dies\" + 0.010*\"verbum\" + 0.009*\"fides\" + 0.009*\"dominus\"\n",
      "2024-11-24 21:13:01,394 - INFO - topic #10 (0.067): 0.025*\"christus\" + 0.015*\"verbum\" + 0.015*\"pater\" + 0.015*\"homo\" + 0.014*\"nomen\" + 0.013*\"vita\" + 0.013*\"gloria\" + 0.012*\"spiritus\" + 0.012*\"sapientia\" + 0.012*\"principium\"\n",
      "2024-11-24 21:13:01,394 - INFO - topic #2 (0.067): 0.033*\"christus\" + 0.026*\"vita\" + 0.020*\"und\" + 0.016*\"dies\" + 0.015*\"mundus\" + 0.014*\"spiritus\" + 0.012*\"filius\" + 0.012*\"homo\" + 0.011*\"intellego\" + 0.010*\"regnum\"\n",
      "2024-11-24 21:13:01,395 - INFO - topic diff=1.573036, rho=1.000000\n",
      "2024-11-24 21:13:01,864 - INFO - -6.442 per-word bound, 86.9 perplexity estimate based on a held-out corpus of 1716 documents with 72301 words\n",
      "2024-11-24 21:13:01,865 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:02,173 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:02,174 - INFO - topic #10 (0.067): 0.032*\"nomen\" + 0.024*\"pater\" + 0.022*\"christus\" + 0.020*\"principium\" + 0.016*\"creatura\" + 0.015*\"homo\" + 0.015*\"verbum\" + 0.015*\"larissa\" + 0.015*\"tempus\" + 0.014*\"sapientia\"\n",
      "2024-11-24 21:13:02,174 - INFO - topic #1 (0.067): 0.035*\"spiritus\" + 0.024*\"gratia\" + 0.022*\"vita\" + 0.016*\"dies\" + 0.015*\"panis\" + 0.013*\"delphi\" + 0.013*\"sanctus\" + 0.011*\"iustitia\" + 0.010*\"christus\" + 0.010*\"misericordia\"\n",
      "2024-11-24 21:13:02,175 - INFO - topic #2 (0.067): 0.046*\"christus\" + 0.034*\"dies\" + 0.028*\"vita\" + 0.013*\"sanctus\" + 0.012*\"mundus\" + 0.011*\"intellego\" + 0.010*\"mors\" + 0.010*\"homo\" + 0.010*\"venio\" + 0.010*\"filius\"\n",
      "2024-11-24 21:13:02,175 - INFO - topic #11 (0.067): 0.033*\"natura\" + 0.028*\"christus\" + 0.026*\"pater\" + 0.025*\"filius\" + 0.017*\"debeo\" + 0.014*\"corpus\" + 0.014*\"homo\" + 0.011*\"mundus\" + 0.009*\"delphi\" + 0.009*\"dominus\"\n",
      "2024-11-24 21:13:02,176 - INFO - topic #0 (0.067): 0.024*\"pax\" + 0.021*\"terra\" + 0.016*\"christus\" + 0.015*\"voluntas\" + 0.013*\"vita\" + 0.011*\"homo\" + 0.011*\"pater\" + 0.011*\"evangelium\" + 0.010*\"larissa\" + 0.010*\"quaero\"\n",
      "2024-11-24 21:13:02,176 - INFO - topic diff=0.613584, rho=0.707107\n",
      "2024-11-24 21:13:02,176 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.18s', 'datetime': '2024-11-24T21:13:02.176642', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:02,179 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:02,227 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:13:02,234 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:13:02,243 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:13:02,251 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:13:02,293 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:13:02,384 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:13:02,422 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:13:03,087 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:13:03,113 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:13:03,140 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:13:03,176 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:13:03,211 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:13:03,216 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:13:03,234 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:13:03,241 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:13:03,252 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:13:03,267 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:13:03,282 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:13:03,295 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:13:03,297 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:13:03,299 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:13:03,301 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:13:03,309 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:13:03,317 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:13:03,319 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:13:03,325 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:13:03,327 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:13:03,332 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:13:03,334 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:13:03,337 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:13:03,467 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:13:03,484 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:13:03,498 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:13:03,518 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:13:03,522 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:13:03,524 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:13:03,527 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:13:03,529 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:13:03,551 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:13:03,556 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:13:03,565 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:13:03,569 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:13:03,595 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:13:03,617 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:13:03,626 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:13:03,630 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:13:03,632 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:13:03,634 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:13:03,642 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:13:03,655 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:13:03,659 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:13:03,661 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:13:03,668 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:13:03,671 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:13:03,677 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:13:03,684 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:13:03,703 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:13:03,715 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:13:03,718 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:13:04,045 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:04,058 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:13:04,236 - INFO - 第 4 折评估完成: NPMI=0.4890, Diversity=0.4200, Optimal Score=0.4545\n",
      "实验进度:  82%|████████▏ | 49/60 [02:31<00:37,  3.42s/it]2024-11-24 21:13:04,237 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:04,336 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:13:04,337 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:13:04.337054', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:04,340 - INFO - discarding 8103 tokens: [('apocalypsis', 15), ('constantinus', 35), ('corona', 26), ('element', 9), ('generalis', 24), ('grando', 7), ('principalis', 16), ('specialis', 11), ('terraemotus', 5), ('aaron', 5)]...\n",
      "2024-11-24 21:13:04,340 - INFO - keeping 800 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:04,341 - INFO - resulting dictionary: Dictionary<800 unique tokens: ['appareo', 'behalten', 'dominus', 'ecclesia', 'expono']...>\n",
      "2024-11-24 21:13:04,342 - INFO - 词典过滤: 8903 -> 800 个词\n",
      "2024-11-24 21:13:04,389 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:04,390 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:04,390 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:04,391 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:04,391 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:04,392 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:04,775 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:04,776 - INFO - topic #6 (0.067): 0.027*\"homo\" + 0.024*\"filius\" + 0.021*\"christus\" + 0.020*\"pater\" + 0.016*\"verbum\" + 0.016*\"virtus\" + 0.011*\"vita\" + 0.010*\"imago\" + 0.010*\"intellego\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:13:04,777 - INFO - topic #13 (0.067): 0.047*\"christus\" + 0.025*\"virtus\" + 0.018*\"homo\" + 0.017*\"spiritus\" + 0.014*\"verbum\" + 0.012*\"vita\" + 0.011*\"corpus\" + 0.011*\"delphi\" + 0.009*\"natura\" + 0.009*\"ratio\"\n",
      "2024-11-24 21:13:04,777 - INFO - topic #12 (0.067): 0.029*\"vita\" + 0.023*\"fides\" + 0.022*\"spiritus\" + 0.020*\"verbum\" + 0.016*\"homo\" + 0.015*\"lux\" + 0.013*\"christus\" + 0.013*\"pater\" + 0.013*\"filius\" + 0.012*\"veritas\"\n",
      "2024-11-24 21:13:04,777 - INFO - topic #10 (0.067): 0.030*\"spiritus\" + 0.025*\"christus\" + 0.025*\"filius\" + 0.023*\"vita\" + 0.016*\"fides\" + 0.015*\"verbum\" + 0.015*\"pater\" + 0.014*\"delphi\" + 0.013*\"mundus\" + 0.011*\"natura\"\n",
      "2024-11-24 21:13:04,778 - INFO - topic #2 (0.067): 0.017*\"intellectus\" + 0.016*\"cognosco\" + 0.016*\"christus\" + 0.015*\"dominus\" + 0.013*\"lux\" + 0.013*\"pater\" + 0.012*\"virtus\" + 0.012*\"fides\" + 0.011*\"clotho\" + 0.011*\"iudico\"\n",
      "2024-11-24 21:13:04,778 - INFO - topic diff=1.539441, rho=1.000000\n",
      "2024-11-24 21:13:05,254 - INFO - -6.459 per-word bound, 88.0 perplexity estimate based on a held-out corpus of 1716 documents with 72659 words\n",
      "2024-11-24 21:13:05,255 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:05,567 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:05,568 - INFO - topic #10 (0.067): 0.029*\"christus\" + 0.028*\"filius\" + 0.026*\"spiritus\" + 0.026*\"vita\" + 0.020*\"pater\" + 0.018*\"delphi\" + 0.017*\"fides\" + 0.016*\"verbum\" + 0.014*\"corpus\" + 0.014*\"veritas\"\n",
      "2024-11-24 21:13:05,568 - INFO - topic #1 (0.067): 0.039*\"christus\" + 0.021*\"debeo\" + 0.020*\"mater\" + 0.016*\"nomen\" + 0.016*\"sanctus\" + 0.016*\"vita\" + 0.014*\"pater\" + 0.014*\"domus\" + 0.014*\"und\" + 0.013*\"symbatios\"\n",
      "2024-11-24 21:13:05,568 - INFO - topic #2 (0.067): 0.029*\"intellectus\" + 0.021*\"cognosco\" + 0.019*\"dominus\" + 0.014*\"pater\" + 0.013*\"nomen\" + 0.013*\"iudico\" + 0.013*\"lux\" + 0.013*\"christus\" + 0.012*\"fides\" + 0.010*\"delphi\"\n",
      "2024-11-24 21:13:05,569 - INFO - topic #11 (0.067): 0.020*\"christus\" + 0.018*\"dies\" + 0.017*\"nomen\" + 0.017*\"delphi\" + 0.014*\"dominus\" + 0.012*\"debeo\" + 0.011*\"vita\" + 0.010*\"peccatum\" + 0.008*\"voluntas\" + 0.008*\"vivo\"\n",
      "2024-11-24 21:13:05,569 - INFO - topic #0 (0.067): 0.041*\"pater\" + 0.037*\"filius\" + 0.019*\"sanctus\" + 0.018*\"nomen\" + 0.015*\"spiritus\" + 0.011*\"christus\" + 0.010*\"gratia\" + 0.009*\"tertius\" + 0.008*\"dies\" + 0.008*\"vita\"\n",
      "2024-11-24 21:13:05,569 - INFO - topic diff=0.615090, rho=0.707107\n",
      "2024-11-24 21:13:05,569 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=800, num_topics=15, decay=0.5, chunksize=2000> in 1.18s', 'datetime': '2024-11-24T21:13:05.569836', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:05,572 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:05,623 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:13:05,642 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:13:05,730 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:13:05,802 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:13:05,804 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:13:05,806 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:13:05,807 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:13:06,601 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:13:06,610 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:13:06,620 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:13:06,648 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:13:06,661 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:13:06,674 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:13:06,690 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:13:06,692 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:13:06,699 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:13:06,710 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:13:06,742 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:13:06,747 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:13:06,769 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:13:06,792 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:13:06,843 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:13:06,928 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:13:06,931 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:13:06,966 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:13:06,977 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:13:06,985 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:13:06,987 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:13:06,989 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:13:06,999 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:13:07,001 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:13:07,005 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:13:07,011 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:13:07,016 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:13:07,023 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:13:07,031 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:13:07,044 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:13:07,047 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:13:07,050 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:13:07,052 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:13:07,055 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:13:07,058 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:13:07,073 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:13:07,075 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:13:07,092 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:13:07,097 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:13:07,099 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:13:07,103 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:13:07,118 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:13:07,120 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:13:07,131 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:13:07,138 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:13:07,144 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:13:07,146 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:13:07,153 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:13:07,160 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:13:07,162 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:13:07,182 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:13:07,196 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:13:07,506 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:07,529 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:13:07,710 - INFO - 第 5 折评估完成: NPMI=0.4891, Diversity=0.3933, Optimal Score=0.4412\n",
      "实验进度:  83%|████████▎ | 50/60 [02:35<00:34,  3.43s/it]2024-11-24 21:13:07,711 - INFO - \n",
      "评估阈值组合: min_freq=4, max_freq=1400\n",
      "2024-11-24 21:13:07,715 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:07,815 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:13:07,816 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:13:07.816088', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:07,819 - INFO - discarding 7439 tokens: [('apocalypsis', 16), ('element', 9), ('grando', 6), ('principalis', 18), ('specialis', 14), ('terraemotus', 5), ('aaron', 7), ('asper', 9), ('correctio', 16), ('expositio', 14)]...\n",
      "2024-11-24 21:13:07,819 - INFO - keeping 1400 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:07,820 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:13:07,821 - INFO - 词典过滤: 8839 -> 1400 个词\n",
      "2024-11-24 21:13:07,885 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:07,886 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:07,887 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:07,889 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:07,890 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:07,891 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:08,327 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:08,328 - INFO - topic #8 (0.067): 0.022*\"iustitia\" + 0.020*\"virtus\" + 0.013*\"spiritus\" + 0.012*\"christus\" + 0.010*\"verbum\" + 0.010*\"larissa\" + 0.009*\"vita\" + 0.008*\"veritas\" + 0.008*\"filius\" + 0.008*\"verus\"\n",
      "2024-11-24 21:13:08,329 - INFO - topic #7 (0.067): 0.031*\"christus\" + 0.023*\"spiritus\" + 0.016*\"pater\" + 0.012*\"virtus\" + 0.012*\"vita\" + 0.011*\"mundus\" + 0.010*\"semen\" + 0.009*\"debeo\" + 0.009*\"terra\" + 0.008*\"delphi\"\n",
      "2024-11-24 21:13:08,329 - INFO - topic #5 (0.067): 0.044*\"und\" + 0.016*\"is\" + 0.016*\"verbum\" + 0.015*\"wir\" + 0.014*\"dies\" + 0.012*\"got\" + 0.009*\"spiritus\" + 0.009*\"pulchritudo\" + 0.009*\"mundus\" + 0.009*\"christus\"\n",
      "2024-11-24 21:13:08,329 - INFO - topic #14 (0.067): 0.018*\"vita\" + 0.017*\"christus\" + 0.016*\"spiritus\" + 0.012*\"natura\" + 0.011*\"fides\" + 0.010*\"veritas\" + 0.009*\"delphi\" + 0.008*\"filius\" + 0.008*\"intellectus\" + 0.007*\"petrus\"\n",
      "2024-11-24 21:13:08,330 - INFO - topic #1 (0.067): 0.035*\"delphi\" + 0.019*\"christus\" + 0.016*\"spiritus\" + 0.013*\"vita\" + 0.013*\"virtus\" + 0.013*\"corpus\" + 0.011*\"homo\" + 0.010*\"verbum\" + 0.009*\"dominus\" + 0.008*\"natura\"\n",
      "2024-11-24 21:13:08,330 - INFO - topic diff=2.396923, rho=1.000000\n",
      "2024-11-24 21:13:08,825 - INFO - -6.937 per-word bound, 122.6 perplexity estimate based on a held-out corpus of 1716 documents with 82506 words\n",
      "2024-11-24 21:13:08,825 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:09,145 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:09,146 - INFO - topic #5 (0.067): 0.034*\"und\" + 0.021*\"pulchritudo\" + 0.020*\"dies\" + 0.018*\"verbum\" + 0.014*\"is\" + 0.011*\"wir\" + 0.010*\"via\" + 0.009*\"intellectus\" + 0.009*\"got\" + 0.008*\"viator\"\n",
      "2024-11-24 21:13:09,147 - INFO - topic #2 (0.067): 0.020*\"lux\" + 0.018*\"homo\" + 0.016*\"vita\" + 0.015*\"verbum\" + 0.014*\"filius\" + 0.012*\"christus\" + 0.012*\"mundus\" + 0.011*\"venio\" + 0.010*\"sapientia\" + 0.009*\"terra\"\n",
      "2024-11-24 21:13:09,147 - INFO - topic #14 (0.067): 0.020*\"natura\" + 0.019*\"vita\" + 0.018*\"veritas\" + 0.016*\"christus\" + 0.015*\"petrus\" + 0.013*\"imago\" + 0.012*\"spiritus\" + 0.011*\"fides\" + 0.009*\"intellectus\" + 0.009*\"ratio\"\n",
      "2024-11-24 21:13:09,147 - INFO - topic #8 (0.067): 0.049*\"iustitia\" + 0.026*\"virtus\" + 0.017*\"iustus\" + 0.013*\"veritas\" + 0.011*\"larissa\" + 0.010*\"christus\" + 0.008*\"spiritus\" + 0.008*\"verus\" + 0.008*\"verbum\" + 0.007*\"vita\"\n",
      "2024-11-24 21:13:09,147 - INFO - topic #0 (0.067): 0.020*\"christus\" + 0.018*\"filius\" + 0.017*\"homo\" + 0.016*\"pater\" + 0.016*\"verbum\" + 0.015*\"sanctus\" + 0.010*\"vita\" + 0.009*\"pax\" + 0.009*\"gratia\" + 0.009*\"spiritus\"\n",
      "2024-11-24 21:13:09,148 - INFO - topic diff=0.816336, rho=0.707107\n",
      "2024-11-24 21:13:09,148 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.26s', 'datetime': '2024-11-24T21:13:09.148384', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:09,151 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:09,199 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:13:09,208 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:13:09,232 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:13:09,380 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:13:09,411 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:13:09,412 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:13:09,414 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:13:10,020 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:13:10,044 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:13:10,083 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:13:10,127 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:13:10,184 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:13:10,187 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:13:10,192 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:13:10,194 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:13:10,213 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:13:10,224 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:13:10,237 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:13:10,370 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:13:10,394 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:13:10,428 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:13:10,431 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:13:10,433 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:13:10,436 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:13:10,441 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:13:10,461 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:13:10,463 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:13:10,470 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:13:10,481 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:13:10,484 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:13:10,485 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:13:10,496 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:13:10,502 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:13:10,507 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:13:10,514 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:13:10,518 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:13:10,523 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:13:10,525 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:13:10,527 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:13:10,530 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:13:10,544 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:13:10,549 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:13:10,551 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:13:10,553 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:13:10,575 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:13:10,580 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:13:10,582 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:13:10,584 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:13:10,585 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:13:10,588 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:13:10,590 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:13:10,593 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:13:10,595 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:13:10,596 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:13:10,598 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:13:10,608 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:13:10,611 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:13:10,617 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:13:10,626 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:13:10,760 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:10,882 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:13:11,116 - INFO - 第 1 折评估完成: NPMI=0.4860, Diversity=0.4133, Optimal Score=0.4497\n",
      "实验进度:  85%|████████▌ | 51/60 [02:38<00:30,  3.43s/it]2024-11-24 21:13:11,118 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:11,221 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:13:11,222 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:13:11.222494', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:11,225 - INFO - discarding 7496 tokens: [('aaron', 7), ('asper', 8), ('element', 7), ('expositio', 13), ('grando', 6), ('habitaculum', 19), ('latus', 7), ('leichnam', 2), ('noe', 12), ('perforo', 5)]...\n",
      "2024-11-24 21:13:11,226 - INFO - keeping 1400 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:11,227 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:13:11,228 - INFO - 词典过滤: 8896 -> 1400 个词\n",
      "2024-11-24 21:13:11,285 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:11,285 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:11,286 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:11,288 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:11,288 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:11,289 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:11,790 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:11,791 - INFO - topic #8 (0.067): 0.034*\"christus\" + 0.021*\"vita\" + 0.015*\"verbum\" + 0.013*\"pater\" + 0.013*\"homo\" + 0.011*\"lux\" + 0.009*\"debeo\" + 0.009*\"delphi\" + 0.007*\"stella\" + 0.007*\"rex\"\n",
      "2024-11-24 21:13:11,792 - INFO - topic #7 (0.067): 0.022*\"christus\" + 0.018*\"verbum\" + 0.015*\"filius\" + 0.014*\"virtus\" + 0.013*\"debeo\" + 0.010*\"semen\" + 0.010*\"vita\" + 0.009*\"volo\" + 0.008*\"terra\" + 0.008*\"delphi\"\n",
      "2024-11-24 21:13:11,792 - INFO - topic #5 (0.067): 0.024*\"christus\" + 0.015*\"ratio\" + 0.015*\"und\" + 0.014*\"fides\" + 0.013*\"symbatios\" + 0.012*\"peccatum\" + 0.010*\"virtus\" + 0.010*\"spiritus\" + 0.009*\"amor\" + 0.008*\"vita\"\n",
      "2024-11-24 21:13:11,792 - INFO - topic #14 (0.067): 0.033*\"pater\" + 0.026*\"filius\" + 0.022*\"christus\" + 0.022*\"vita\" + 0.015*\"veritas\" + 0.014*\"spiritus\" + 0.011*\"homo\" + 0.009*\"mundus\" + 0.008*\"dies\" + 0.008*\"opus\"\n",
      "2024-11-24 21:13:11,793 - INFO - topic #1 (0.067): 0.026*\"christus\" + 0.020*\"vita\" + 0.012*\"debeo\" + 0.012*\"virtus\" + 0.011*\"filius\" + 0.011*\"gegen\" + 0.011*\"panis\" + 0.010*\"und\" + 0.010*\"intellectus\" + 0.009*\"divinus\"\n",
      "2024-11-24 21:13:11,793 - INFO - topic diff=2.232802, rho=1.000000\n",
      "2024-11-24 21:13:12,202 - INFO - -6.935 per-word bound, 122.4 perplexity estimate based on a held-out corpus of 1716 documents with 82647 words\n",
      "2024-11-24 21:13:12,202 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:12,523 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:12,524 - INFO - topic #5 (0.067): 0.024*\"symbatios\" + 0.022*\"fides\" + 0.022*\"peccatum\" + 0.020*\"ratio\" + 0.020*\"christus\" + 0.013*\"amor\" + 0.009*\"virtus\" + 0.008*\"spiritus\" + 0.008*\"diligo\" + 0.007*\"verus\"\n",
      "2024-11-24 21:13:12,525 - INFO - topic #2 (0.067): 0.061*\"spiritus\" + 0.025*\"homo\" + 0.025*\"christus\" + 0.019*\"mundus\" + 0.013*\"dies\" + 0.012*\"vita\" + 0.012*\"venio\" + 0.011*\"filius\" + 0.010*\"motus\" + 0.008*\"veritas\"\n",
      "2024-11-24 21:13:12,525 - INFO - topic #14 (0.067): 0.057*\"pater\" + 0.042*\"filius\" + 0.027*\"christus\" + 0.020*\"veritas\" + 0.018*\"vita\" + 0.013*\"spiritus\" + 0.012*\"homo\" + 0.009*\"dies\" + 0.009*\"cognosco\" + 0.009*\"opus\"\n",
      "2024-11-24 21:13:12,525 - INFO - topic #8 (0.067): 0.041*\"christus\" + 0.020*\"vita\" + 0.016*\"verbum\" + 0.013*\"homo\" + 0.012*\"pater\" + 0.010*\"lux\" + 0.009*\"stella\" + 0.009*\"debeo\" + 0.008*\"delphi\" + 0.008*\"gaudium\"\n",
      "2024-11-24 21:13:12,526 - INFO - topic #0 (0.067): 0.035*\"verbum\" + 0.019*\"pater\" + 0.018*\"barabbas\" + 0.014*\"terra\" + 0.014*\"mundus\" + 0.013*\"christus\" + 0.013*\"lex\" + 0.012*\"filius\" + 0.011*\"vita\" + 0.011*\"delphi\"\n",
      "2024-11-24 21:13:12,526 - INFO - topic diff=0.820391, rho=0.707107\n",
      "2024-11-24 21:13:12,526 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.24s', 'datetime': '2024-11-24T21:13:12.526822', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:12,529 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:12,577 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:13:12,581 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:13:12,586 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:13:12,706 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:13:12,750 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:13:12,757 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:13:12,797 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:13:13,542 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:13:13,560 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:13:13,572 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:13:13,574 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:13:13,599 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:13:13,697 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:13:13,779 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:13:13,782 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:13:13,783 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:13:13,785 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:13:13,787 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:13:13,789 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:13:13,792 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:13:13,794 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:13:13,802 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:13:13,803 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:13:13,809 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:13:13,818 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:13:13,820 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:13:13,822 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:13:13,832 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:13:13,834 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:13:13,836 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:13:13,840 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:13:13,853 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:13:13,856 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:13:13,862 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:13:13,866 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:13:13,868 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:13:13,882 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:13:13,887 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:13:13,891 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:13:13,895 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:13:13,899 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:13:13,901 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:13:13,919 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:13:13,923 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:13:13,924 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:13:13,929 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:13:13,931 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:13:13,937 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:13:13,949 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:13:13,962 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:13:13,964 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:13:13,968 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:13:13,982 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:13:13,984 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:13:13,994 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:13:13,998 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:13:14,000 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:13:14,005 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:13:14,010 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:13:14,236 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:14,286 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:13:14,515 - INFO - 第 2 折评估完成: NPMI=0.4908, Diversity=0.4067, Optimal Score=0.4487\n",
      "实验进度:  87%|████████▋ | 52/60 [02:42<00:27,  3.42s/it]2024-11-24 21:13:14,518 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:14,604 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:13:14,605 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:13:14.605076', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:14,608 - INFO - discarding 7434 tokens: [('apocalypsis', 13), ('element', 9), ('grando', 6), ('principalis', 17), ('specialis', 13), ('terraemotus', 6), ('aaron', 8), ('asper', 9), ('contritio', 14), ('correctio', 17)]...\n",
      "2024-11-24 21:13:14,608 - INFO - keeping 1400 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:14,610 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:13:14,610 - INFO - 词典过滤: 8834 -> 1400 个词\n",
      "2024-11-24 21:13:14,663 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:14,663 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:14,664 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:14,676 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:14,677 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:14,678 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:15,183 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:15,184 - INFO - topic #8 (0.067): 0.018*\"vita\" + 0.013*\"larissa\" + 0.013*\"homo\" + 0.012*\"christus\" + 0.012*\"iustitia\" + 0.011*\"spiritus\" + 0.010*\"debeo\" + 0.010*\"lux\" + 0.009*\"amor\" + 0.008*\"dies\"\n",
      "2024-11-24 21:13:15,184 - INFO - topic #7 (0.067): 0.028*\"christus\" + 0.019*\"mundus\" + 0.016*\"debeo\" + 0.010*\"spiritus\" + 0.009*\"ratio\" + 0.009*\"delphi\" + 0.009*\"rex\" + 0.009*\"virtus\" + 0.009*\"volo\" + 0.007*\"vita\"\n",
      "2024-11-24 21:13:15,184 - INFO - topic #5 (0.067): 0.060*\"und\" + 0.031*\"dies\" + 0.016*\"is\" + 0.014*\"verbum\" + 0.014*\"wir\" + 0.012*\"spiritus\" + 0.012*\"peccatum\" + 0.012*\"christus\" + 0.011*\"unser\" + 0.010*\"got\"\n",
      "2024-11-24 21:13:15,185 - INFO - topic #14 (0.067): 0.027*\"vita\" + 0.019*\"filius\" + 0.014*\"christus\" + 0.011*\"homo\" + 0.008*\"mundus\" + 0.008*\"symbatios\" + 0.007*\"pater\" + 0.007*\"mors\" + 0.007*\"scio\" + 0.006*\"ratio\"\n",
      "2024-11-24 21:13:15,185 - INFO - topic #1 (0.067): 0.034*\"vita\" + 0.020*\"christus\" + 0.018*\"spiritus\" + 0.015*\"mors\" + 0.014*\"delphi\" + 0.011*\"verbum\" + 0.010*\"dominus\" + 0.009*\"lex\" + 0.009*\"filius\" + 0.007*\"opus\"\n",
      "2024-11-24 21:13:15,185 - INFO - topic diff=2.470042, rho=1.000000\n",
      "2024-11-24 21:13:15,590 - INFO - -6.921 per-word bound, 121.2 perplexity estimate based on a held-out corpus of 1716 documents with 81296 words\n",
      "2024-11-24 21:13:15,590 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:15,909 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:15,910 - INFO - topic #5 (0.067): 0.078*\"dies\" + 0.038*\"und\" + 0.034*\"peccatum\" + 0.014*\"verbum\" + 0.011*\"is\" + 0.010*\"christus\" + 0.009*\"spiritus\" + 0.009*\"delphi\" + 0.009*\"wir\" + 0.009*\"motus\"\n",
      "2024-11-24 21:13:15,910 - INFO - topic #2 (0.067): 0.020*\"christus\" + 0.014*\"homo\" + 0.013*\"vita\" + 0.011*\"filius\" + 0.010*\"lex\" + 0.010*\"via\" + 0.010*\"mundus\" + 0.009*\"bonus\" + 0.009*\"iustitia\" + 0.009*\"annas\"\n",
      "2024-11-24 21:13:15,911 - INFO - topic #14 (0.067): 0.024*\"vita\" + 0.014*\"filius\" + 0.012*\"homo\" + 0.012*\"mare\" + 0.010*\"christus\" + 0.009*\"symbatios\" + 0.009*\"contemplatio\" + 0.008*\"dies\" + 0.008*\"theophilus\" + 0.007*\"gebresten\"\n",
      "2024-11-24 21:13:15,911 - INFO - topic #8 (0.067): 0.024*\"iustitia\" + 0.019*\"larissa\" + 0.015*\"vita\" + 0.014*\"sol\" + 0.013*\"homo\" + 0.012*\"lux\" + 0.012*\"iustus\" + 0.011*\"christus\" + 0.010*\"dies\" + 0.009*\"debeo\"\n",
      "2024-11-24 21:13:15,912 - INFO - topic #0 (0.067): 0.045*\"filius\" + 0.042*\"pater\" + 0.022*\"verbum\" + 0.017*\"christus\" + 0.015*\"gratia\" + 0.012*\"homo\" + 0.010*\"sanctus\" + 0.010*\"ars\" + 0.010*\"semen\" + 0.009*\"imago\"\n",
      "2024-11-24 21:13:15,912 - INFO - topic diff=0.830118, rho=0.707107\n",
      "2024-11-24 21:13:15,912 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.24s', 'datetime': '2024-11-24T21:13:15.912646', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:15,915 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:15,963 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:13:15,967 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:13:15,978 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:13:16,092 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:13:16,151 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:13:16,154 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:13:16,155 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:13:16,847 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:13:16,863 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:13:16,881 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:13:16,910 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:13:16,942 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:13:16,977 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:13:16,980 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:13:16,990 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:13:17,029 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:13:17,046 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:13:17,052 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:13:17,058 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:13:17,067 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:13:17,073 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:13:17,074 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:13:17,090 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:13:17,097 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:13:17,113 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:13:17,133 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:13:17,136 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:13:17,139 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:13:17,144 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:13:17,163 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:13:17,170 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:13:17,173 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:13:17,176 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:13:17,179 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:13:17,184 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:13:17,186 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:13:17,189 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:13:17,204 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:13:17,207 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:13:17,208 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:13:17,210 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:13:17,212 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:13:17,214 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:13:17,216 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:13:17,217 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:13:17,219 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:13:17,229 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:13:17,232 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:13:17,237 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:13:17,243 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:13:17,248 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:13:17,257 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:13:17,259 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:13:17,264 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:13:17,269 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:13:17,277 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:13:17,284 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:13:17,287 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:13:17,288 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:13:17,558 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:17,571 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:13:17,780 - INFO - 第 3 折评估完成: NPMI=0.4864, Diversity=0.4400, Optimal Score=0.4632\n",
      "实验进度:  88%|████████▊ | 53/60 [02:45<00:23,  3.37s/it]2024-11-24 21:13:17,784 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:17,943 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:13:17,943 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:13:17.943901', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:17,947 - INFO - discarding 7485 tokens: [('apocalypsis', 14), ('element', 6), ('grando', 3), ('principalis', 16), ('specialis', 12), ('terraemotus', 3), ('anatomia', 1), ('caesarius', 10), ('capitaneus', 11), ('carnalitas', 7)]...\n",
      "2024-11-24 21:13:17,947 - INFO - keeping 1400 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:17,949 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:13:17,949 - INFO - 词典过滤: 8885 -> 1400 个词\n",
      "2024-11-24 21:13:18,003 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:18,003 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:18,005 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:18,006 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:18,006 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:18,007 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:18,406 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:18,407 - INFO - topic #8 (0.067): 0.020*\"christus\" + 0.020*\"lux\" + 0.011*\"virtus\" + 0.010*\"verbum\" + 0.009*\"filius\" + 0.009*\"venio\" + 0.009*\"iudico\" + 0.008*\"rex\" + 0.008*\"petrus\" + 0.008*\"intellectus\"\n",
      "2024-11-24 21:13:18,408 - INFO - topic #7 (0.067): 0.023*\"christus\" + 0.022*\"vita\" + 0.015*\"filius\" + 0.014*\"homo\" + 0.014*\"mundus\" + 0.012*\"verbum\" + 0.010*\"spiritus\" + 0.009*\"panis\" + 0.009*\"delphi\" + 0.007*\"pater\"\n",
      "2024-11-24 21:13:18,408 - INFO - topic #5 (0.067): 0.042*\"und\" + 0.023*\"dies\" + 0.021*\"pater\" + 0.020*\"christus\" + 0.018*\"spiritus\" + 0.017*\"is\" + 0.015*\"filius\" + 0.014*\"verbum\" + 0.013*\"homo\" + 0.011*\"vita\"\n",
      "2024-11-24 21:13:18,408 - INFO - topic #14 (0.067): 0.036*\"und\" + 0.029*\"dies\" + 0.011*\"gratia\" + 0.010*\"filius\" + 0.010*\"mo\" + 0.009*\"delphi\" + 0.008*\"lux\" + 0.008*\"forma\" + 0.007*\"nichtestis\" + 0.007*\"homo\"\n",
      "2024-11-24 21:13:18,409 - INFO - topic #1 (0.067): 0.028*\"homo\" + 0.021*\"christus\" + 0.012*\"veritas\" + 0.012*\"natura\" + 0.011*\"verbum\" + 0.010*\"vita\" + 0.010*\"spiritus\" + 0.009*\"sapientia\" + 0.008*\"delphi\" + 0.008*\"filius\"\n",
      "2024-11-24 21:13:18,409 - INFO - topic diff=2.501997, rho=1.000000\n",
      "2024-11-24 21:13:18,812 - INFO - -6.921 per-word bound, 121.2 perplexity estimate based on a held-out corpus of 1716 documents with 81787 words\n",
      "2024-11-24 21:13:18,812 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:19,147 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:19,148 - INFO - topic #5 (0.067): 0.039*\"pater\" + 0.037*\"dies\" + 0.026*\"und\" + 0.023*\"filius\" + 0.020*\"christus\" + 0.016*\"verbum\" + 0.015*\"spiritus\" + 0.012*\"homo\" + 0.011*\"is\" + 0.010*\"mundus\"\n",
      "2024-11-24 21:13:19,148 - INFO - topic #2 (0.067): 0.022*\"homo\" + 0.018*\"natura\" + 0.018*\"gratia\" + 0.017*\"virtus\" + 0.017*\"ars\" + 0.016*\"verbum\" + 0.013*\"intellectus\" + 0.012*\"imago\" + 0.012*\"filius\" + 0.011*\"creo\"\n",
      "2024-11-24 21:13:19,148 - INFO - topic #14 (0.067): 0.096*\"dies\" + 0.019*\"annus\" + 0.014*\"und\" + 0.011*\"gratia\" + 0.011*\"dacia\" + 0.010*\"sirenes\" + 0.010*\"octavus\" + 0.010*\"mensis\" + 0.008*\"sufficio\" + 0.008*\"hoffnung\"\n",
      "2024-11-24 21:13:19,149 - INFO - topic #8 (0.067): 0.031*\"lux\" + 0.022*\"christus\" + 0.011*\"sol\" + 0.010*\"venio\" + 0.010*\"mitto\" + 0.009*\"iudico\" + 0.009*\"filius\" + 0.009*\"tenebrae\" + 0.009*\"verbum\" + 0.008*\"petrus\"\n",
      "2024-11-24 21:13:19,149 - INFO - topic #0 (0.067): 0.035*\"nomen\" + 0.022*\"fides\" + 0.016*\"verbum\" + 0.015*\"christus\" + 0.011*\"gegen\" + 0.011*\"debeo\" + 0.010*\"dominus\" + 0.009*\"ratio\" + 0.008*\"ordo\" + 0.007*\"scribo\"\n",
      "2024-11-24 21:13:19,149 - INFO - topic diff=0.843534, rho=0.707107\n",
      "2024-11-24 21:13:19,150 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.14s', 'datetime': '2024-11-24T21:13:19.150324', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:19,153 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:19,313 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:13:19,333 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:13:19,358 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:13:19,361 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:13:19,363 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:13:19,365 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:13:19,367 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:13:20,249 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:13:20,268 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:13:20,278 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:13:20,284 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:13:20,298 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:13:20,314 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:13:20,328 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:13:20,333 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:13:20,335 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:13:20,337 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:13:20,339 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:13:20,340 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:13:20,342 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:13:20,346 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:13:20,360 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:13:20,368 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:13:20,371 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:13:20,372 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:13:20,375 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:13:20,383 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:13:20,385 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:13:20,389 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:13:20,392 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:13:20,394 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:13:20,413 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:13:20,417 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:13:20,421 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:13:20,422 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:13:20,429 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:13:20,468 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:13:20,612 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:13:20,616 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:13:20,617 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:13:20,618 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:13:20,620 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:13:20,626 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:13:20,645 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:13:20,651 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:13:20,667 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:13:20,670 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:13:20,675 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:13:20,676 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:13:20,685 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:13:20,693 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:13:20,695 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:13:20,705 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:13:20,714 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:13:20,727 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:13:20,751 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:13:20,762 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:13:20,766 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:13:20,782 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:13:20,849 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:20,866 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:13:21,152 - INFO - 第 4 折评估完成: NPMI=0.4851, Diversity=0.4600, Optimal Score=0.4725\n",
      "实验进度:  90%|█████████ | 54/60 [02:48<00:20,  3.37s/it]2024-11-24 21:13:21,155 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:21,260 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:13:21,261 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:13:21.261339', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:21,265 - INFO - discarding 7503 tokens: [('apocalypsis', 15), ('element', 9), ('grando', 7), ('principalis', 16), ('specialis', 11), ('terraemotus', 5), ('aaron', 5), ('asper', 10), ('correctio', 17), ('expositio', 12)]...\n",
      "2024-11-24 21:13:21,266 - INFO - keeping 1400 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:21,268 - INFO - resulting dictionary: Dictionary<1400 unique tokens: ['appareo', 'behalten', 'constantinus', 'corona', 'dominus']...>\n",
      "2024-11-24 21:13:21,269 - INFO - 词典过滤: 8903 -> 1400 个词\n",
      "2024-11-24 21:13:21,341 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:21,342 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:21,343 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:21,344 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:21,345 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:21,346 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:21,827 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:21,829 - INFO - topic #8 (0.067): 0.022*\"filius\" + 0.021*\"spiritus\" + 0.018*\"homo\" + 0.014*\"larissa\" + 0.013*\"christus\" + 0.013*\"natura\" + 0.011*\"corpus\" + 0.011*\"regnum\" + 0.010*\"unio\" + 0.010*\"locus\"\n",
      "2024-11-24 21:13:21,829 - INFO - topic #7 (0.067): 0.030*\"christus\" + 0.023*\"virtus\" + 0.019*\"vita\" + 0.014*\"homo\" + 0.014*\"amor\" + 0.014*\"delphi\" + 0.013*\"pater\" + 0.013*\"filius\" + 0.009*\"spiritus\" + 0.008*\"verbum\"\n",
      "2024-11-24 21:13:21,829 - INFO - topic #5 (0.067): 0.051*\"und\" + 0.026*\"dies\" + 0.019*\"wir\" + 0.016*\"homo\" + 0.013*\"christus\" + 0.012*\"is\" + 0.012*\"verbum\" + 0.011*\"debeo\" + 0.011*\"got\" + 0.010*\"natura\"\n",
      "2024-11-24 21:13:21,830 - INFO - topic #14 (0.067): 0.022*\"christus\" + 0.015*\"pater\" + 0.013*\"venio\" + 0.013*\"rex\" + 0.011*\"pax\" + 0.010*\"filius\" + 0.009*\"homo\" + 0.008*\"delphi\" + 0.007*\"spiritus\" + 0.007*\"vinco\"\n",
      "2024-11-24 21:13:21,830 - INFO - topic #1 (0.067): 0.022*\"christus\" + 0.018*\"pater\" + 0.012*\"filius\" + 0.011*\"sanctus\" + 0.011*\"dominus\" + 0.011*\"virtus\" + 0.010*\"spiritus\" + 0.010*\"verbum\" + 0.009*\"natura\" + 0.007*\"homo\"\n",
      "2024-11-24 21:13:21,830 - INFO - topic diff=2.415692, rho=1.000000\n",
      "2024-11-24 21:13:22,237 - INFO - -6.939 per-word bound, 122.7 perplexity estimate based on a held-out corpus of 1716 documents with 82495 words\n",
      "2024-11-24 21:13:22,237 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:22,558 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:22,559 - INFO - topic #5 (0.067): 0.058*\"dies\" + 0.039*\"und\" + 0.014*\"wir\" + 0.013*\"homo\" + 0.012*\"christus\" + 0.011*\"verbum\" + 0.010*\"natura\" + 0.010*\"is\" + 0.010*\"debeo\" + 0.008*\"semen\"\n",
      "2024-11-24 21:13:22,560 - INFO - topic #2 (0.067): 0.028*\"verbum\" + 0.025*\"nomen\" + 0.018*\"intellectus\" + 0.016*\"vita\" + 0.013*\"lux\" + 0.011*\"divinus\" + 0.010*\"principium\" + 0.010*\"gegen\" + 0.010*\"virtus\" + 0.010*\"delphi\"\n",
      "2024-11-24 21:13:22,560 - INFO - topic #14 (0.067): 0.022*\"christus\" + 0.015*\"pater\" + 0.012*\"sirenes\" + 0.012*\"pax\" + 0.012*\"homo\" + 0.011*\"venio\" + 0.011*\"filius\" + 0.011*\"rex\" + 0.010*\"nomen\" + 0.008*\"virgo\"\n",
      "2024-11-24 21:13:22,561 - INFO - topic #8 (0.067): 0.022*\"larissa\" + 0.020*\"homo\" + 0.020*\"natura\" + 0.019*\"filius\" + 0.016*\"spiritus\" + 0.013*\"locus\" + 0.013*\"unio\" + 0.012*\"corpus\" + 0.012*\"regnum\" + 0.011*\"christus\"\n",
      "2024-11-24 21:13:22,561 - INFO - topic #0 (0.067): 0.041*\"fides\" + 0.022*\"spiritus\" + 0.022*\"verbum\" + 0.016*\"christus\" + 0.014*\"volo\" + 0.014*\"ratio\" + 0.014*\"homo\" + 0.013*\"credo\" + 0.011*\"delphi\" + 0.011*\"vita\"\n",
      "2024-11-24 21:13:22,561 - INFO - topic diff=0.810077, rho=0.707107\n",
      "2024-11-24 21:13:22,561 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=1400, num_topics=15, decay=0.5, chunksize=2000> in 1.22s', 'datetime': '2024-11-24T21:13:22.561981', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:22,564 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:22,613 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:13:22,650 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:13:22,699 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:13:22,762 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:13:22,765 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:13:22,766 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:13:22,767 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:13:23,574 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:13:23,592 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:13:23,612 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:13:23,630 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:13:23,644 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:13:23,646 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:13:23,679 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:13:23,715 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:13:23,717 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:13:23,719 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:13:23,722 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:13:23,724 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:13:23,725 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:13:23,726 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:13:23,765 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:13:23,766 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:13:23,775 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:13:23,778 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:13:23,782 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:13:23,784 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:13:23,795 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:13:23,803 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:13:23,805 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:13:23,816 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:13:23,823 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:13:23,827 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:13:23,832 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:13:23,835 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:13:23,837 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:13:23,860 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:13:23,866 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:13:23,868 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:13:23,870 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:13:23,881 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:13:23,882 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:13:23,884 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:13:23,889 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:13:23,909 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:13:23,920 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:13:23,928 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:13:23,930 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:13:23,932 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:13:23,937 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:13:23,944 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:13:23,958 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:13:23,966 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:13:23,968 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:13:23,970 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:13:23,971 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:13:23,973 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:13:23,977 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:13:23,989 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:13:24,257 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:24,276 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:13:24,485 - INFO - 第 5 折评估完成: NPMI=0.4889, Diversity=0.4400, Optimal Score=0.4644\n",
      "实验进度:  92%|█████████▏| 55/60 [02:52<00:16,  3.36s/it]2024-11-24 21:13:24,486 - INFO - \n",
      "评估阈值组合: min_freq=4, max_freq=2000\n",
      "2024-11-24 21:13:24,489 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:24,674 - INFO - built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\n",
      "2024-11-24 21:13:24,675 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8839 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216188 corpus positions)\", 'datetime': '2024-11-24T21:13:24.675262', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:24,678 - INFO - discarding 6839 tokens: [('element', 9), ('grando', 6), ('terraemotus', 5), ('aaron', 7), ('asper', 9), ('latus', 7), ('leichnam', 3), ('noe', 10), ('perforo', 7), ('phoenica', 11)]...\n",
      "2024-11-24 21:13:24,679 - INFO - keeping 2000 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:24,680 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:13:24,681 - INFO - 词典过滤: 8839 -> 2000 个词\n",
      "2024-11-24 21:13:24,735 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:24,735 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:24,736 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:24,737 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:24,741 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:24,748 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:25,168 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:25,169 - INFO - topic #0 (0.067): 0.023*\"vita\" + 0.022*\"christus\" + 0.021*\"spiritus\" + 0.019*\"pater\" + 0.014*\"filius\" + 0.010*\"veritas\" + 0.008*\"sanctus\" + 0.008*\"venio\" + 0.008*\"verbum\" + 0.007*\"cognosco\"\n",
      "2024-11-24 21:13:25,170 - INFO - topic #8 (0.067): 0.024*\"spiritus\" + 0.020*\"christus\" + 0.016*\"verbum\" + 0.015*\"vita\" + 0.012*\"intellectus\" + 0.012*\"fides\" + 0.009*\"symbatios\" + 0.009*\"panis\" + 0.007*\"cognosco\" + 0.007*\"lex\"\n",
      "2024-11-24 21:13:25,170 - INFO - topic #14 (0.067): 0.021*\"vita\" + 0.016*\"fides\" + 0.013*\"spiritus\" + 0.012*\"delphi\" + 0.011*\"gegen\" + 0.010*\"christus\" + 0.009*\"venio\" + 0.008*\"mundus\" + 0.008*\"homo\" + 0.008*\"symbatios\"\n",
      "2024-11-24 21:13:25,170 - INFO - topic #1 (0.067): 0.033*\"christus\" + 0.021*\"und\" + 0.015*\"fides\" + 0.014*\"mundus\" + 0.013*\"regnum\" + 0.012*\"dies\" + 0.011*\"filius\" + 0.010*\"verbum\" + 0.009*\"wir\" + 0.008*\"homo\"\n",
      "2024-11-24 21:13:25,171 - INFO - topic #3 (0.067): 0.037*\"spiritus\" + 0.019*\"vita\" + 0.015*\"lux\" + 0.014*\"mors\" + 0.013*\"delphi\" + 0.013*\"christus\" + 0.009*\"mundus\" + 0.008*\"filius\" + 0.008*\"verbum\" + 0.008*\"sanctus\"\n",
      "2024-11-24 21:13:25,171 - INFO - topic diff=3.569692, rho=1.000000\n",
      "2024-11-24 21:13:25,582 - INFO - -7.230 per-word bound, 150.2 perplexity estimate based on a held-out corpus of 1716 documents with 87656 words\n",
      "2024-11-24 21:13:25,583 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:25,907 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:25,909 - INFO - topic #11 (0.067): 0.019*\"christus\" + 0.017*\"rex\" + 0.013*\"homo\" + 0.013*\"locus\" + 0.012*\"corpus\" + 0.012*\"delphi\" + 0.011*\"peccatum\" + 0.011*\"natura\" + 0.010*\"ratio\" + 0.008*\"venio\"\n",
      "2024-11-24 21:13:25,909 - INFO - topic #3 (0.067): 0.048*\"spiritus\" + 0.028*\"lux\" + 0.023*\"mors\" + 0.019*\"vita\" + 0.018*\"delphi\" + 0.014*\"tenebrae\" + 0.014*\"christus\" + 0.009*\"verbum\" + 0.009*\"sanctus\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:13:25,910 - INFO - topic #14 (0.067): 0.024*\"vita\" + 0.021*\"fides\" + 0.014*\"delphi\" + 0.013*\"symbatios\" + 0.013*\"gegen\" + 0.011*\"clotho\" + 0.010*\"spiritus\" + 0.010*\"iustitia\" + 0.008*\"christus\" + 0.008*\"homo\"\n",
      "2024-11-24 21:13:25,910 - INFO - topic #7 (0.067): 0.026*\"homo\" + 0.022*\"verbum\" + 0.019*\"filius\" + 0.017*\"christus\" + 0.017*\"natura\" + 0.016*\"pater\" + 0.015*\"spiritus\" + 0.013*\"vita\" + 0.010*\"larissa\" + 0.009*\"mundus\"\n",
      "2024-11-24 21:13:25,910 - INFO - topic #0 (0.067): 0.028*\"christus\" + 0.025*\"vita\" + 0.023*\"pater\" + 0.020*\"spiritus\" + 0.016*\"filius\" + 0.014*\"veritas\" + 0.012*\"nomen\" + 0.011*\"sanctus\" + 0.010*\"venio\" + 0.009*\"credo\"\n",
      "2024-11-24 21:13:25,911 - INFO - topic diff=0.968955, rho=0.707107\n",
      "2024-11-24 21:13:25,911 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.17s', 'datetime': '2024-11-24T21:13:25.911391', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:25,914 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:26,410 - INFO - 1 batches submitted to accumulate stats from 64 documents (2817 virtual)\n",
      "2024-11-24 21:13:26,414 - INFO - 2 batches submitted to accumulate stats from 128 documents (5315 virtual)\n",
      "2024-11-24 21:13:26,416 - INFO - 3 batches submitted to accumulate stats from 192 documents (8308 virtual)\n",
      "2024-11-24 21:13:26,417 - INFO - 4 batches submitted to accumulate stats from 256 documents (11133 virtual)\n",
      "2024-11-24 21:13:26,419 - INFO - 5 batches submitted to accumulate stats from 320 documents (14795 virtual)\n",
      "2024-11-24 21:13:26,420 - INFO - 6 batches submitted to accumulate stats from 384 documents (17376 virtual)\n",
      "2024-11-24 21:13:26,421 - INFO - 7 batches submitted to accumulate stats from 448 documents (20991 virtual)\n",
      "2024-11-24 21:13:27,101 - INFO - 8 batches submitted to accumulate stats from 512 documents (24125 virtual)\n",
      "2024-11-24 21:13:27,148 - INFO - 9 batches submitted to accumulate stats from 576 documents (27138 virtual)\n",
      "2024-11-24 21:13:27,173 - INFO - 10 batches submitted to accumulate stats from 640 documents (31580 virtual)\n",
      "2024-11-24 21:13:27,200 - INFO - 11 batches submitted to accumulate stats from 704 documents (34391 virtual)\n",
      "2024-11-24 21:13:27,219 - INFO - 12 batches submitted to accumulate stats from 768 documents (36751 virtual)\n",
      "2024-11-24 21:13:27,226 - INFO - 13 batches submitted to accumulate stats from 832 documents (38570 virtual)\n",
      "2024-11-24 21:13:27,227 - INFO - 14 batches submitted to accumulate stats from 896 documents (41243 virtual)\n",
      "2024-11-24 21:13:27,228 - INFO - 15 batches submitted to accumulate stats from 960 documents (45159 virtual)\n",
      "2024-11-24 21:13:27,255 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47914 virtual)\n",
      "2024-11-24 21:13:27,287 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51923 virtual)\n",
      "2024-11-24 21:13:27,301 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54862 virtual)\n",
      "2024-11-24 21:13:27,304 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57770 virtual)\n",
      "2024-11-24 21:13:27,310 - INFO - 20 batches submitted to accumulate stats from 1280 documents (61819 virtual)\n",
      "2024-11-24 21:13:27,313 - INFO - 21 batches submitted to accumulate stats from 1344 documents (64614 virtual)\n",
      "2024-11-24 21:13:27,317 - INFO - 22 batches submitted to accumulate stats from 1408 documents (68096 virtual)\n",
      "2024-11-24 21:13:27,319 - INFO - 23 batches submitted to accumulate stats from 1472 documents (71631 virtual)\n",
      "2024-11-24 21:13:27,351 - INFO - 24 batches submitted to accumulate stats from 1536 documents (74369 virtual)\n",
      "2024-11-24 21:13:27,374 - INFO - 25 batches submitted to accumulate stats from 1600 documents (78231 virtual)\n",
      "2024-11-24 21:13:27,462 - INFO - 26 batches submitted to accumulate stats from 1664 documents (81817 virtual)\n",
      "2024-11-24 21:13:27,578 - INFO - 27 batches submitted to accumulate stats from 1728 documents (84598 virtual)\n",
      "2024-11-24 21:13:27,600 - INFO - 28 batches submitted to accumulate stats from 1792 documents (87196 virtual)\n",
      "2024-11-24 21:13:27,603 - INFO - 29 batches submitted to accumulate stats from 1856 documents (90961 virtual)\n",
      "2024-11-24 21:13:27,609 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93789 virtual)\n",
      "2024-11-24 21:13:27,611 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96681 virtual)\n",
      "2024-11-24 21:13:27,618 - INFO - 32 batches submitted to accumulate stats from 2048 documents (99395 virtual)\n",
      "2024-11-24 21:13:27,648 - INFO - 33 batches submitted to accumulate stats from 2112 documents (103597 virtual)\n",
      "2024-11-24 21:13:27,655 - INFO - 34 batches submitted to accumulate stats from 2176 documents (106491 virtual)\n",
      "2024-11-24 21:13:27,663 - INFO - 35 batches submitted to accumulate stats from 2240 documents (109057 virtual)\n",
      "2024-11-24 21:13:27,667 - INFO - 36 batches submitted to accumulate stats from 2304 documents (111642 virtual)\n",
      "2024-11-24 21:13:27,672 - INFO - 37 batches submitted to accumulate stats from 2368 documents (114440 virtual)\n",
      "2024-11-24 21:13:27,676 - INFO - 38 batches submitted to accumulate stats from 2432 documents (119189 virtual)\n",
      "2024-11-24 21:13:27,688 - INFO - 39 batches submitted to accumulate stats from 2496 documents (122083 virtual)\n",
      "2024-11-24 21:13:27,701 - INFO - 40 batches submitted to accumulate stats from 2560 documents (125150 virtual)\n",
      "2024-11-24 21:13:27,704 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128710 virtual)\n",
      "2024-11-24 21:13:27,712 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131496 virtual)\n",
      "2024-11-24 21:13:27,714 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134612 virtual)\n",
      "2024-11-24 21:13:27,718 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138970 virtual)\n",
      "2024-11-24 21:13:27,727 - INFO - 45 batches submitted to accumulate stats from 2880 documents (142138 virtual)\n",
      "2024-11-24 21:13:27,729 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145562 virtual)\n",
      "2024-11-24 21:13:27,731 - INFO - 47 batches submitted to accumulate stats from 3008 documents (149443 virtual)\n",
      "2024-11-24 21:13:27,745 - INFO - 48 batches submitted to accumulate stats from 3072 documents (151315 virtual)\n",
      "2024-11-24 21:13:27,751 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153950 virtual)\n",
      "2024-11-24 21:13:27,752 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157577 virtual)\n",
      "2024-11-24 21:13:27,754 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160949 virtual)\n",
      "2024-11-24 21:13:27,758 - INFO - 52 batches submitted to accumulate stats from 3328 documents (164004 virtual)\n",
      "2024-11-24 21:13:27,762 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166363 virtual)\n",
      "2024-11-24 21:13:27,771 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168977 virtual)\n",
      "2024-11-24 21:13:27,794 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172267 virtual)\n",
      "2024-11-24 21:13:27,796 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175085 virtual)\n",
      "2024-11-24 21:13:27,799 - INFO - 57 batches submitted to accumulate stats from 3648 documents (177870 virtual)\n",
      "2024-11-24 21:13:27,802 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182572 virtual)\n",
      "2024-11-24 21:13:27,806 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182744 virtual)\n",
      "2024-11-24 21:13:28,014 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:28,224 - INFO - accumulated word occurrence stats for 182942 virtual documents\n",
      "2024-11-24 21:13:28,397 - INFO - 第 1 折评估完成: NPMI=0.4849, Diversity=0.4400, Optimal Score=0.4625\n",
      "实验进度:  93%|█████████▎| 56/60 [02:56<00:14,  3.53s/it]2024-11-24 21:13:28,402 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:28,497 - INFO - built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\n",
      "2024-11-24 21:13:28,498 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8896 unique tokens: ['aaron', 'ada', 'aqua', 'asper', 'bonus']...> from 3716 documents (total 215072 corpus positions)\", 'datetime': '2024-11-24T21:13:28.498202', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:28,502 - INFO - discarding 6896 tokens: [('aaron', 7), ('asper', 8), ('element', 7), ('grando', 6), ('latus', 7), ('leichnam', 2), ('perforo', 5), ('phoenica', 10), ('potestativus', 1), ('primitivus', 3)]...\n",
      "2024-11-24 21:13:28,502 - INFO - keeping 2000 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:28,503 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['ada', 'aqua', 'bonus', 'christus', 'conservo']...>\n",
      "2024-11-24 21:13:28,504 - INFO - 词典过滤: 8896 -> 2000 个词\n",
      "2024-11-24 21:13:28,557 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:28,557 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:28,558 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:28,560 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:28,560 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:28,560 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:28,973 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:28,975 - INFO - topic #0 (0.067): 0.028*\"vita\" + 0.020*\"delphi\" + 0.016*\"corpus\" + 0.013*\"spiritus\" + 0.010*\"christus\" + 0.008*\"virtus\" + 0.008*\"nomen\" + 0.008*\"vivo\" + 0.008*\"pulchritudo\" + 0.007*\"verbum\"\n",
      "2024-11-24 21:13:28,975 - INFO - topic #8 (0.067): 0.020*\"christus\" + 0.013*\"pater\" + 0.013*\"intellectus\" + 0.012*\"volo\" + 0.011*\"filius\" + 0.011*\"vita\" + 0.009*\"intellego\" + 0.009*\"mors\" + 0.008*\"verbum\" + 0.008*\"fides\"\n",
      "2024-11-24 21:13:28,975 - INFO - topic #14 (0.067): 0.016*\"christus\" + 0.014*\"debeo\" + 0.012*\"rex\" + 0.010*\"homo\" + 0.010*\"dies\" + 0.010*\"vita\" + 0.007*\"cognosco\" + 0.007*\"volo\" + 0.006*\"dominus\" + 0.006*\"veritas\"\n",
      "2024-11-24 21:13:28,976 - INFO - topic #1 (0.067): 0.015*\"christus\" + 0.014*\"verbum\" + 0.013*\"rex\" + 0.013*\"homo\" + 0.012*\"spiritus\" + 0.009*\"vita\" + 0.009*\"larissa\" + 0.009*\"sapientia\" + 0.008*\"pater\" + 0.008*\"oboedio\"\n",
      "2024-11-24 21:13:28,976 - INFO - topic #3 (0.067): 0.031*\"christus\" + 0.015*\"und\" + 0.014*\"dies\" + 0.013*\"uns\" + 0.012*\"lex\" + 0.011*\"wir\" + 0.009*\"unser\" + 0.009*\"fides\" + 0.009*\"amor\" + 0.008*\"finis\"\n",
      "2024-11-24 21:13:28,976 - INFO - topic diff=3.533654, rho=1.000000\n",
      "2024-11-24 21:13:29,471 - INFO - -7.234 per-word bound, 150.6 perplexity estimate based on a held-out corpus of 1716 documents with 87826 words\n",
      "2024-11-24 21:13:29,471 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:29,803 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:29,804 - INFO - topic #11 (0.067): 0.036*\"christus\" + 0.035*\"veritas\" + 0.015*\"vita\" + 0.010*\"via\" + 0.010*\"verus\" + 0.009*\"filius\" + 0.008*\"mundus\" + 0.008*\"intellectus\" + 0.008*\"venio\" + 0.008*\"mors\"\n",
      "2024-11-24 21:13:29,805 - INFO - topic #3 (0.067): 0.046*\"dies\" + 0.033*\"lex\" + 0.032*\"christus\" + 0.025*\"annus\" + 0.012*\"sabbatum\" + 0.011*\"iesse\" + 0.010*\"primus\" + 0.010*\"finis\" + 0.008*\"abraham\" + 0.008*\"ecclesia\"\n",
      "2024-11-24 21:13:29,805 - INFO - topic #14 (0.067): 0.020*\"christus\" + 0.018*\"dies\" + 0.016*\"debeo\" + 0.010*\"annus\" + 0.009*\"dominus\" + 0.008*\"homo\" + 0.008*\"rex\" + 0.007*\"volo\" + 0.007*\"dimitto\" + 0.006*\"sanctus\"\n",
      "2024-11-24 21:13:29,805 - INFO - topic #7 (0.067): 0.030*\"spiritus\" + 0.019*\"virtus\" + 0.017*\"vita\" + 0.016*\"ars\" + 0.015*\"delphi\" + 0.013*\"amor\" + 0.012*\"sanctus\" + 0.012*\"motus\" + 0.009*\"natura\" + 0.009*\"imago\"\n",
      "2024-11-24 21:13:29,806 - INFO - topic #0 (0.067): 0.034*\"vita\" + 0.025*\"delphi\" + 0.020*\"corpus\" + 0.015*\"nomen\" + 0.011*\"spiritus\" + 0.009*\"vivo\" + 0.009*\"christus\" + 0.008*\"amor\" + 0.008*\"gloria\" + 0.008*\"dominus\"\n",
      "2024-11-24 21:13:29,806 - INFO - topic diff=1.005497, rho=0.707107\n",
      "2024-11-24 21:13:29,806 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.25s', 'datetime': '2024-11-24T21:13:29.806793', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:29,809 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:30,248 - INFO - 1 batches submitted to accumulate stats from 64 documents (2623 virtual)\n",
      "2024-11-24 21:13:30,250 - INFO - 2 batches submitted to accumulate stats from 128 documents (4778 virtual)\n",
      "2024-11-24 21:13:30,251 - INFO - 3 batches submitted to accumulate stats from 192 documents (7683 virtual)\n",
      "2024-11-24 21:13:30,252 - INFO - 4 batches submitted to accumulate stats from 256 documents (10225 virtual)\n",
      "2024-11-24 21:13:30,253 - INFO - 5 batches submitted to accumulate stats from 320 documents (13593 virtual)\n",
      "2024-11-24 21:13:30,253 - INFO - 6 batches submitted to accumulate stats from 384 documents (16124 virtual)\n",
      "2024-11-24 21:13:30,255 - INFO - 7 batches submitted to accumulate stats from 448 documents (20255 virtual)\n",
      "2024-11-24 21:13:30,823 - INFO - 8 batches submitted to accumulate stats from 512 documents (22775 virtual)\n",
      "2024-11-24 21:13:30,843 - INFO - 9 batches submitted to accumulate stats from 576 documents (26040 virtual)\n",
      "2024-11-24 21:13:30,887 - INFO - 10 batches submitted to accumulate stats from 640 documents (29739 virtual)\n",
      "2024-11-24 21:13:30,918 - INFO - 11 batches submitted to accumulate stats from 704 documents (33426 virtual)\n",
      "2024-11-24 21:13:30,960 - INFO - 12 batches submitted to accumulate stats from 768 documents (36203 virtual)\n",
      "2024-11-24 21:13:31,003 - INFO - 13 batches submitted to accumulate stats from 832 documents (38022 virtual)\n",
      "2024-11-24 21:13:31,006 - INFO - 14 batches submitted to accumulate stats from 896 documents (39972 virtual)\n",
      "2024-11-24 21:13:31,029 - INFO - 15 batches submitted to accumulate stats from 960 documents (42998 virtual)\n",
      "2024-11-24 21:13:31,142 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46822 virtual)\n",
      "2024-11-24 21:13:31,180 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50338 virtual)\n",
      "2024-11-24 21:13:31,202 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54184 virtual)\n",
      "2024-11-24 21:13:31,229 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56671 virtual)\n",
      "2024-11-24 21:13:31,236 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60010 virtual)\n",
      "2024-11-24 21:13:31,241 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63252 virtual)\n",
      "2024-11-24 21:13:31,252 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66577 virtual)\n",
      "2024-11-24 21:13:31,261 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70713 virtual)\n",
      "2024-11-24 21:13:31,264 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73000 virtual)\n",
      "2024-11-24 21:13:31,273 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77018 virtual)\n",
      "2024-11-24 21:13:31,275 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80546 virtual)\n",
      "2024-11-24 21:13:31,277 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83538 virtual)\n",
      "2024-11-24 21:13:31,293 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85932 virtual)\n",
      "2024-11-24 21:13:31,299 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89379 virtual)\n",
      "2024-11-24 21:13:31,303 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92509 virtual)\n",
      "2024-11-24 21:13:31,329 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95382 virtual)\n",
      "2024-11-24 21:13:31,330 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97898 virtual)\n",
      "2024-11-24 21:13:31,336 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101669 virtual)\n",
      "2024-11-24 21:13:31,340 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104648 virtual)\n",
      "2024-11-24 21:13:31,343 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107435 virtual)\n",
      "2024-11-24 21:13:31,351 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109874 virtual)\n",
      "2024-11-24 21:13:31,353 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112670 virtual)\n",
      "2024-11-24 21:13:31,362 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117517 virtual)\n",
      "2024-11-24 21:13:31,371 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120261 virtual)\n",
      "2024-11-24 21:13:31,372 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123283 virtual)\n",
      "2024-11-24 21:13:31,375 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126760 virtual)\n",
      "2024-11-24 21:13:31,379 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129481 virtual)\n",
      "2024-11-24 21:13:31,402 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132933 virtual)\n",
      "2024-11-24 21:13:31,405 - INFO - 44 batches submitted to accumulate stats from 2816 documents (137233 virtual)\n",
      "2024-11-24 21:13:31,407 - INFO - 45 batches submitted to accumulate stats from 2880 documents (140053 virtual)\n",
      "2024-11-24 21:13:31,421 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143508 virtual)\n",
      "2024-11-24 21:13:31,429 - INFO - 47 batches submitted to accumulate stats from 3008 documents (147081 virtual)\n",
      "2024-11-24 21:13:31,432 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148972 virtual)\n",
      "2024-11-24 21:13:31,434 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151888 virtual)\n",
      "2024-11-24 21:13:31,437 - INFO - 50 batches submitted to accumulate stats from 3200 documents (156076 virtual)\n",
      "2024-11-24 21:13:31,447 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159472 virtual)\n",
      "2024-11-24 21:13:31,454 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162384 virtual)\n",
      "2024-11-24 21:13:31,459 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164887 virtual)\n",
      "2024-11-24 21:13:31,468 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167320 virtual)\n",
      "2024-11-24 21:13:31,470 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170921 virtual)\n",
      "2024-11-24 21:13:31,490 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173690 virtual)\n",
      "2024-11-24 21:13:31,495 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176733 virtual)\n",
      "2024-11-24 21:13:31,499 - INFO - 58 batches submitted to accumulate stats from 3712 documents (181243 virtual)\n",
      "2024-11-24 21:13:31,500 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181628 virtual)\n",
      "2024-11-24 21:13:31,832 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:31,841 - INFO - accumulated word occurrence stats for 181846 virtual documents\n",
      "2024-11-24 21:13:32,026 - INFO - 第 2 折评估完成: NPMI=0.4907, Diversity=0.4400, Optimal Score=0.4653\n",
      "实验进度:  95%|█████████▌| 57/60 [02:59<00:10,  3.56s/it]2024-11-24 21:13:32,028 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:32,121 - INFO - built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\n",
      "2024-11-24 21:13:32,121 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8834 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 213289 corpus positions)\", 'datetime': '2024-11-24T21:13:32.121897', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:32,125 - INFO - discarding 6834 tokens: [('element', 9), ('grando', 6), ('terraemotus', 6), ('aaron', 8), ('asper', 9), ('latus', 7), ('leichnam', 2), ('noe', 10), ('perforo', 8), ('potestativus', 2)]...\n",
      "2024-11-24 21:13:32,125 - INFO - keeping 2000 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:32,127 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:13:32,127 - INFO - 词典过滤: 8834 -> 2000 个词\n",
      "2024-11-24 21:13:32,283 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:32,284 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:32,284 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:32,286 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:32,286 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:32,287 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:32,708 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:32,709 - INFO - topic #0 (0.067): 0.026*\"christus\" + 0.017*\"und\" + 0.012*\"virtus\" + 0.010*\"spiritus\" + 0.009*\"natura\" + 0.009*\"rex\" + 0.008*\"dies\" + 0.007*\"imago\" + 0.007*\"homo\" + 0.007*\"filius\"\n",
      "2024-11-24 21:13:32,710 - INFO - topic #8 (0.067): 0.022*\"delphi\" + 0.017*\"christus\" + 0.016*\"vita\" + 0.014*\"verbum\" + 0.009*\"spiritus\" + 0.009*\"amor\" + 0.009*\"sapientia\" + 0.009*\"fides\" + 0.008*\"pater\" + 0.008*\"ratio\"\n",
      "2024-11-24 21:13:32,710 - INFO - topic #14 (0.067): 0.021*\"vita\" + 0.020*\"homo\" + 0.017*\"sapientia\" + 0.014*\"spiritus\" + 0.011*\"venio\" + 0.009*\"christus\" + 0.009*\"mundus\" + 0.009*\"ratio\" + 0.008*\"amor\" + 0.007*\"scio\"\n",
      "2024-11-24 21:13:32,710 - INFO - topic #1 (0.067): 0.029*\"christus\" + 0.018*\"vita\" + 0.016*\"filius\" + 0.016*\"homo\" + 0.011*\"verbum\" + 0.011*\"mundus\" + 0.009*\"pater\" + 0.009*\"virtus\" + 0.009*\"regnum\" + 0.009*\"intellego\"\n",
      "2024-11-24 21:13:32,711 - INFO - topic #3 (0.067): 0.012*\"pulchritudo\" + 0.011*\"christus\" + 0.010*\"natura\" + 0.009*\"virtus\" + 0.008*\"finis\" + 0.007*\"delphi\" + 0.007*\"imago\" + 0.007*\"lux\" + 0.007*\"ratio\" + 0.007*\"pulcher\"\n",
      "2024-11-24 21:13:32,711 - INFO - topic diff=3.612133, rho=1.000000\n",
      "2024-11-24 21:13:33,110 - INFO - -7.224 per-word bound, 149.5 perplexity estimate based on a held-out corpus of 1716 documents with 86367 words\n",
      "2024-11-24 21:13:33,110 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:33,433 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:33,434 - INFO - topic #11 (0.067): 0.016*\"sermo\" + 0.015*\"homo\" + 0.014*\"mitto\" + 0.012*\"christus\" + 0.012*\"filius\" + 0.011*\"iudico\" + 0.011*\"dies\" + 0.011*\"misericordia\" + 0.011*\"loquor\" + 0.010*\"spiritus\"\n",
      "2024-11-24 21:13:33,434 - INFO - topic #3 (0.067): 0.020*\"ars\" + 0.016*\"pulchritudo\" + 0.014*\"imago\" + 0.010*\"natura\" + 0.009*\"annus\" + 0.008*\"perfectus\" + 0.008*\"intellectus\" + 0.007*\"virtus\" + 0.007*\"lux\" + 0.007*\"ratio\"\n",
      "2024-11-24 21:13:33,435 - INFO - topic #14 (0.067): 0.026*\"homo\" + 0.025*\"sapientia\" + 0.020*\"vita\" + 0.013*\"spiritus\" + 0.009*\"mundus\" + 0.009*\"iustitia\" + 0.009*\"amor\" + 0.008*\"annas\" + 0.008*\"trinitas\" + 0.008*\"gratia\"\n",
      "2024-11-24 21:13:33,435 - INFO - topic #7 (0.067): 0.026*\"spiritus\" + 0.020*\"pater\" + 0.020*\"filius\" + 0.020*\"christus\" + 0.020*\"verbum\" + 0.013*\"homo\" + 0.010*\"nomen\" + 0.010*\"lux\" + 0.009*\"vita\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:13:33,435 - INFO - topic #0 (0.067): 0.022*\"christus\" + 0.012*\"dies\" + 0.010*\"virtus\" + 0.008*\"rex\" + 0.007*\"und\" + 0.007*\"natura\" + 0.007*\"imago\" + 0.006*\"spiritus\" + 0.006*\"mundus\" + 0.006*\"dominus\"\n",
      "2024-11-24 21:13:33,436 - INFO - topic diff=1.002165, rho=0.707107\n",
      "2024-11-24 21:13:33,436 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.15s', 'datetime': '2024-11-24T21:13:33.436517', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:33,439 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:33,838 - INFO - 1 batches submitted to accumulate stats from 64 documents (2635 virtual)\n",
      "2024-11-24 21:13:33,841 - INFO - 2 batches submitted to accumulate stats from 128 documents (4683 virtual)\n",
      "2024-11-24 21:13:33,844 - INFO - 3 batches submitted to accumulate stats from 192 documents (7746 virtual)\n",
      "2024-11-24 21:13:33,845 - INFO - 4 batches submitted to accumulate stats from 256 documents (10413 virtual)\n",
      "2024-11-24 21:13:33,845 - INFO - 5 batches submitted to accumulate stats from 320 documents (13754 virtual)\n",
      "2024-11-24 21:13:33,846 - INFO - 6 batches submitted to accumulate stats from 384 documents (16396 virtual)\n",
      "2024-11-24 21:13:33,847 - INFO - 7 batches submitted to accumulate stats from 448 documents (20238 virtual)\n",
      "2024-11-24 21:13:34,600 - INFO - 8 batches submitted to accumulate stats from 512 documents (22679 virtual)\n",
      "2024-11-24 21:13:34,634 - INFO - 9 batches submitted to accumulate stats from 576 documents (25659 virtual)\n",
      "2024-11-24 21:13:34,652 - INFO - 10 batches submitted to accumulate stats from 640 documents (29877 virtual)\n",
      "2024-11-24 21:13:34,665 - INFO - 11 batches submitted to accumulate stats from 704 documents (33843 virtual)\n",
      "2024-11-24 21:13:34,672 - INFO - 12 batches submitted to accumulate stats from 768 documents (36142 virtual)\n",
      "2024-11-24 21:13:34,692 - INFO - 13 batches submitted to accumulate stats from 832 documents (37918 virtual)\n",
      "2024-11-24 21:13:34,739 - INFO - 14 batches submitted to accumulate stats from 896 documents (40032 virtual)\n",
      "2024-11-24 21:13:34,744 - INFO - 15 batches submitted to accumulate stats from 960 documents (43603 virtual)\n",
      "2024-11-24 21:13:34,747 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46950 virtual)\n",
      "2024-11-24 21:13:34,750 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50883 virtual)\n",
      "2024-11-24 21:13:34,753 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54650 virtual)\n",
      "2024-11-24 21:13:34,759 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57099 virtual)\n",
      "2024-11-24 21:13:34,763 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60285 virtual)\n",
      "2024-11-24 21:13:34,768 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63897 virtual)\n",
      "2024-11-24 21:13:34,769 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67014 virtual)\n",
      "2024-11-24 21:13:34,771 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70917 virtual)\n",
      "2024-11-24 21:13:34,780 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73494 virtual)\n",
      "2024-11-24 21:13:34,785 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77637 virtual)\n",
      "2024-11-24 21:13:34,791 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80774 virtual)\n",
      "2024-11-24 21:13:34,797 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83603 virtual)\n",
      "2024-11-24 21:13:34,801 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86039 virtual)\n",
      "2024-11-24 21:13:34,802 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89341 virtual)\n",
      "2024-11-24 21:13:34,816 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92485 virtual)\n",
      "2024-11-24 21:13:34,818 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95072 virtual)\n",
      "2024-11-24 21:13:34,823 - INFO - 32 batches submitted to accumulate stats from 2048 documents (97732 virtual)\n",
      "2024-11-24 21:13:34,830 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101512 virtual)\n",
      "2024-11-24 21:13:34,858 - INFO - 34 batches submitted to accumulate stats from 2176 documents (104594 virtual)\n",
      "2024-11-24 21:13:34,897 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107227 virtual)\n",
      "2024-11-24 21:13:34,972 - INFO - 36 batches submitted to accumulate stats from 2304 documents (109778 virtual)\n",
      "2024-11-24 21:13:34,978 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112740 virtual)\n",
      "2024-11-24 21:13:34,981 - INFO - 38 batches submitted to accumulate stats from 2432 documents (117582 virtual)\n",
      "2024-11-24 21:13:34,982 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120293 virtual)\n",
      "2024-11-24 21:13:34,986 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123036 virtual)\n",
      "2024-11-24 21:13:34,991 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126485 virtual)\n",
      "2024-11-24 21:13:35,006 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129315 virtual)\n",
      "2024-11-24 21:13:35,018 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132742 virtual)\n",
      "2024-11-24 21:13:35,021 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136814 virtual)\n",
      "2024-11-24 21:13:35,023 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139629 virtual)\n",
      "2024-11-24 21:13:35,039 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143409 virtual)\n",
      "2024-11-24 21:13:35,046 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146901 virtual)\n",
      "2024-11-24 21:13:35,050 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148533 virtual)\n",
      "2024-11-24 21:13:35,053 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151281 virtual)\n",
      "2024-11-24 21:13:35,055 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155272 virtual)\n",
      "2024-11-24 21:13:35,061 - INFO - 51 batches submitted to accumulate stats from 3264 documents (158416 virtual)\n",
      "2024-11-24 21:13:35,069 - INFO - 52 batches submitted to accumulate stats from 3328 documents (161927 virtual)\n",
      "2024-11-24 21:13:35,072 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164184 virtual)\n",
      "2024-11-24 21:13:35,076 - INFO - 54 batches submitted to accumulate stats from 3456 documents (166760 virtual)\n",
      "2024-11-24 21:13:35,081 - INFO - 55 batches submitted to accumulate stats from 3520 documents (169860 virtual)\n",
      "2024-11-24 21:13:35,109 - INFO - 56 batches submitted to accumulate stats from 3584 documents (172578 virtual)\n",
      "2024-11-24 21:13:35,111 - INFO - 57 batches submitted to accumulate stats from 3648 documents (175208 virtual)\n",
      "2024-11-24 21:13:35,115 - INFO - 58 batches submitted to accumulate stats from 3712 documents (179513 virtual)\n",
      "2024-11-24 21:13:35,119 - INFO - 59 batches submitted to accumulate stats from 3776 documents (179845 virtual)\n",
      "2024-11-24 21:13:35,241 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:35,258 - INFO - accumulated word occurrence stats for 180057 virtual documents\n",
      "2024-11-24 21:13:35,584 - INFO - 第 3 折评估完成: NPMI=0.4857, Diversity=0.4133, Optimal Score=0.4495\n",
      "实验进度:  97%|█████████▋| 58/60 [03:03<00:07,  3.56s/it]2024-11-24 21:13:35,587 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:35,672 - INFO - built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\n",
      "2024-11-24 21:13:35,672 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8885 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 214643 corpus positions)\", 'datetime': '2024-11-24T21:13:35.672660', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:35,675 - INFO - discarding 6885 tokens: [('element', 6), ('grando', 3), ('terraemotus', 3), ('anatomia', 1), ('caesarius', 10), ('carnalitas', 7), ('deauro', 4), ('durities', 4), ('foramen', 2), ('innitor', 9)]...\n",
      "2024-11-24 21:13:35,676 - INFO - keeping 2000 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:35,677 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:13:35,678 - INFO - 词典过滤: 8885 -> 2000 个词\n",
      "2024-11-24 21:13:35,733 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:35,733 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:35,734 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:35,736 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:35,736 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:35,747 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:36,241 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:36,243 - INFO - topic #0 (0.067): 0.032*\"und\" + 0.016*\"wir\" + 0.016*\"ratio\" + 0.013*\"spiritus\" + 0.012*\"dies\" + 0.010*\"christus\" + 0.008*\"delphi\" + 0.008*\"homo\" + 0.008*\"vita\" + 0.007*\"intellectus\"\n",
      "2024-11-24 21:13:36,243 - INFO - topic #8 (0.067): 0.024*\"vita\" + 0.020*\"christus\" + 0.019*\"verbum\" + 0.018*\"homo\" + 0.016*\"mundus\" + 0.012*\"filius\" + 0.011*\"pater\" + 0.010*\"spiritus\" + 0.009*\"intellectus\" + 0.009*\"panis\"\n",
      "2024-11-24 21:13:36,243 - INFO - topic #14 (0.067): 0.018*\"christus\" + 0.015*\"spiritus\" + 0.014*\"delphi\" + 0.014*\"natura\" + 0.013*\"vita\" + 0.009*\"pater\" + 0.009*\"volo\" + 0.009*\"homo\" + 0.008*\"venio\" + 0.008*\"debeo\"\n",
      "2024-11-24 21:13:36,244 - INFO - topic #1 (0.067): 0.014*\"mundus\" + 0.014*\"homo\" + 0.014*\"ratio\" + 0.013*\"spiritus\" + 0.011*\"verbum\" + 0.009*\"virtus\" + 0.009*\"christus\" + 0.008*\"volo\" + 0.008*\"vita\" + 0.008*\"larissa\"\n",
      "2024-11-24 21:13:36,244 - INFO - topic #3 (0.067): 0.016*\"filius\" + 0.014*\"christus\" + 0.014*\"delphi\" + 0.013*\"pater\" + 0.011*\"mors\" + 0.011*\"evangelium\" + 0.010*\"spiritus\" + 0.010*\"vita\" + 0.010*\"pulchritudo\" + 0.009*\"veritas\"\n",
      "2024-11-24 21:13:36,244 - INFO - topic diff=3.390296, rho=1.000000\n",
      "2024-11-24 21:13:36,652 - INFO - -7.235 per-word bound, 150.7 perplexity estimate based on a held-out corpus of 1716 documents with 86959 words\n",
      "2024-11-24 21:13:36,652 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:36,977 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:36,978 - INFO - topic #11 (0.067): 0.027*\"homo\" + 0.019*\"spiritus\" + 0.018*\"christus\" + 0.014*\"veritas\" + 0.014*\"virtus\" + 0.013*\"sapientia\" + 0.011*\"vita\" + 0.011*\"verbum\" + 0.011*\"mundus\" + 0.010*\"fides\"\n",
      "2024-11-24 21:13:36,979 - INFO - topic #3 (0.067): 0.019*\"filius\" + 0.019*\"lex\" + 0.017*\"pater\" + 0.013*\"delphi\" + 0.013*\"mors\" + 0.013*\"veritas\" + 0.013*\"christus\" + 0.012*\"evangelium\" + 0.011*\"pulchritudo\" + 0.010*\"intellectus\"\n",
      "2024-11-24 21:13:36,979 - INFO - topic #14 (0.067): 0.018*\"delphi\" + 0.018*\"christus\" + 0.017*\"natura\" + 0.012*\"spiritus\" + 0.011*\"vita\" + 0.010*\"homo\" + 0.010*\"corpus\" + 0.009*\"debeo\" + 0.008*\"volo\" + 0.008*\"creatura\"\n",
      "2024-11-24 21:13:36,979 - INFO - topic #7 (0.067): 0.028*\"filius\" + 0.018*\"christus\" + 0.015*\"homo\" + 0.014*\"natura\" + 0.014*\"verbum\" + 0.013*\"pater\" + 0.012*\"gratia\" + 0.011*\"larissa\" + 0.011*\"fides\" + 0.009*\"gloria\"\n",
      "2024-11-24 21:13:36,980 - INFO - topic #0 (0.067): 0.028*\"ratio\" + 0.021*\"und\" + 0.013*\"dies\" + 0.011*\"wir\" + 0.009*\"sensus\" + 0.009*\"spiritus\" + 0.009*\"intellectus\" + 0.008*\"nomen\" + 0.008*\"vir\" + 0.007*\"scio\"\n",
      "2024-11-24 21:13:36,980 - INFO - topic diff=0.959596, rho=0.707107\n",
      "2024-11-24 21:13:36,980 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.24s', 'datetime': '2024-11-24T21:13:36.980841', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:36,983 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:37,344 - INFO - 1 batches submitted to accumulate stats from 64 documents (2551 virtual)\n",
      "2024-11-24 21:13:37,347 - INFO - 2 batches submitted to accumulate stats from 128 documents (5092 virtual)\n",
      "2024-11-24 21:13:37,349 - INFO - 3 batches submitted to accumulate stats from 192 documents (7924 virtual)\n",
      "2024-11-24 21:13:37,350 - INFO - 4 batches submitted to accumulate stats from 256 documents (10461 virtual)\n",
      "2024-11-24 21:13:37,352 - INFO - 5 batches submitted to accumulate stats from 320 documents (14164 virtual)\n",
      "2024-11-24 21:13:37,354 - INFO - 6 batches submitted to accumulate stats from 384 documents (16327 virtual)\n",
      "2024-11-24 21:13:37,356 - INFO - 7 batches submitted to accumulate stats from 448 documents (20650 virtual)\n",
      "2024-11-24 21:13:38,081 - INFO - 8 batches submitted to accumulate stats from 512 documents (23026 virtual)\n",
      "2024-11-24 21:13:38,110 - INFO - 9 batches submitted to accumulate stats from 576 documents (26395 virtual)\n",
      "2024-11-24 21:13:38,141 - INFO - 10 batches submitted to accumulate stats from 640 documents (29998 virtual)\n",
      "2024-11-24 21:13:38,165 - INFO - 11 batches submitted to accumulate stats from 704 documents (34014 virtual)\n",
      "2024-11-24 21:13:38,229 - INFO - 12 batches submitted to accumulate stats from 768 documents (36311 virtual)\n",
      "2024-11-24 21:13:38,233 - INFO - 13 batches submitted to accumulate stats from 832 documents (37940 virtual)\n",
      "2024-11-24 21:13:38,238 - INFO - 14 batches submitted to accumulate stats from 896 documents (40250 virtual)\n",
      "2024-11-24 21:13:38,247 - INFO - 15 batches submitted to accumulate stats from 960 documents (43580 virtual)\n",
      "2024-11-24 21:13:38,260 - INFO - 16 batches submitted to accumulate stats from 1024 documents (46775 virtual)\n",
      "2024-11-24 21:13:38,263 - INFO - 17 batches submitted to accumulate stats from 1088 documents (50887 virtual)\n",
      "2024-11-24 21:13:38,270 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54379 virtual)\n",
      "2024-11-24 21:13:38,275 - INFO - 19 batches submitted to accumulate stats from 1216 documents (56785 virtual)\n",
      "2024-11-24 21:13:38,293 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60160 virtual)\n",
      "2024-11-24 21:13:38,299 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63664 virtual)\n",
      "2024-11-24 21:13:38,302 - INFO - 22 batches submitted to accumulate stats from 1408 documents (66683 virtual)\n",
      "2024-11-24 21:13:38,311 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70328 virtual)\n",
      "2024-11-24 21:13:38,323 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73357 virtual)\n",
      "2024-11-24 21:13:38,350 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77532 virtual)\n",
      "2024-11-24 21:13:38,355 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80514 virtual)\n",
      "2024-11-24 21:13:38,369 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83629 virtual)\n",
      "2024-11-24 21:13:38,372 - INFO - 28 batches submitted to accumulate stats from 1792 documents (85940 virtual)\n",
      "2024-11-24 21:13:38,374 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89395 virtual)\n",
      "2024-11-24 21:13:38,376 - INFO - 30 batches submitted to accumulate stats from 1920 documents (92595 virtual)\n",
      "2024-11-24 21:13:38,378 - INFO - 31 batches submitted to accumulate stats from 1984 documents (95565 virtual)\n",
      "2024-11-24 21:13:38,380 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98165 virtual)\n",
      "2024-11-24 21:13:38,381 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101126 virtual)\n",
      "2024-11-24 21:13:38,383 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105078 virtual)\n",
      "2024-11-24 21:13:38,384 - INFO - 35 batches submitted to accumulate stats from 2240 documents (107750 virtual)\n",
      "2024-11-24 21:13:38,387 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110149 virtual)\n",
      "2024-11-24 21:13:38,395 - INFO - 37 batches submitted to accumulate stats from 2368 documents (112718 virtual)\n",
      "2024-11-24 21:13:38,398 - INFO - 38 batches submitted to accumulate stats from 2432 documents (116206 virtual)\n",
      "2024-11-24 21:13:38,402 - INFO - 39 batches submitted to accumulate stats from 2496 documents (120074 virtual)\n",
      "2024-11-24 21:13:38,410 - INFO - 40 batches submitted to accumulate stats from 2560 documents (123022 virtual)\n",
      "2024-11-24 21:13:38,411 - INFO - 41 batches submitted to accumulate stats from 2624 documents (126267 virtual)\n",
      "2024-11-24 21:13:38,416 - INFO - 42 batches submitted to accumulate stats from 2688 documents (129111 virtual)\n",
      "2024-11-24 21:13:38,417 - INFO - 43 batches submitted to accumulate stats from 2752 documents (132186 virtual)\n",
      "2024-11-24 21:13:38,445 - INFO - 44 batches submitted to accumulate stats from 2816 documents (136595 virtual)\n",
      "2024-11-24 21:13:38,451 - INFO - 45 batches submitted to accumulate stats from 2880 documents (139556 virtual)\n",
      "2024-11-24 21:13:38,453 - INFO - 46 batches submitted to accumulate stats from 2944 documents (143530 virtual)\n",
      "2024-11-24 21:13:38,470 - INFO - 47 batches submitted to accumulate stats from 3008 documents (146865 virtual)\n",
      "2024-11-24 21:13:38,487 - INFO - 48 batches submitted to accumulate stats from 3072 documents (148663 virtual)\n",
      "2024-11-24 21:13:38,506 - INFO - 49 batches submitted to accumulate stats from 3136 documents (151516 virtual)\n",
      "2024-11-24 21:13:38,626 - INFO - 50 batches submitted to accumulate stats from 3200 documents (155440 virtual)\n",
      "2024-11-24 21:13:38,642 - INFO - 51 batches submitted to accumulate stats from 3264 documents (159011 virtual)\n",
      "2024-11-24 21:13:38,644 - INFO - 52 batches submitted to accumulate stats from 3328 documents (162096 virtual)\n",
      "2024-11-24 21:13:38,646 - INFO - 53 batches submitted to accumulate stats from 3392 documents (164525 virtual)\n",
      "2024-11-24 21:13:38,648 - INFO - 54 batches submitted to accumulate stats from 3456 documents (167216 virtual)\n",
      "2024-11-24 21:13:38,649 - INFO - 55 batches submitted to accumulate stats from 3520 documents (170668 virtual)\n",
      "2024-11-24 21:13:38,651 - INFO - 56 batches submitted to accumulate stats from 3584 documents (173362 virtual)\n",
      "2024-11-24 21:13:38,653 - INFO - 57 batches submitted to accumulate stats from 3648 documents (176523 virtual)\n",
      "2024-11-24 21:13:38,655 - INFO - 58 batches submitted to accumulate stats from 3712 documents (180814 virtual)\n",
      "2024-11-24 21:13:38,656 - INFO - 59 batches submitted to accumulate stats from 3776 documents (181199 virtual)\n",
      "2024-11-24 21:13:38,826 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:38,845 - INFO - accumulated word occurrence stats for 181418 virtual documents\n",
      "2024-11-24 21:13:39,119 - INFO - 第 4 折评估完成: NPMI=0.4823, Diversity=0.4000, Optimal Score=0.4411\n",
      "实验进度:  98%|█████████▊| 59/60 [03:06<00:03,  3.55s/it]2024-11-24 21:13:39,122 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-11-24 21:13:39,218 - INFO - built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\n",
      "2024-11-24 21:13:39,219 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<8903 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...> from 3716 documents (total 216240 corpus positions)\", 'datetime': '2024-11-24T21:13:39.219120', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:39,222 - INFO - discarding 6903 tokens: [('element', 9), ('grando', 7), ('terraemotus', 5), ('aaron', 5), ('asper', 10), ('latus', 7), ('leichnam', 3), ('perforo', 7), ('potestativus', 2), ('primitivus', 3)]...\n",
      "2024-11-24 21:13:39,222 - INFO - keeping 2000 tokens which were in no less than 4 and no more than 1858 (=50.0%) documents\n",
      "2024-11-24 21:13:39,224 - INFO - resulting dictionary: Dictionary<2000 unique tokens: ['apocalypsis', 'appareo', 'behalten', 'constantinus', 'corona']...>\n",
      "2024-11-24 21:13:39,224 - INFO - 词典过滤: 8903 -> 2000 个词\n",
      "2024-11-24 21:13:39,290 - INFO - using symmetric alpha at 0.06666666666666667\n",
      "2024-11-24 21:13:39,290 - INFO - using symmetric eta at 0.06666666666666667\n",
      "2024-11-24 21:13:39,292 - INFO - using serial LDA version on this node\n",
      "2024-11-24 21:13:39,295 - INFO - running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3716 documents, updating model once every 2000 documents, evaluating perplexity every 3716 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2024-11-24 21:13:39,296 - WARNING - too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2024-11-24 21:13:39,297 - INFO - PROGRESS: pass 0, at document #2000/3716\n",
      "2024-11-24 21:13:39,743 - INFO - merging changes from 2000 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:39,745 - INFO - topic #0 (0.067): 0.020*\"christus\" + 0.019*\"spiritus\" + 0.016*\"homo\" + 0.014*\"mors\" + 0.013*\"virtus\" + 0.013*\"vita\" + 0.010*\"volo\" + 0.010*\"filius\" + 0.009*\"delphi\" + 0.008*\"verbum\"\n",
      "2024-11-24 21:13:39,745 - INFO - topic #8 (0.067): 0.022*\"christus\" + 0.015*\"verbum\" + 0.013*\"natura\" + 0.013*\"lux\" + 0.011*\"gegen\" + 0.010*\"homo\" + 0.009*\"filius\" + 0.009*\"spiritus\" + 0.009*\"corpus\" + 0.008*\"fides\"\n",
      "2024-11-24 21:13:39,745 - INFO - topic #14 (0.067): 0.019*\"pater\" + 0.013*\"christus\" + 0.012*\"rex\" + 0.012*\"mundus\" + 0.012*\"homo\" + 0.012*\"filius\" + 0.010*\"gloria\" + 0.009*\"spiritus\" + 0.009*\"barabbas\" + 0.008*\"venio\"\n",
      "2024-11-24 21:13:39,746 - INFO - topic #1 (0.067): 0.027*\"christus\" + 0.022*\"spiritus\" + 0.011*\"verbum\" + 0.010*\"sanctus\" + 0.010*\"vita\" + 0.009*\"pater\" + 0.009*\"intellectus\" + 0.009*\"virtus\" + 0.009*\"homo\" + 0.009*\"mundus\"\n",
      "2024-11-24 21:13:39,746 - INFO - topic #3 (0.067): 0.023*\"regnum\" + 0.022*\"spiritus\" + 0.014*\"christus\" + 0.012*\"larissa\" + 0.010*\"vita\" + 0.009*\"mundus\" + 0.009*\"gratia\" + 0.008*\"delphi\" + 0.007*\"homo\" + 0.007*\"iustitia\"\n",
      "2024-11-24 21:13:39,746 - INFO - topic diff=3.291545, rho=1.000000\n",
      "2024-11-24 21:13:40,233 - INFO - -7.279 per-word bound, 155.3 perplexity estimate based on a held-out corpus of 1716 documents with 87835 words\n",
      "2024-11-24 21:13:40,233 - INFO - PROGRESS: pass 0, at document #3716/3716\n",
      "2024-11-24 21:13:40,559 - INFO - merging changes from 1716 documents into a model of 3716 documents\n",
      "2024-11-24 21:13:40,561 - INFO - topic #11 (0.067): 0.019*\"spiritus\" + 0.017*\"sapientia\" + 0.014*\"magister\" + 0.012*\"homo\" + 0.012*\"christus\" + 0.011*\"delphi\" + 0.011*\"verbum\" + 0.010*\"mundus\" + 0.009*\"vita\" + 0.007*\"recipio\"\n",
      "2024-11-24 21:13:40,561 - INFO - topic #3 (0.067): 0.030*\"regnum\" + 0.019*\"spiritus\" + 0.017*\"larissa\" + 0.013*\"christus\" + 0.013*\"gratia\" + 0.009*\"vita\" + 0.009*\"dies\" + 0.008*\"peccatum\" + 0.008*\"mundus\" + 0.007*\"gaudium\"\n",
      "2024-11-24 21:13:40,561 - INFO - topic #14 (0.067): 0.018*\"pater\" + 0.014*\"gloria\" + 0.013*\"christus\" + 0.011*\"barabbas\" + 0.010*\"rex\" + 0.010*\"mundus\" + 0.010*\"homo\" + 0.010*\"larissa\" + 0.010*\"nomen\" + 0.009*\"filius\"\n",
      "2024-11-24 21:13:40,562 - INFO - topic #7 (0.067): 0.039*\"pater\" + 0.030*\"verbum\" + 0.027*\"christus\" + 0.023*\"filius\" + 0.017*\"spiritus\" + 0.015*\"homo\" + 0.010*\"loquor\" + 0.010*\"bonus\" + 0.009*\"mitto\" + 0.008*\"sanctus\"\n",
      "2024-11-24 21:13:40,562 - INFO - topic #0 (0.067): 0.019*\"mors\" + 0.019*\"spiritus\" + 0.018*\"christus\" + 0.018*\"homo\" + 0.012*\"vita\" + 0.010*\"delphi\" + 0.010*\"volo\" + 0.010*\"virtus\" + 0.009*\"amor\" + 0.007*\"filius\"\n",
      "2024-11-24 21:13:40,562 - INFO - topic diff=0.932602, rho=0.707107\n",
      "2024-11-24 21:13:40,563 - INFO - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=2000, num_topics=15, decay=0.5, chunksize=2000> in 1.27s', 'datetime': '2024-11-24T21:13:40.563324', 'gensim': '4.3.3', 'python': '3.10.15 (main, Oct  3 2024, 02:24:49) [Clang 14.0.6 ]', 'platform': 'macOS-15.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-11-24 21:13:40,566 - INFO - using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "2024-11-24 21:13:40,912 - INFO - 1 batches submitted to accumulate stats from 64 documents (2624 virtual)\n",
      "2024-11-24 21:13:40,915 - INFO - 2 batches submitted to accumulate stats from 128 documents (5145 virtual)\n",
      "2024-11-24 21:13:40,920 - INFO - 3 batches submitted to accumulate stats from 192 documents (8286 virtual)\n",
      "2024-11-24 21:13:40,922 - INFO - 4 batches submitted to accumulate stats from 256 documents (10621 virtual)\n",
      "2024-11-24 21:13:40,924 - INFO - 5 batches submitted to accumulate stats from 320 documents (14581 virtual)\n",
      "2024-11-24 21:13:40,925 - INFO - 6 batches submitted to accumulate stats from 384 documents (16958 virtual)\n",
      "2024-11-24 21:13:40,926 - INFO - 7 batches submitted to accumulate stats from 448 documents (20538 virtual)\n",
      "2024-11-24 21:13:41,632 - INFO - 8 batches submitted to accumulate stats from 512 documents (23194 virtual)\n",
      "2024-11-24 21:13:41,661 - INFO - 9 batches submitted to accumulate stats from 576 documents (26402 virtual)\n",
      "2024-11-24 21:13:41,695 - INFO - 10 batches submitted to accumulate stats from 640 documents (30032 virtual)\n",
      "2024-11-24 21:13:41,737 - INFO - 11 batches submitted to accumulate stats from 704 documents (33775 virtual)\n",
      "2024-11-24 21:13:41,776 - INFO - 12 batches submitted to accumulate stats from 768 documents (36186 virtual)\n",
      "2024-11-24 21:13:41,779 - INFO - 13 batches submitted to accumulate stats from 832 documents (37852 virtual)\n",
      "2024-11-24 21:13:41,781 - INFO - 14 batches submitted to accumulate stats from 896 documents (40051 virtual)\n",
      "2024-11-24 21:13:41,801 - INFO - 15 batches submitted to accumulate stats from 960 documents (43965 virtual)\n",
      "2024-11-24 21:13:41,829 - INFO - 16 batches submitted to accumulate stats from 1024 documents (47017 virtual)\n",
      "2024-11-24 21:13:41,910 - INFO - 17 batches submitted to accumulate stats from 1088 documents (51353 virtual)\n",
      "2024-11-24 21:13:42,015 - INFO - 18 batches submitted to accumulate stats from 1152 documents (54837 virtual)\n",
      "2024-11-24 21:13:42,017 - INFO - 19 batches submitted to accumulate stats from 1216 documents (57266 virtual)\n",
      "2024-11-24 21:13:42,019 - INFO - 20 batches submitted to accumulate stats from 1280 documents (60302 virtual)\n",
      "2024-11-24 21:13:42,021 - INFO - 21 batches submitted to accumulate stats from 1344 documents (63885 virtual)\n",
      "2024-11-24 21:13:42,023 - INFO - 22 batches submitted to accumulate stats from 1408 documents (67115 virtual)\n",
      "2024-11-24 21:13:42,025 - INFO - 23 batches submitted to accumulate stats from 1472 documents (70972 virtual)\n",
      "2024-11-24 21:13:42,027 - INFO - 24 batches submitted to accumulate stats from 1536 documents (73772 virtual)\n",
      "2024-11-24 21:13:42,029 - INFO - 25 batches submitted to accumulate stats from 1600 documents (77892 virtual)\n",
      "2024-11-24 21:13:42,035 - INFO - 26 batches submitted to accumulate stats from 1664 documents (80890 virtual)\n",
      "2024-11-24 21:13:42,048 - INFO - 27 batches submitted to accumulate stats from 1728 documents (83875 virtual)\n",
      "2024-11-24 21:13:42,053 - INFO - 28 batches submitted to accumulate stats from 1792 documents (86190 virtual)\n",
      "2024-11-24 21:13:42,055 - INFO - 29 batches submitted to accumulate stats from 1856 documents (89815 virtual)\n",
      "2024-11-24 21:13:42,056 - INFO - 30 batches submitted to accumulate stats from 1920 documents (93205 virtual)\n",
      "2024-11-24 21:13:42,063 - INFO - 31 batches submitted to accumulate stats from 1984 documents (96068 virtual)\n",
      "2024-11-24 21:13:42,066 - INFO - 32 batches submitted to accumulate stats from 2048 documents (98589 virtual)\n",
      "2024-11-24 21:13:42,070 - INFO - 33 batches submitted to accumulate stats from 2112 documents (101951 virtual)\n",
      "2024-11-24 21:13:42,078 - INFO - 34 batches submitted to accumulate stats from 2176 documents (105799 virtual)\n",
      "2024-11-24 21:13:42,085 - INFO - 35 batches submitted to accumulate stats from 2240 documents (108469 virtual)\n",
      "2024-11-24 21:13:42,089 - INFO - 36 batches submitted to accumulate stats from 2304 documents (110975 virtual)\n",
      "2024-11-24 21:13:42,095 - INFO - 37 batches submitted to accumulate stats from 2368 documents (113876 virtual)\n",
      "2024-11-24 21:13:42,097 - INFO - 38 batches submitted to accumulate stats from 2432 documents (118842 virtual)\n",
      "2024-11-24 21:13:42,106 - INFO - 39 batches submitted to accumulate stats from 2496 documents (121288 virtual)\n",
      "2024-11-24 21:13:42,108 - INFO - 40 batches submitted to accumulate stats from 2560 documents (124746 virtual)\n",
      "2024-11-24 21:13:42,112 - INFO - 41 batches submitted to accumulate stats from 2624 documents (128006 virtual)\n",
      "2024-11-24 21:13:42,129 - INFO - 42 batches submitted to accumulate stats from 2688 documents (131244 virtual)\n",
      "2024-11-24 21:13:42,134 - INFO - 43 batches submitted to accumulate stats from 2752 documents (134324 virtual)\n",
      "2024-11-24 21:13:42,157 - INFO - 44 batches submitted to accumulate stats from 2816 documents (138878 virtual)\n",
      "2024-11-24 21:13:42,175 - INFO - 45 batches submitted to accumulate stats from 2880 documents (141596 virtual)\n",
      "2024-11-24 21:13:42,201 - INFO - 46 batches submitted to accumulate stats from 2944 documents (145775 virtual)\n",
      "2024-11-24 21:13:42,203 - INFO - 47 batches submitted to accumulate stats from 3008 documents (148859 virtual)\n",
      "2024-11-24 21:13:42,209 - INFO - 48 batches submitted to accumulate stats from 3072 documents (150634 virtual)\n",
      "2024-11-24 21:13:42,215 - INFO - 49 batches submitted to accumulate stats from 3136 documents (153328 virtual)\n",
      "2024-11-24 21:13:42,217 - INFO - 50 batches submitted to accumulate stats from 3200 documents (157244 virtual)\n",
      "2024-11-24 21:13:42,221 - INFO - 51 batches submitted to accumulate stats from 3264 documents (160634 virtual)\n",
      "2024-11-24 21:13:42,223 - INFO - 52 batches submitted to accumulate stats from 3328 documents (163582 virtual)\n",
      "2024-11-24 21:13:42,229 - INFO - 53 batches submitted to accumulate stats from 3392 documents (166366 virtual)\n",
      "2024-11-24 21:13:42,235 - INFO - 54 batches submitted to accumulate stats from 3456 documents (168659 virtual)\n",
      "2024-11-24 21:13:42,258 - INFO - 55 batches submitted to accumulate stats from 3520 documents (172360 virtual)\n",
      "2024-11-24 21:13:42,260 - INFO - 56 batches submitted to accumulate stats from 3584 documents (175145 virtual)\n",
      "2024-11-24 21:13:42,262 - INFO - 57 batches submitted to accumulate stats from 3648 documents (178087 virtual)\n",
      "2024-11-24 21:13:42,264 - INFO - 58 batches submitted to accumulate stats from 3712 documents (182411 virtual)\n",
      "2024-11-24 21:13:42,265 - INFO - 59 batches submitted to accumulate stats from 3776 documents (182796 virtual)\n",
      "2024-11-24 21:13:42,367 - INFO - 7 accumulators retrieved from output queue\n",
      "2024-11-24 21:13:42,387 - INFO - accumulated word occurrence stats for 183005 virtual documents\n",
      "2024-11-24 21:13:42,650 - INFO - 第 5 折评估完成: NPMI=0.4909, Diversity=0.3733, Optimal Score=0.4321\n",
      "实验进度: 100%|██████████| 60/60 [03:10<00:00,  3.17s/it]\n",
      "2024-11-24 21:13:42,672 - INFO - 已保存评估结果DataFrame\n",
      "2024-11-24 21:13:42,673 - INFO - 已保存每折详细结果\n",
      "2024-11-24 21:13:42,690 - INFO - 已保存主题词结果\n",
      "2024-11-24 21:13:42,690 - INFO - 已保存最佳参数\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验结果已成功保存!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 26368 (\\N{CJK UNIFIED IDEOGRAPH-6700}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 22823 (\\N{CJK UNIFIED IDEOGRAPH-5927}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 35789 (\\N{CJK UNIFIED IDEOGRAPH-8BCD}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 39057 (\\N{CJK UNIFIED IDEOGRAPH-9891}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 38408 (\\N{CJK UNIFIED IDEOGRAPH-9608}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 23567 (\\N{CJK UNIFIED IDEOGRAPH-5C0F}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 32452 (\\N{CJK UNIFIED IDEOGRAPH-7EC4}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 21512 (\\N{CJK UNIFIED IDEOGRAPH-5408}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 35780 (\\N{CJK UNIFIED IDEOGRAPH-8BC4}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 20272 (\\N{CJK UNIFIED IDEOGRAPH-4F30}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:20: UserWarning: Glyph 26524 (\\N{CJK UNIFIED IDEOGRAPH-679C}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 26368 (\\N{CJK UNIFIED IDEOGRAPH-6700}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 22823 (\\N{CJK UNIFIED IDEOGRAPH-5927}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 35789 (\\N{CJK UNIFIED IDEOGRAPH-8BCD}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 39057 (\\N{CJK UNIFIED IDEOGRAPH-9891}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 38408 (\\N{CJK UNIFIED IDEOGRAPH-9608}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 23567 (\\N{CJK UNIFIED IDEOGRAPH-5C0F}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 32452 (\\N{CJK UNIFIED IDEOGRAPH-7EC4}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 21512 (\\N{CJK UNIFIED IDEOGRAPH-5408}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 35780 (\\N{CJK UNIFIED IDEOGRAPH-8BC4}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 20272 (\\N{CJK UNIFIED IDEOGRAPH-4F30}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_24774/3012458350.py:21: UserWarning: Glyph 26524 (\\N{CJK UNIFIED IDEOGRAPH-679C}) missing from current font.\n",
      "  plt.savefig(os.path.join(experiment_dir, 'threshold_heatmap.png'))\n",
      "2024-11-24 21:13:43,159 - INFO - 已保存评估结果热力图\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可视化结果已生成!\n",
      "\n",
      "最佳参数组合:\n",
      "最小词频阈值: 2\n",
      "最大词频阈值: 200\n",
      "Optimal Score: 0.476\n"
     ]
    }
   ],
   "source": [
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置时间戳和实验目录\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    experiment_dir = os.path.join(dirs['output'], f'experiment_{timestamp}')\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "    # 设置日志\n",
    "    log_file = os.path.join(dirs['logs'], f'threshold_evaluation_{timestamp}.log')\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 加载段落数据\n",
    "        paragraphs = load_paragraphs(dirs['input'])\n",
    "        logging.info(f\"成功加载语料库，共 {len(paragraphs)} 个段落\")\n",
    "\n",
    "        # 运行实验\n",
    "        results_df, best_params, raw_results = evaluate_thresholds(\n",
    "            corpus=paragraphs,\n",
    "            min_freqs=[2, 3, 4],\n",
    "            max_freqs=[200, 800, 1400, 2000],\n",
    "            n_topics=15,\n",
    "            n_splits=5,\n",
    "            alpha=0.5\n",
    "        )\n",
    "\n",
    "        # 保存结果\n",
    "        save_experiment_results(results_df, best_params, raw_results, experiment_dir)\n",
    "        print(\"实验结果已成功保存!\")\n",
    "\n",
    "        # 生成可视化\n",
    "        visualize_results(results_df, experiment_dir)\n",
    "        print(\"可视化结果已生成!\")\n",
    "\n",
    "        # 打印最佳参数\n",
    "        print(\"\\n最佳参数组合:\")\n",
    "        print(f\"最小词频阈值: {best_params['min_freq']}\")\n",
    "        print(f\"最大词频阈值: {best_params['max_freq']}\")\n",
    "        print(f\"Optimal Score: {best_params['optimal_score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"实验过程中发生错误: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 21:13:43,207 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2024-11-24 21:13:43,210 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2024-11-24 21:13:43,211 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2024-11-24 21:13:43,212 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2024-11-24 21:13:43,214 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2024-11-24 21:13:43,215 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameter Combination:\n",
      "Threshold Range: 2-200\n",
      "NPMI: 0.4981\n",
      "Diversity: 0.4547\n",
      "Optimal Score: 0.4764\n",
      "Visualization saved in: experiments/lda/cusanus/threshold/experiment_20241124_211031/metrics_trends.png\n"
     ]
    }
   ],
   "source": [
    "def visualize_metrics_trends(df, experiment_dir):\n",
    "    \"\"\"Create comprehensive visualization for all metrics\"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # 创建阈值组合标签\n",
    "    df['threshold_range'] = df['min_freq'].astype(str) + '-' + df['max_freq'].astype(str)\n",
    "    \n",
    "    # 计算每个阈值组合的平均指标值\n",
    "    metrics_avg = df.groupby('threshold_range').agg({\n",
    "        'npmi': 'mean',\n",
    "        'diversity': 'mean',\n",
    "        'optimal_score': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 排序以确保x轴顺序合理\n",
    "    metrics_avg['min_freq'] = metrics_avg['threshold_range'].str.split('-').str[0].astype(int)\n",
    "    metrics_avg['max_freq'] = metrics_avg['threshold_range'].str.split('-').str[1].astype(int)\n",
    "    metrics_avg = metrics_avg.sort_values(['min_freq', 'max_freq'])\n",
    "    \n",
    "    # 绘制三个指标的折线\n",
    "    plt.plot(metrics_avg['threshold_range'], metrics_avg['npmi'], \n",
    "            marker='o', label='NPMI', color='#FFA500', linewidth=2)\n",
    "    plt.plot(metrics_avg['threshold_range'], metrics_avg['diversity'], \n",
    "            marker='s', label='Diversity', color='#FF6B6B', linewidth=2)\n",
    "    plt.plot(metrics_avg['threshold_range'], metrics_avg['optimal_score'], \n",
    "            marker='^', label='Optimal Score', color='#4ECDC4', linewidth=2)\n",
    "    \n",
    "    # 设置图表格式\n",
    "    plt.title('Relationship Between Threshold Range and Metrics', fontsize=14, pad=20)\n",
    "    plt.xlabel('Threshold Range (min_freq-max_freq)', fontsize=12)\n",
    "    plt.ylabel('Scores', fontsize=12)\n",
    "    \n",
    "    # 添加网格\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 调整x轴标签\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # 添加图例\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图片\n",
    "    plt.savefig(os.path.join(experiment_dir, 'metrics_trends.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 打印最优组合\n",
    "    best_combo = metrics_avg.loc[metrics_avg['optimal_score'].idxmax()]\n",
    "    print(f\"\\nBest Parameter Combination:\")\n",
    "    print(f\"Threshold Range: {best_combo['threshold_range']}\")\n",
    "    print(f\"NPMI: {best_combo['npmi']:.4f}\")\n",
    "    print(f\"Diversity: {best_combo['diversity']:.4f}\")\n",
    "    print(f\"Optimal Score: {best_combo['optimal_score']:.4f}\")\n",
    "\n",
    "# 读取数据并生成可视化\n",
    "df = pd.read_csv(os.path.join(experiment_dir, 'fold_results.csv'))\n",
    "visualize_metrics_trends(df, experiment_dir)\n",
    "print(f\"Visualization saved in: {experiment_dir}/metrics_trends.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cusanus_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
